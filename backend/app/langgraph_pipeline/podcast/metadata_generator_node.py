"""
Metadata Generator Node (V3 - ONNX Recognition + Gemini Fallback)
=================================================================

ë³€ê²½ì‚¬í•­:
- EasyOCR/PaddleOCR ì™„ì „ ì œê±° (ë©”ëª¨ë¦¬ OOM í•´ê²°)
- ONNX Runtime ê¸°ë°˜ì˜ ì´ˆê²½ëŸ‰ Recognition ì•„í‚¤í…ì²˜ ë„ì…
- í…ìŠ¤íŠ¸ ë¼ì¸ ê²€ì¶œ(Heuristic Crop) -> ONNX ì¶”ë¡ 
- ëª¨ë¸ ë¶€ì¬ ì‹œ Gemini Visionìœ¼ë¡œ ìë™ Fallback

"""

import os
import json
import tempfile
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime
import traceback
import io
import logging
import sys
import math

# âœ… ê²½ëŸ‰í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import cv2
import numpy as np
from PIL import Image

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
from .document_converter_node import DocumentConverterNode
from .improved_hybrid_filter import (
    ImprovedHybridFilterPipeline,
    UniversalImageExtractor,
    ImageMetadata,
    get_global_model,
    gemini_ocr_image_bytes
)
from vertexai.generative_models import Part
from pypdfium2 import PdfDocument

logger = logging.getLogger(__name__)

def _log(*args, level: str | None = None, exc_info: bool = False, end: str = '\n', flush: bool = False) -> None:
    msg = " ".join(str(a) for a in args).rstrip() if args else ""
    if end != "\n" or flush:
        print(msg, end=end, flush=flush)
        return
    lvl = (level or "DEBUG").upper()
    if lvl == "INFO": logger.info(msg, exc_info=exc_info)
    elif lvl in ("WARN", "WARNING"): logger.warning(msg, exc_info=exc_info)
    elif lvl == "ERROR": logger.error(msg, exc_info=exc_info)
    else: logger.debug(msg, exc_info=exc_info)

# ==========================================
# ğŸ”§ RapidOCR Wrapper
# ==========================================
_rapid_ocr_engine = None

def get_rapid_ocr():
    global _rapid_ocr_engine
    if _rapid_ocr_engine is not None:
        return _rapid_ocr_engine
    try:
        from rapidocr_onnxruntime import RapidOCR
        base_dir = Path(__file__).parent.parent.parent / "ocr_model"
        det_path = base_dir / "det.onnx"
        rec_path = base_dir / "rec.onnx"
        dict_path = base_dir / "dict.txt"

        if not det_path.exists() or not rec_path.exists():
            _log(f"âš ï¸ OCR ëª¨ë¸ íŒŒì¼ ì—†ìŒ ({base_dir}) -> Gemini Fallback", level="WARNING")
            return None

        _rapid_ocr_engine = RapidOCR(
            det_model_path=str(det_path),
            rec_model_path=str(rec_path),
            rec_keys_path=str(dict_path),
        )
        _log("âœ… RapidOCR ì´ˆê¸°í™” ì™„ë£Œ", level="INFO")
        return _rapid_ocr_engine
    except Exception as e:
        _log(f"âš ï¸ RapidOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", level="WARNING")
        return None

# ==========================================
# ğŸ”§ Main Class
# ==========================================
class TextExtractor:
    """
    PDFì—ì„œ í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ + ë§ˆì»¤ ì‚½ì…
    V3: pdfplumber + ONNX(Recognition) + Gemini Fallback
    """

    def __init__(self):
        if not PDFPLUMBER_AVAILABLE:
            raise ImportError("pdfplumberê°€ í•„ìš”í•©ë‹ˆë‹¤")

        self.ocr_enabled = True
        self.min_text_length = 100
        self.gemini_ocr_fallback = os.getenv('GEMINI_OCR_FALLBACK', 'true').lower() in ('1','true','yes','y')
        self.gemini_ocr_max_sample_pages = int(os.getenv('GEMINI_OCR_MAX_SAMPLE_PAGES', '10'))
        self._gemini_ocr_used_pages = 0
        self._gemini_ocr_skipped_pages = 0

        # RapidOCR ì´ˆê¸°í™” ì‹œë„
        self._ocr = get_rapid_ocr()

    def _perform_ocr_on_page(self, pdf_path: str, page_number: int) -> Tuple[str, Optional[Image.Image]]:
        """
        í˜ì´ì§€ì— OCR ìˆ˜í–‰
        ì „ëµ: ONNX (1ìˆœìœ„) -> ì‹¤íŒ¨/ê²°ê³¼ë¶€ì¡± -> Gemini (2ìˆœìœ„)
        """
        pil_img = None
        try:
            pdf = PdfDocument(pdf_path)
            page = pdf[page_number - 1]
            bitmap = page.render(scale=2.0)
            pil_img = bitmap.to_pil()

            max_dim = 1024
            if max(pil_img.size) > max_dim:
                pil_img.thumbnail((max_dim, max_dim), Image.LANCZOS)

            if self._ocr is None:
                return "", pil_img

            import numpy as np
            img_np = np.array(pil_img)
            result, elapsed = self._ocr(img_np)

            if not result:
                _log(f"âš ï¸ RapidOCR ê²°ê³¼ ì—†ìŒ (page {page_number})", level="WARNING")
                return "", pil_img

            texts = [line[1] for line in result if line[1] and line[1].strip()]
            extracted_text = "\n".join(texts)
            _log(f"ğŸ§© RapidOCR ê²°ê³¼: {len(extracted_text)}ì (page {page_number})", level="DEBUG")
            return extracted_text, pil_img

        except Exception as e:
            _log(f"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (page {page_number}): {e}", level="ERROR")
            return "", pil_img

    def _calculate_sample_pages(self, total_pages: int, max_samples: int) -> List[int]:
        # (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        if total_pages <= max_samples: return list(range(1, total_pages + 1))
        head_count = min(6, total_pages)
        tail_count = min(6, total_pages)
        head_pages = list(range(1, head_count + 1))
        tail_pages = list(range(max(total_pages - tail_count + 1, head_count + 1), total_pages + 1))
        mid_count = max_samples - len(head_pages) - len(tail_pages)
        if mid_count > 0:
            mid_start = head_count + 1
            mid_end = total_pages - tail_count
            if mid_end > mid_start:
                step = (mid_end - mid_start + 1) / (mid_count + 1)
                mid_pages = [int(mid_start + step * (i + 1)) for i in range(mid_count)]
                mid_pages = [p for p in mid_pages if p not in head_pages and p not in tail_pages]
            else: mid_pages = []
        else: mid_pages = []
        return sorted(set(head_pages + mid_pages + tail_pages))

    def _save_debug_image(self, image, pdf_path: str, page_number: int):
        if image is None: return
        try:
            pdf_name = Path(pdf_path).stem
            debug_dir = Path("/tmp/ocr_debug") / pdf_name
            debug_dir.mkdir(parents=True, exist_ok=True)
            image.save(debug_dir / f"page_{page_number:03d}.png")
        except: pass

    def extract_with_markers(self, pdf_path: str, prefix: str = "MAIN"):
        """
        ë©”ì¸ ì¶”ì¶œ ë¡œì§
        """
        pages_text = []
        total_pages = 0
        ocr_count = 0
        
        # í†µê³„ ì´ˆê¸°í™”
        self._gemini_ocr_used_pages = 0
        self._gemini_ocr_skipped_pages = 0

        # 1. í˜ì´ì§€ ìƒ˜í”Œë§ ê³„ì‚°
        sample_pages = None
        try:
            with pdfplumber.open(pdf_path) as pdf:
                total_pages = len(pdf.pages)
                if self.gemini_ocr_fallback:
                    sample_pages = self._calculate_sample_pages(total_pages, self.gemini_ocr_max_sample_pages)
                    _log(f"ğŸ¯ Gemini ìƒ˜í”Œë§: {len(sample_pages)}/{total_pages} í˜ì´ì§€", level="INFO")
        except Exception as e:
            _log(f"âŒ PDF ì—´ê¸° ì‹¤íŒ¨: {e}", level="ERROR")
            return {"full_text": "", "total_pages": 0, "gemini_fallback_used": False}

        # 2. í˜ì´ì§€ë³„ ìˆœíšŒ
        with pdfplumber.open(pdf_path) as pdf:
            for page_idx, page in enumerate(pdf.pages, start=1):
                # A. í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì¶”ì¶œ (ê°€ì¥ ë¹ ë¥´ê³  ì •í™•, 0ì›)
                text = page.extract_text() or ""
                text_length = len(text.strip())

                # B. í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë©´ ì´ë¯¸ì§€ OCR ì‹œë„
                if text_length < self.min_text_length:
                    _log(f"page={page_idx} í…ìŠ¤íŠ¸ ë¶€ì¡±({text_length}ì) -> ì´ë¯¸ì§€ OCR ì‹œë„", level="DEBUG")
                    
                    # (1) ONNX OCR ì‹œë„ + ì´ë¯¸ì§€ ë Œë”ë§
                    ocr_text, pil_img = self._perform_ocr_on_page(pdf_path, page_idx)
                    
                    # ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥
                    self._save_debug_image(pil_img, pdf_path, page_idx)

                    if ocr_text and len(ocr_text) > 50:
                        text = ocr_text
                        ocr_count += 1
                        _log(f"âœ… ONNX OCR ì„±ê³µ ({len(text)}ì)", level="INFO")
                    
                    # (2) ONNX ì‹¤íŒ¨ ì‹œ Gemini Fallback
                    elif self.gemini_ocr_fallback and pil_img is not None:
                        if sample_pages and page_idx in sample_pages:
                            try:
                                buf = io.BytesIO()
                                pil_img.save(buf, format="PNG")
                                gem_text, usage = gemini_ocr_image_bytes(
                                    buf.getvalue(),
                                    language_hint="ko",
                                )
                                self._gemini_ocr_used_pages += 1
                                if gem_text and gem_text.strip():
                                    text = gem_text
                                    ocr_count += 1
                                    _log(f"âœ… Gemini Vision ì„±ê³µ ({len(text)}ì)", level="INFO")
                                else:
                                    _log("âš ï¸ Gemini ê²°ê³¼ ì—†ìŒ", level="WARNING")
                            except Exception as e:
                                _log(f"âš ï¸ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}", level="WARNING")
                        else:
                            self._gemini_ocr_skipped_pages += 1

                # ê²°ê³¼ ì €ì¥
                title = text.split("\n")[0][:50] if text.strip() else f"Page {page_idx}"
                pages_text.append(f"[{prefix}-PAGE {page_idx}: {title}]")
                pages_text.append(text)
                pages_text.append("")

        if ocr_count:
            _log(f"âœ… ì´ OCR ì²˜ë¦¬ í˜ì´ì§€: {ocr_count}", level="INFO")

        return {
            "full_text": "\n".join(pages_text),
            "total_pages": total_pages,
            "gemini_fallback_used": self._gemini_ocr_used_pages > 0,
        }

class ImageDescriptionGenerator:
    """í†µê³¼ëœ ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„± (2-4ë¬¸ì¥)"""
    
    
    def __init__(self):
        """ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.total_tokens = 0  # âœ… ëˆ„ì  í† í° ìˆ˜
        self.description_count = 0  # ìƒì„±í•œ ì„¤ëª… ê°œìˆ˜
        
        # âœ… Gemini ëª¨ë¸ ì´ˆê¸°í™”
        from .improved_hybrid_filter import get_global_model
        self.model = get_global_model()
        
        if self.model is None:
            print("      âš ï¸  Warning: Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ - ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ë¶ˆê°€", level="WARNING")
    def generate_description(
        self, 
        image_bytes: bytes, 
        adjacent_text: str,
        keywords: List[str],
        max_retries=3
    ) -> str:
        """
        Vision APIë¡œ ì´ë¯¸ì§€ ìƒì„¸ ì„¤ëª… ìƒì„±
        ì¬ì‹œë„ ë¡œì§ í¬í•¨ (429 Rate Limit ëŒ€ì‘)
        """
        import time
        
        for attempt in range(max_retries):
            try:
                mime_type = self._get_mime_type(image_bytes)
                image_part = Part.from_data(data=image_bytes, mime_type=mime_type)
                
                keyword_context = ', '.join(keywords[:10]) if keywords else "ì¼ë°˜ í•™ìŠµ ë‚´ìš©"
                
                prompt = f"""
ì´ ì´ë¯¸ì§€ë¥¼ 2-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

ê°•ì˜ ì£¼ì œ: {keyword_context}
ì£¼ë³€ í…ìŠ¤íŠ¸: "{adjacent_text}"

ì„¤ëª…ì— í¬í•¨í•  ë‚´ìš©:
1. ì´ë¯¸ì§€ê°€ ë‚˜íƒ€ë‚´ëŠ” ì£¼ì œ/ê°œë… (1ë¬¸ì¥)
2. ì£¼ìš” êµ¬ì„± ìš”ì†Œ 2-3ê°œ (1-2ë¬¸ì¥)
3. í•µì‹¬ ì •ë³´ë‚˜ íŒ¨í„´ (1ë¬¸ì¥)

ì œì™¸í•  ë‚´ìš©:
- ì„¸ë¶€ ìš”ì†Œ ì „ì²´ ë‚˜ì—´
- ë¶ˆí•„ìš”í•œ ì¶”ì¸¡ì´ë‚˜ í•´ì„

ì¶œë ¥: ëª…í™•í•˜ê³  ê°„ê²°í•œ 2-4ë¬¸ì¥ë§Œ.
"""
                # âœ… Vertex AI model ê°€ì ¸ì˜¤ê¸°
                model = get_global_model()
                if model is None:
                    return "ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: Vertex AI model not initialized"

                response = model.generate_content([image_part, prompt])
                description = response.text.strip()
                
                # âœ… í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (usage_metadata ìš°ì„ )
                tokens_added = 0
                try:
                    # Method 1: response.usage_metadata (ê°€ì¥ ì •í™•)
                    if hasattr(response, 'usage_metadata') and response.usage_metadata:
                        tokens_added = getattr(response.usage_metadata, 'total_token_count', 0)
                        if tokens_added > 0:
                            self.total_tokens += tokens_added
                            self.description_count += 1
                except Exception:
                    pass
                
                return description
                
            except Exception as e:
                error_msg = str(e)
                
                if "429" in error_msg or "Resource exhausted" in error_msg:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 3
                        _log(f"      âš ï¸  Rate Limit, {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘...", level="WARNING", end='', flush=True)
                        time.sleep(wait_time)
                        _log(" ì¬ì‹œë„", level="WARNING")
                        continue
                    else:
                        return "ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: API rate limit exceeded"
                else:
                    return f"ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {error_msg}"
        
        return "ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: Failed after all retries"
    
    def _get_mime_type(self, image_bytes: bytes) -> str:
        """ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ì—ì„œ MIME íƒ€ì… ê°ì§€"""
        if image_bytes.startswith(b'\xff\xd8'):
            return "image/jpeg"
        elif image_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
            return "image/png"
        elif image_bytes.startswith(b'GIF87a') or image_bytes.startswith(b'GIF89a'):
            return "image/gif"
        elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP':
            return "image/webp"
        return "image/png"


class MetadataGenerator:
    """
    ë©”íƒ€ë°ì´í„° ìƒì„± ë…¸ë“œ
    
    ì£¼ê°•ì˜ìë£Œ + ë³´ì¡°ìë£Œ â†’ metadata.json
    """
    
    def __init__(self):
        self.converter = None
        self.text_extractor = TextExtractor()
        self.image_filter = ImprovedHybridFilterPipeline(auto_extract_keywords=True)
        self.image_describer = ImageDescriptionGenerator()
        self.debug = True  # ğŸ”§ DEBUG í•­ìƒ ì¼œê¸° (ì›ì¸ íŒŒì•…ìš©)
            
    def _extract_page_title(self, slide_title: str, adjacent_text: str) -> str:
        """ì˜ë¯¸ìˆëŠ” í˜ì´ì§€ ì œëª© ì¶”ì¶œ"""
        if slide_title and slide_title.strip() and slide_title.lower() != "no title":
            return slide_title.strip()[:50]
        
        if adjacent_text:
            lines = adjacent_text.strip().split('\n')
            for line in lines:
                line = line.strip()
                if len(line) > 3 and not line.startswith('â˜'):
                    return line[:50]
        
        return "í˜ì´ì§€ ì œëª© ì—†ìŒ"
    
    def generate(
        self,
        primary_file: str,
        supplementary_files: Optional[List[str]] = None,
        output_path: str = "output/metadata.json"
    ) -> str:
        """ë©”íƒ€ë°ì´í„° ìƒì„±"""
        _log(f"\n{'='*120}")
        _log(f"ğŸ¯ ë©”íƒ€ë°ì´í„° ìƒì„± ì‹œì‘", level="INFO")
        _log(f"{'='*120}")
        _log(f"ì£¼ê°•ì˜ìë£Œ: {primary_file}", level="INFO")
        if supplementary_files:
            _log(f"ë³´ì¡°ìë£Œ: {len(supplementary_files)}ê°œ")
            for i, supp in enumerate(supplementary_files, 1):
                _log(f"  {i}. {supp}")
        _log(f"{'='*120}\n")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            self.converter = DocumentConverterNode(output_dir=temp_dir)
            
            _log("ğŸ“„ [1/3] ì£¼ê°•ì˜ìë£Œ ì²˜ë¦¬ ì¤‘...", level="INFO")
            primary_metadata = self._process_primary_source(primary_file)
            
            _log("\nğŸ“š [2/3] ë³´ì¡°ìë£Œ ì²˜ë¦¬ ì¤‘...", level="INFO")
            supplementary_metadata = []
            if supplementary_files:
                for i, supp_file in enumerate(supplementary_files[:3], 1):
                    try:
                        supp_meta = self._process_supplementary_source(supp_file, i)
                        supplementary_metadata.append(supp_meta)
                        _log(f"   âœ… ë³´ì¡°ìë£Œ {i} ì²˜ë¦¬ ì„±ê³µ", level="INFO")
                    except Exception as e:
                        _log(f"   âš ï¸ ë³´ì¡°ìë£Œ {i} ì²˜ë¦¬ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}", level="WARNING", exc_info=True)
            else:
                _log("   âš ï¸  ë³´ì¡°ìë£Œ ì—†ìŒ (ì„ íƒ ì‚¬í•­)", level="INFO")
            
            _log("\nğŸ”§ [3/3] ë©”íƒ€ë°ì´í„° í†µí•© ì¤‘...", level="INFO")
            
            # âœ… Vision í† í° í†µê³„ ìˆ˜ì§‘
            vision_tokens = {}
            if hasattr(self.image_filter, 'vision_tokens'):
                vision_tokens = self.image_filter.vision_tokens.copy()
                _log(f"   image_filter.vision_tokens = {vision_tokens}", level="DEBUG")
            
            # âœ… ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± í† í° ì¶”ê°€
            _log(f"   image_describer.total_tokens = {self.image_describer.total_tokens}", level="DEBUG")
            _log(f"   image_describer.description_count = {self.image_describer.description_count}", level="DEBUG")
            
            if self.image_describer.total_tokens > 0:
                vision_tokens['image_description'] = self.image_describer.total_tokens
                vision_tokens['description_count'] = self.image_describer.description_count
                vision_tokens['total'] = vision_tokens.get('total', 0) + self.image_describer.total_tokens
                _log(f"   vision_tokens after adding image_description = {vision_tokens}", level="DEBUG")
            
            # âœ… ë¹„ìš© ê³„ì‚°
            if vision_tokens.get('total', 0) > 0:
                from .pricing import calculate_vision_cost, format_cost
                vision_cost = calculate_vision_cost(vision_tokens['total'])
                vision_tokens['cost_usd'] = vision_cost
            
            metadata = {
                "metadata_version": "1.0",
                "created_at": datetime.now().isoformat(),
                "primary_source": primary_metadata,
                "supplementary_sources": supplementary_metadata
            }
            
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            _log(f"\n{'='*120}")
            _log(f"âœ… ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ!", level="INFO")
            _log(f"{'='*120}")
            _log(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_path}")
            _log(f"ğŸ“Š ì£¼ê°•ì˜ìë£Œ í˜ì´ì§€: {primary_metadata['total_pages']}ê°œ")
            _log(f"ğŸ–¼ï¸  í•„í„°ë§ëœ ì´ë¯¸ì§€: {len(primary_metadata['filtered_images'])}ê°œ")
            if supplementary_metadata:
                total_supp_pages = sum(s['total_pages'] for s in supplementary_metadata)
                _log(f"ğŸ“š ë³´ì¡°ìë£Œ í˜ì´ì§€: {total_supp_pages}ê°œ", level="INFO")
            
            # âœ… Vision í† í° í†µê³„ ì¶œë ¥
            if vision_tokens:
                _log(f"\nğŸ’° Vision API ì‚¬ìš© í†µê³„:", level="INFO")
                if 'keyword_extraction' in vision_tokens:
                    _log(f"   ğŸ“ í‚¤ì›Œë“œ ì¶”ì¶œ: {vision_tokens['keyword_extraction']:,} tokens", level="INFO")
                if 'image_filtering' in vision_tokens:
                    _log(f"   ğŸ” ì´ë¯¸ì§€ í•„í„°ë§: {vision_tokens['image_filtering']:,} tokens", level="INFO")
                if 'image_description' in vision_tokens:
                    _log(f"   ğŸ“¸ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±: {vision_tokens['image_description']:,} tokens ({vision_tokens['description_count']}ê°œ)", level="INFO")
                if 'total' in vision_tokens:
                    _log(f"   ğŸ“Š Total: {vision_tokens['total']:,} tokens", level="INFO")
                if 'cost_usd' in vision_tokens:
                    _log(f"   ğŸ’µ ë¹„ìš©: {format_cost(vision_tokens['cost_usd'])}", level="INFO")
            
            print(f"{'='*120}\n")
            
            # âœ… vision_tokensì™€ í•¨ê»˜ ë°˜í™˜
            return {
                "metadata_path": str(output_path),
                "vision_tokens": vision_tokens
            }
    
    def _process_primary_source(self, file_path: str) -> Dict[str, Any]:
        """
        ì£¼ê°•ì˜ìë£Œ ì²˜ë¦¬
        âœ… TXT/URL ì§€ì› ì¶”ê°€
        âœ… PPTX ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PDF ë³€í™˜ ì—†ì´)
        """
        file_path_str = str(file_path)
        
        # ì›ë³¸ íŒŒì¼ íƒ€ì… ê°ì§€
        if file_path_str.startswith(('http://', 'https://')):
            original_file_type = 'url'
            file_path_obj = None
            display_name = file_path_str[:50]
        else:
            file_path_obj = Path(file_path)
            original_file_type = file_path_obj.suffix.lower().replace('.', '')
            display_name = file_path_obj.name
        
        _log(f"   ğŸ“„ íŒŒì¼: {display_name} ({original_file_type})", level="INFO")
        
        # âœ… PPTXëŠ” ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PDF ë³€í™˜ ì‹œ í•œê¸€ ê¹¨ì§ ë°©ì§€)
        if original_file_type == 'pptx':
            _log(f"   ğŸ“ PPTX ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (PDF ë³€í™˜ ê±´ë„ˆëœ€)", level="INFO")
            from pptx import Presentation
            
            prs = Presentation(file_path_str)
            pages_text = []
            total_pages = 0
            
            for slide_num, slide in enumerate(prs.slides, 1):
                total_pages += 1
                
                # ìŠ¬ë¼ì´ë“œ ì œëª© ì¶”ì¶œ
                title = "No Title"
                if slide.shapes.title and slide.shapes.title.text.strip():
                    title = slide.shapes.title.text.strip()[:50]
                
                # í˜ì´ì§€ ë§ˆì»¤
                pages_text.append(f"[MAIN-PAGE {slide_num}: {title}]")
                
                # ìŠ¬ë¼ì´ë“œ ë‚´ìš© ì¶”ì¶œ
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        pages_text.append(shape.text.strip())
                
                pages_text.append("")  # ìŠ¬ë¼ì´ë“œ êµ¬ë¶„
            
            full_text = "\n".join(pages_text)
            _log(f"   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(full_text)}ì, {total_pages}í˜ì´ì§€", level="INFO")
            
            # ì´ë¯¸ì§€ëŠ” PPTX ì›ë³¸ì—ì„œ ì¶”ì¶œ
            _log(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...", level="INFO")
            _log(f"      â†’ PPTX ì›ë³¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ", level="INFO")
            self.image_filter.extract_keywords_from_document(file_path_str, text=full_text)
            keywords = self.image_filter.document_keywords
            all_images = self._extract_images_from_pptx(file_path_str)
            
        else:
            # ê¸°ì¡´ ë°©ì‹: PDF ë³€í™˜
            _log(f"   ğŸ”„ íŒŒì¼ ì²˜ë¦¬ ì¤‘...", level="INFO")
            processed_path = self.converter.convert(file_path_str)
            
            # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            _log(f"   ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...", level="INFO")
            text_data = self.text_extractor.extract_with_markers(processed_path, prefix="MAIN")
            full_text = text_data['full_text']
            total_pages = text_data['total_pages']
            _log(f"   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(full_text)}ì", level="INFO")
            
            # 3. ì´ë¯¸ì§€ í•„í„°ë§
            # 3. ì´ë¯¸ì§€ í•„í„°ë§
            _log(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...", level="INFO")
            
            # TXT/URLì€ ì´ë¯¸ì§€ ì—†ìŒ
            if original_file_type in ['txt', 'url']:
                _log(f"      â†’ TXT/URLì€ ì´ë¯¸ì§€ ì—†ìŒ, ê±´ë„ˆë›°ê¸°", level="INFO")
                all_images = []
                keywords = []
            
            elif original_file_type in ['docx', 'pdf']:
                _log(f"      â†’ PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ", level="INFO")
                self.image_filter.extract_keywords_from_document(processed_path, text=full_text)
                keywords = self.image_filter.document_keywords
                extractor = UniversalImageExtractor()
                
                # âœ… Gemini Fallback ì‚¬ìš© ì—¬ë¶€ ì „ë‹¬
                gemini_used = text_data.get('gemini_fallback_used', False)
                all_images = extractor.extract(processed_path, skip_ocr=gemini_used)
            
            else:
                _log(f"   âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {original_file_type}", level="WARNING")
                all_images = []
                keywords = []
        
        # 4. í•„í„°ë§ ì‹¤í–‰ (ê³µí†µ)
        filtered_images = []
        if all_images:
            _log(f"   ğŸ” {len(all_images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬, í•„í„°ë§ ì‹œì‘...")

            for img_meta in all_images:
                decision, reason = self.image_filter.step1_rule_check(img_meta)
                
                if decision == "INCLUDE":
                    # âœ… V3: Rule í†µê³¼ë„ AIë¡œ ê²€ì¦ + ì„¤ëª… ìƒì„±
                    result = self.image_filter.unified_vision_check(img_meta)
                    
                    if result["is_core"]:
                        img_meta.is_core_content = True
                        img_meta.description = result["description"] or ""
                        img_meta.filter_reason = f"Rule+AI: {result['reason']}"
                        filtered_images.append(img_meta)
                    
                elif decision == "PENDING":
                    # âœ… V3: unified_vision_check ì‚¬ìš© (í•„í„°ë§ + ì„¤ëª… í†µí•©)
                    result = self.image_filter.unified_vision_check(img_meta)
                    
                    if result["is_core"]:
                        img_meta.is_core_content = True
                        img_meta.description = result["description"] or ""
                        img_meta.filter_reason = result["reason"]
                        filtered_images.append(img_meta)
            
            _log(f"   âœ… í•„í„°ë§ ì™„ë£Œ: {len(filtered_images)}ê°œ ì„ íƒ")
        
        # 5. ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° êµ¬ì„±
        filtered_image_metadata = []
        
        if filtered_images:
            # âœ… V3: ì„¤ëª…ì´ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ (unified_vision_checkì—ì„œ ìƒì„±)
            _log(f"   âœ… ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° êµ¬ì„± ì¤‘... ({len(filtered_images)}ê°œ)", level="INFO")
            
            for i, img_meta in enumerate(filtered_images, 1):
                page_title = self._extract_page_title(
                    img_meta.slide_title,
                    img_meta.adjacent_text
                )
                
                # âœ… descriptionì€ ì´ë¯¸ img_meta.descriptionì— ì¡´ì¬!
                filtered_image_metadata.append({
                    "image_id": img_meta.image_id.replace("S", "MAIN_P").replace("P", "MAIN_P"),
                    "page_number": img_meta.slide_number,
                    "page_title": page_title,
                    "description": img_meta.description or "ì„¤ëª… ì—†ìŒ",  # âœ… ì´ë¯¸ ìƒì„±ë¨
                    "filter_stage": "1ì°¨ (Rule+AI)" if "Rule+AI" in img_meta.filter_reason else "2ì°¨ (AI)",
                    "area_percentage": img_meta.area_percentage
                })
            
            _log(f"   âœ… ë©”íƒ€ë°ì´í„° êµ¬ì„± ì™„ë£Œ: {len(filtered_image_metadata)}ê°œ", level="INFO")
            _log(f"   âš¡ ìµœì í™”: í†µí•© Vision APIë¡œ ì„¤ëª… ìƒì„± ì¤‘ë³µ ì œê±°", level="INFO")

        # 6. í†µê³„
        total_images = len(all_images)
        passed_images = len(filtered_images)
        
        return {
            "role": "main",
            "filename": display_name if original_file_type == 'url' else (file_path_obj.name if file_path_obj else display_name),
            "file_type": original_file_type,
            "total_pages": total_pages,
            "content": {
                "full_text": full_text
            },
            "filtered_images": filtered_image_metadata,
            "statistics": {
                "total_images_found": total_images,
                "images_passed": passed_images,
                "filter_rate": passed_images / total_images if total_images > 0 else 0
            }
        }
    
    def _process_supplementary_source(self, file_path: str, order: int) -> Dict[str, Any]:
        """
        ë³´ì¡°ìë£Œ ì²˜ë¦¬
        âœ… PPTX ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PDF ë³€í™˜ ì—†ì´)
        """
        file_path_str = str(file_path)
        
        # URLê³¼ íŒŒì¼ êµ¬ë¶„
        if file_path_str.startswith(('http://', 'https://')):
            file_type = 'url'
            display_name = 'Web Content'
            file_path_obj = None
        else:
            file_path_obj = Path(file_path)
            file_type = file_path_obj.suffix.lower().replace('.', '')
            display_name = file_path_obj.name
        
        _log(f"   ğŸ“š ë³´ì¡°ìë£Œ {order}: {display_name} ({file_type})")
        
        # âœ… PPTXëŠ” ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PDF ë³€í™˜ ê±´ë„ˆëœ€)
        if file_type == 'pptx':
            print(f"      ğŸ“ PPTX ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (PDF ë³€í™˜ ê±´ë„ˆëœ€)")
            from pptx import Presentation
            
            prs = Presentation(file_path_str)
            pages_text = []
            total_pages = 0
            
            for slide_num, slide in enumerate(prs.slides, 1):
                total_pages += 1
                
                # ìŠ¬ë¼ì´ë“œ ì œëª© ì¶”ì¶œ
                title = "No Title"
                if slide.shapes.title and slide.shapes.title.text.strip():
                    title = slide.shapes.title.text.strip()[:50]
                
                # í˜ì´ì§€ ë§ˆì»¤
                pages_text.append(f"[SUPP{order}-PAGE {slide_num}: {title}]")
                
                # ìŠ¬ë¼ì´ë“œ ë‚´ìš© ì¶”ì¶œ
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        pages_text.append(shape.text.strip())
                
                pages_text.append("")  # ìŠ¬ë¼ì´ë“œ êµ¬ë¶„
            
            full_text = "\n".join(pages_text)
            print(f"      âœ… ì™„ë£Œ ({total_pages}í˜ì´ì§€)")
            
        else:
            # ê¸°ì¡´ ë°©ì‹: PDF ë³€í™˜
            print(f"      ğŸ”„ PDF ë³€í™˜ ì¤‘...")
            pdf_path = self.converter.convert(file_path_str)
            
            print(f"      ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            text_data = self.text_extractor.extract_with_markers(pdf_path, prefix=f"SUPP{order}")
            
            full_text = text_data['full_text']
            total_pages = text_data['total_pages']
            
            print(f"      âœ… ì™„ë£Œ ({total_pages}í˜ì´ì§€)")
        
        return {
            "order": order,
            "filename": display_name,
            "file_type": file_type,
            "total_pages": total_pages,
            "content": {
                "full_text": full_text
            }
        }
    
    def _extract_images_from_pptx(self, pptx_path: str) -> List[ImageMetadata]:
        """PPTXì—ì„œ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        extractor = UniversalImageExtractor()
        return extractor.extract(pptx_path)


# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == "__main__":
    import sys
    
    _log("\n" + "="*120)
    _log("ğŸ¯ Metadata Generator Node (V2 - pdfplumber)")
    _log("="*120)
    
    if len(sys.argv) < 2:
        _log("\nì‚¬ìš©ë²•:")
        _log("  python metadata_generator_node.py <ì£¼ê°•ì˜ìë£Œ> [ë³´ì¡°1] [ë³´ì¡°2] [ë³´ì¡°3]")
        _log("\nì˜ˆì‹œ:")
        _log("  python metadata_generator_node.py ì¤‘ë“±êµ­ì–´1.pptx")
        _log("  python metadata_generator_node.py notes.txt")
        _log("  python metadata_generator_node.py https://example.com/article")
        _log("\nâœ… ì§€ì› í˜•ì‹: PPTX, DOCX, PDF, TXT, URL")
        _log("="*120 + "\n")
        sys.exit(1)
    
    primary_file = sys.argv[1]
    supplementary_files = sys.argv[2:5] if len(sys.argv) > 2 else None
    
    if not primary_file.startswith('http') and not os.path.exists(primary_file):
        _log(f"\nâŒ ì£¼ê°•ì˜ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {primary_file}")
        sys.exit(1)
    
    if supplementary_files:
        for supp in supplementary_files:
            if not supp.startswith('http') and not os.path.exists(supp):
                _log(f"\nâŒ ë³´ì¡°ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {supp}")
                sys.exit(1)
    
    try:
        generator = MetadataGenerator()
        output_path = generator.generate(
            primary_file=primary_file,
            supplementary_files=supplementary_files,
            output_path="output/metadata.json"
        )
        
        _log(f"âœ… ì„±ê³µ!")
        _log(f"ğŸ“ {output_path}")
        
    except Exception as e:
        _log(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)