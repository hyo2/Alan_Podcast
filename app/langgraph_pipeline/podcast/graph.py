# app/langgraph_pipeline/podcast/graph.py

import logging
import json
import os
import uuid
from typing import List, Dict, Any
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from .state import PodcastState
from .metadata_generator_node import MetadataGenerator 
from .script_generator import ScriptGenerator
from .tts_service import TTSService
from .audio_processor import AudioProcessor
from .pricing import format_cost

logger = logging.getLogger(__name__)

def get_temp_output_dir() -> str:
    """í™˜ê²½ì— ë§ëŠ” ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ë°˜í™˜"""
    base = os.getenv("BASE_OUTPUT_DIR", "outputs")
    return base


def extract_texts_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 1: MetadataGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì„¤ëª… ì¶”ì¶œ"""
    logger.info("ë©”íƒ€ë°ì´í„° ìƒì„± ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘...")
    
    main_sources = state.get('main_sources', [])
    aux_sources = state.get('aux_sources', [])
    
    # âœ… V4: ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ì¶”ì¶œ
    session_id = state.get('session_id')
    storage_prefix = state.get('storage_prefix')
    checkpoint_callback = state.get('checkpoint_callback')
    
    if not main_sources:
        return {
            **state,
            "errors": ["ì²˜ë¦¬í•  ì£¼ ì†ŒìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."],
            "current_step": "error"
        }

    try:
        primary_file = main_sources[0]
        supplementary_files = main_sources[1:] + aux_sources
        
        logger.info(f"Primary: {primary_file}, Supp: {len(supplementary_files)}ê°œ")

        # âœ… V4: ì²´í¬í¬ì¸íŠ¸ ì½œë°± ì „ë‹¬
        generator = MetadataGenerator(
            checkpoint_callback=checkpoint_callback,
            checkpoint_interval=5,
        )
        
        #  í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ê²½ë¡œ ì‚¬ìš©
        output_dir = get_temp_output_dir()
        temp_json_path = os.path.join(output_dir, f"temp_metadata_{uuid.uuid4().hex[:8]}.json")
        
        # âœ… V4: session_id, storage_prefix ì „ë‹¬
        generated_path = generator.generate(
            primary_file=primary_file,
            supplementary_files=supplementary_files,
            output_path=temp_json_path,
            session_id=session_id,
            storage_prefix=storage_prefix,
        )
        
        # âœ… Vision í† í° ì •ë³´ ìˆ˜ì§‘
        vision_tokens = {}
        if isinstance(generated_path, dict):
            vision_tokens = generated_path.get("vision_tokens", {})
            generated_path = generated_path.get("metadata_path", generated_path)
        
        with open(generated_path, 'r', encoding='utf-8') as f:
            source_data = json.load(f)
            
        if os.path.exists(generated_path):
            os.remove(generated_path)
        
        main_texts = []
        aux_texts = []
        
        primary = source_data.get("primary_source", {}) 
        if primary and "content" in primary:
            text = primary["content"].get("full_text", "")
            if text:
                images = primary.get("filtered_images", [])
                if images:
                    text += "\n\n=== [VISUAL CONTEXT] (Images in the document) ===\n"
                    for img in images:
                        desc = img.get("description", "")
                        page = img.get("page_number", "?")
                        text += f"- Page {page}: {desc}\n"
                
                main_texts.append(text)

        supp_list = source_data.get("supplementary_sources", [])
        for supp in supp_list:
            text = supp.get("content", {}).get("full_text", "")
            if text:
                aux_texts.append(text)

        logger.info(f"íŒŒì‹± ì™„ë£Œ - Main: {len(main_texts)}ê°œ, Aux: {len(aux_texts)}ê°œ")
        
        # âœ… usageì— vision_tokens ì €ì¥
        current_usage = state.get("usage", {})
        if vision_tokens:
            current_usage["vision"] = vision_tokens
        
        return {
            **state,
            "source_data": source_data,
            "main_texts": main_texts,
            "aux_texts": aux_texts,
            "usage": current_usage,
            "errors": [],
            "current_step": "extract_complete"
        }

    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        return {
            **state,
            "errors": state.get('errors', []) + [f"ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}"],
            "current_step": "error"
        }


def combine_texts_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 2: í…ìŠ¤íŠ¸ êµ¬ì¡°í™” ë° ê²°í•©"""
    logger.info("í…ìŠ¤íŠ¸ êµ¬ì¡°í™” ë° ê²°í•© ì¤‘...")
    
    if not state['main_texts']:
        return {
            **state,
            "errors": state.get('errors', []) + ["ì£¼ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."],
            "current_step": "error"
        }
    
    formatted_text = "=== [MAIN SOURCE] (Core Content) ===\n"
    formatted_text += "The following content is the primary topic. Focus the script on this.\n\n"
    formatted_text += "\n\n---\n\n".join(state['main_texts'])
    
    if state['aux_texts']:
        formatted_text += "\n\n\n=== [AUXILIARY SOURCE] (Reference/Context) ===\n"
        formatted_text += "Use the following content only for supporting details.\n\n"
        formatted_text += "\n\n---\n\n".join(state['aux_texts'])
    
    return {
        **state,
        "combined_text": formatted_text,
        "current_step": "combine_complete"
    }


def generate_script_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 3: ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    logger.info("ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
    try:
        from app.db.db_session import SessionLocal
        if SessionLocal is None:
            raise RuntimeError("DB session factory(SessionLocal)ê°€ ì—†ìŠµë‹ˆë‹¤. DATABASE_URL ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        db = SessionLocal()
        try:
            generator = ScriptGenerator(
                db=db,
                project_id=state['project_id'],
                region=state['region'],
                sa_file=state['sa_file'],
                style=state.get('style', 'explain')
            )
            result = generator.generate_script(
                combined_text=state['combined_text'],
                host_name=state['host_name'],
                guest_name=state['guest_name'],
                duration=state.get('duration', 5),
                difficulty=state.get('difficulty', 'intermediate'),
                user_prompt=state.get('user_prompt', "")
            )
        finally:
            db.close()
        
        new_usage = state.get("usage", {})
        if "usage" in result:
            new_usage.update(result["usage"])

        return {
            **state,
            "title": result.get("title", "Untitled"),
            "script": result.get("script", ""),
            "usage": new_usage,
            "current_step": "script_complete"
        }
    except Exception as e:
        logger.error(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return {**state, "errors": state.get('errors', []) + [str(e)], "current_step": "error"}


def generate_audio_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 4: TTS ë³€í™˜"""
    logger.info("TTS ë³€í™˜ ì¤‘...")
    try:
        tts = TTSService()
        metadata, files = tts.generate_audio(state['script'], state['host_name'], state['guest_name'])
        
        # âœ… TTS/STT í†µê³„ ì •ë³´ ì¶”ì¶œ
        tts_stats = {}
        if metadata and len(metadata) > 0 and '_tts_stats' in metadata[0]:
            tts_stats = metadata[0].pop('_tts_stats')  # metadataì—ì„œ ì œê±°í•˜ê³  stateì— ì¶”ê°€
            print(f"[DEBUG] TTS/STT stats extracted: {tts_stats}")
        else:
            print(f"[DEBUG] No _tts_stats found in metadata")
            if metadata and len(metadata) > 0:
                print(f"[DEBUG] metadata[0] keys: {metadata[0].keys()}")
        
        tts_chars = tts_stats.get('tts_characters', 0)
        stt_secs = tts_stats.get('stt_seconds', 0.0)
        print(f"[DEBUG] tts_characters={tts_chars}, stt_seconds={stt_secs}")
        
        # âœ… usageì— TTS/STT í†µê³„ ì¶”ê°€
        current_usage = state.get("usage", {})
        current_usage["tts_characters"] = tts_chars
        current_usage["stt_seconds"] = stt_secs
        
        new_state = {
            **state, 
            "audio_metadata": metadata, 
            "wav_files": files, 
            "current_step": "audio_complete",
            "usage": current_usage  # âœ… ì—…ë°ì´íŠ¸ëœ usage
        }
        
        print(f"[DEBUG] Returning state with usage={new_state.get('usage')}")
        
        return new_state
    except Exception as e:
        logger.error(f"TTS ì˜¤ë¥˜: {e}")
        return {**state, "errors": state.get('errors', []) + [str(e)], "current_step": "error"}


def merge_audio_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 5: ì˜¤ë””ì˜¤ ë³‘í•©"""
    logger.info("ì˜¤ë””ì˜¤ ë³‘í•© ì¤‘...")
    if not state.get('wav_files'):
         return {**state, "errors": state.get('errors', []) + ["ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ"], "current_step": "error"}
    try:
        processor = AudioProcessor()
        path = processor.merge_audio_files(state['wav_files'])
        return {**state, "final_podcast_path": path, "current_step": "merge_complete"}
    except Exception as e:
        logger.error(f"ë³‘í•© ì˜¤ë¥˜: {e}")
        return {**state, "errors": state.get('errors', []) + [str(e)], "current_step": "error"}


def generate_transcript_node(state: PodcastState) -> PodcastState:
    """ë…¸ë“œ 6: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    logger.info("íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
    try:
        processor = AudioProcessor()
        path = processor.generate_transcript(state['audio_metadata'], state['final_podcast_path'])
        
        # âœ… ìµœì¢… í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„ ì¶œë ¥
        usage = state.get("usage", {})
        
        print("\n" + "="*60)
        print("ğŸ‰ íŒŸìºìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ!")
        print("="*60)
        
        if usage:
            from .pricing import calculate_llm_cost, calculate_vision_cost, get_pricing
            
            print("\n" + "="*60)
            print("ğŸ’° ìµœì¢… ë¹„ìš© ìš”ì•½")
            print("="*60)
            print("\nğŸ“Š í•­ëª©ë³„ ìƒì„¸:\n")
            
            total_cost_usd = 0.0
            pricing = get_pricing()
            
            # ====================================
            # LLM (ìŠ¤í¬ë¦½íŠ¸ ìƒì„±)
            # ====================================
            llm_usage = usage.get("script_generation", {})
            if llm_usage:
                attempts = llm_usage.get('attempts', 0)
                attempts_detail = llm_usage.get('attempts_detail', [])
                total_input = llm_usage.get('input_tokens', 0)
                total_output = llm_usage.get('output_tokens', 0)
                
                print(f"ğŸ’¬ LLM (ìŠ¤í¬ë¦½íŠ¸ ìƒì„±) - {attempts}íšŒ ì‹œë„")
                
                # Input ìƒì„¸
                if attempts_detail:
                    input_parts = []
                    input_costs = []
                    for detail in attempts_detail:
                        attempt_num = detail['attempt']
                        input_tok = detail['input_tokens']
                        input_parts.append(f"{input_tok:,} ({attempt_num}ì°¨)")
                        input_cost = input_tok * pricing['llm_input']
                        input_costs.append(f"${input_cost:.4f}")
                    
                    print(f"   Input:  " + " + ".join(input_parts) + f" = {total_input:,} tokens")
                    print(f"          " + "   + ".join(input_costs) + f" = ${sum([d['input_tokens'] * pricing['llm_input'] for d in attempts_detail]):.4f}")
                    print()
                    
                    # Output ìƒì„¸
                    output_parts = []
                    output_costs = []
                    for detail in attempts_detail:
                        attempt_num = detail['attempt']
                        output_tok = detail['output_tokens']
                        output_parts.append(f"{output_tok:,} ({attempt_num}ì°¨)")
                        output_cost = output_tok * pricing['llm_output']
                        output_costs.append(f"${output_cost:.4f}")
                    
                    print(f"   Output: " + " + ".join(output_parts) + f" = {total_output:,} tokens")
                    print(f"          " + "   + ".join(output_costs) + f" = ${sum([d['output_tokens'] * pricing['llm_output'] for d in attempts_detail]):.4f}")
                else:
                    # attempts_detail ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
                    print(f"   Input:  {total_input:,} tokens (${total_input * pricing['llm_input']:.4f})")
                    print(f"   Output: {total_output:,} tokens (${total_output * pricing['llm_output']:.4f})")
                
                llm_cost = calculate_llm_cost(total_input, total_output)
                total_cost_usd += llm_cost
                print(f"\n   ì†Œê³„: {format_cost(llm_cost)}")
                print()
            
            # ====================================
            # Vision (ì´ë¯¸ì§€ í•„í„°ë§ + ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±)
            # ====================================
            vision_usage = usage.get("vision", {})
            if vision_usage:
                keyword_tokens = vision_usage.get("keyword_extraction", 0)
                image_tokens = vision_usage.get("image_filtering", 0)
                description_tokens = vision_usage.get("image_description", 0)  # âœ… ì´ë¯¸ì§€ ì„¤ëª…
                vision_total = vision_usage.get("total", 0)
                vision_cost = vision_usage.get('cost_usd', 0.0)
                total_cost_usd += vision_cost
                
                print(f"ğŸ‘ï¸  Vision (ì´ë¯¸ì§€ ì²˜ë¦¬)")
                print(f"   í‚¤ì›Œë“œ ì¶”ì¶œ: {keyword_tokens:,} tokens (${keyword_tokens * pricing['vision']:.4f})")
                # âœ… ì´ë¯¸ì§€ ê°œìˆ˜ í‘œì‹œ
                images_analyzed = vision_usage.get("images_analyzed", 0)
                if images_analyzed > 0:
                    print(f"   ì´ë¯¸ì§€ ë¶„ì„:  {image_tokens:,} tokens ({images_analyzed}ê°œ ì´ë¯¸ì§€) (${image_tokens * pricing['vision']:.4f})")
                else:
                    print(f"   ì´ë¯¸ì§€ ë¶„ì„:  {image_tokens:,} tokens (${image_tokens * pricing['vision']:.4f})")
                # âœ… ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± í† í° ì¶œë ¥
                if description_tokens > 0:
                    description_count = vision_usage.get("description_count", 0)
                    print(f"   ì´ë¯¸ì§€ ì„¤ëª…:  {description_tokens:,} tokens (${description_tokens * pricing['vision']:.4f}) - {description_count}ê°œ")
                print(f"\n   ì†Œê³„: {format_cost(vision_cost)}")
                print()
            
            # ====================================
            # TTS / STT (usageì—ì„œ ê°€ì ¸ì˜¤ê¸°)
            # ====================================
            tts_chars = usage.get('tts_characters', 0)
            stt_seconds = usage.get('stt_seconds', 0.0)
            
            if tts_chars > 0 or stt_seconds > 0:
                from .pricing import calculate_tts_cost, calculate_stt_cost
                
                if tts_chars > 0:
                    tts_cost = calculate_tts_cost(tts_chars)
                    total_cost_usd += tts_cost
                    print(f"ğŸ™ï¸  TTS (ìŒì„± í•©ì„±)")
                    print(f"   ë¬¸ì: {tts_chars:,}ì")
                    print(f"\n   ì†Œê³„: {format_cost(tts_cost)}")
                    print()
                
                if stt_seconds > 0:
                    stt_cost = calculate_stt_cost(stt_seconds)
                    total_cost_usd += stt_cost
                    print(f"ğŸ§ STT (ìŒì„± ì¸ì‹)")
                    print(f"   ì‹œê°„: {stt_seconds:.2f}ì´ˆ")
                    print(f"\n   ì†Œê³„: {format_cost(stt_cost)}")
                    print()
            else:
                print(f"âš ï¸  TTS/STT ë¹„ìš© ì •ë³´ê°€ stateì— ì—†ìŠµë‹ˆë‹¤.")
                print(f"   tail_focus_v5_fixed.pyì˜ ì„±ëŠ¥ ì¸¡ì • ì„¹ì…˜ì„ ì°¸ê³ í•˜ì„¸ìš”.")
                print()
            
            # ====================================
            # ì´í•©
            # ====================================
            print("="*60)
            print(f"ğŸ’µ ì´ ë¹„ìš©: {format_cost(total_cost_usd)}")
            print("="*60)
            
        print()
        
        return {**state, "transcript_path": path, "current_step": "complete"}
    except Exception as e:
        logger.error(f"íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜: {e}")
        return {**state, "errors": state.get('errors', []) + [str(e)], "current_step": "error"}

def _should_end(state: PodcastState) -> bool:
    # errorsê°€ ìˆê±°ë‚˜ current_stepì´ errorë©´ ì¦‰ì‹œ ì¤‘ë‹¨
    if state.get("current_step") == "error":
        return True
    errs = state.get("errors") or []
    return len(errs) > 0


def _route_after_extract(state: PodcastState):
    return END if _should_end(state) else "combine_texts"


def _route_after_combine(state: PodcastState):
    return END if _should_end(state) else "generate_script"


def _route_after_script(state: PodcastState):
    return END if _should_end(state) else "generate_audio"


def _route_after_audio(state: PodcastState):
    return END if _should_end(state) else "merge_audio"


def _route_after_merge(state: PodcastState):
    return END if _should_end(state) else "generate_transcript"


def _route_after_transcript(state: PodcastState):
    return END  # ë§ˆì§€ë§‰ì€ ë¬´ì¡°ê±´ ì¢…ë£Œ


def create_podcast_graph():
    """LangGraph ê·¸ë˜í”„ ì •ì˜ (ì—ëŸ¬ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ)"""
    workflow = StateGraph(PodcastState)

    workflow.add_node("extract_texts", extract_texts_node)
    workflow.add_node("combine_texts", combine_texts_node)
    workflow.add_node("generate_script", generate_script_node)
    workflow.add_node("generate_audio", generate_audio_node)
    workflow.add_node("merge_audio", merge_audio_node)
    workflow.add_node("generate_transcript", generate_transcript_node)

    workflow.set_entry_point("extract_texts")

    # ë‹¨ê³„ë³„ conditional routing
    workflow.add_conditional_edges("extract_texts", _route_after_extract)
    workflow.add_conditional_edges("combine_texts", _route_after_combine)
    workflow.add_conditional_edges("generate_script", _route_after_script)
    workflow.add_conditional_edges("generate_audio", _route_after_audio)
    workflow.add_conditional_edges("merge_audio", _route_after_merge)
    workflow.add_conditional_edges("generate_transcript", _route_after_transcript)

    return workflow.compile(checkpointer=MemorySaver())


def run_podcast_generation(
    main_sources: List[str],       
    aux_sources: List[str],        
    project_id: str,
    region: str,
    sa_file: str,
    host_name: str = None,
    guest_name: str = None,
    style: str = "explain",
    duration: int = 5,
    difficulty: str = "intermediate",
    user_prompt: str = ""
) -> Dict[str, Any]:
    """íŒŸìºìŠ¤íŠ¸ ìƒì„± ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if not project_id:
        raise ValueError("Google Cloud Project IDë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤")

    host = host_name if host_name else "ì§„í–‰ì"
    guest = guest_name if guest_name else "ê²ŒìŠ¤íŠ¸"

    logger.info(f"ì§„í–‰ì: {host}, ê²ŒìŠ¤íŠ¸: {guest}")
    logger.info(f"ì„¤ì • - ìŠ¤íƒ€ì¼: {style}, ì‹œê°„: {duration}ë¶„, ë‚œì´ë„: {difficulty}")

    initial_state = {
        "main_sources": main_sources,
        "aux_sources": aux_sources,
        "source_data": {}, 
        "main_texts": [],
        "aux_texts": [],
        "combined_text": "",
        "script": "",
        "audio_metadata": [],
        "wav_files": [],
        "final_podcast_path": "",
        "transcript_path": "",
        "errors": [],
        "current_step": "start",
        "project_id": project_id,
        "region": region,
        "sa_file": sa_file,
        "host_name": host,
        "guest_name": guest,
        "style": style,
        "duration": duration,
        "difficulty": difficulty,
        "user_prompt": user_prompt
    }

    app = create_podcast_graph()
    config = {"configurable": {"thread_id": f"podcast_generation_{id(initial_state)}"}}

    logger.info("LangGraph ì›Œí¬í”Œë¡œìš° ì‹œì‘...")

    try:
        final_state = app.invoke(initial_state, config)
        
        if final_state.get('errors'):
            logger.warning(f"ì˜¤ë¥˜ ë°œìƒ: {final_state['errors']}")
        
        if final_state.get('final_podcast_path'):
            return {
                "final_podcast_path": final_state['final_podcast_path'],
                "transcript_path": final_state.get('transcript_path', ''),
                "errors": final_state.get('errors', []),
                "host_name": host,
                "guest_name": guest
            }
        else:
            raise RuntimeError(f"ì‹¤íŒ¨: {final_state.get('errors')}")
            
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
        raise