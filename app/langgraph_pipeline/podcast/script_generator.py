# app/langgraph_pipeline/podcast/script_generator.py
import os
import re
import logging

from google.oauth2 import service_account
from vertexai.generative_models import GenerativeModel
import vertexai

from .script.parsing import extract_json_from_llm, extract_title_fallback
from .script.cleanup import clean_script
from .script.validation import is_script_truncated, measure
from .script.prompt_builder import create_prompt
from .script.options_parser import parse_user_prompt_overrides, apply_overrides
from .script.compression import compress_script_once
from .script.postprocess import hard_cap_fallback, continue_script_fallback, expand_script_fallback, expand_middle_content
from .script.structure_analyzer import analyze_script_structure
from .utils import target_char_budget
from .pricing import calculate_llm_cost, format_cost

from sqlalchemy.orm import Session
from .prompt_service import PromptTemplateService
 
logger = logging.getLogger(__name__)

def get_tolerance_ratios(budget: int, duration_min: float) -> tuple:
    """
    durationë³„ ì ˆëŒ€ ì‹œê°„(Â±1ë¶„) ê¸°ë°˜ tolerance ratio ê³„ì‚°
    
    ëª©í‘œ:
    - 5ë¶„:  Â±45ì´ˆ í—ˆìš©
    - 10ë¶„: Â±45ì´ˆ í—ˆìš©
    - 15ë¶„: Â±60ì´ˆ í—ˆìš©
    
    Returns:
        (min_ratio, max_ratio): budget ëŒ€ë¹„ ë¹„ìœ¨
    """
    chars_per_sec = 470 / 60  # ì‹¤ì œ ë°œí™” ì†ë„ ê¸°ì¤€ (7.83ì/ì´ˆ)
    
    if duration_min <= 7:
        # 5ë¶„: Â±45ì´ˆ
        tolerance_chars = int(45 * chars_per_sec)  # Â±352ì
    elif duration_min <= 12:
        # 10ë¶„: Â±45ì´ˆ
        tolerance_chars = int(45 * chars_per_sec)  # Â±352ì
    else:
        # 15ë¶„ ì´ìƒ: Â±60ì´ˆ
        tolerance_chars = int(60 * chars_per_sec)  # Â±470ì
    
    min_chars = budget - tolerance_chars
    max_chars = budget + tolerance_chars
    
    min_ratio = min_chars / budget
    max_ratio = max_chars / budget
    
    return min_ratio, max_ratio

def _build_structured_padding_prompt(is_dialogue: bool, min_add_chars: int, speaker_b_label: str = "í•™ìƒ") -> str:
    """
    ë¶„ëŸ‰ì´ í¬ê²Œ ë¶€ì¡±í•  ë•Œ, ê¸¸ì´ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì±„ìš°ê¸° ìœ„í•œ 'êµ¬ì¡°í™” íŒ¨ë”©' í”„ë¡¬í”„íŠ¸.
    - ë‹¨ìˆœ ì´ì–´ì“°ê¸°ë³´ë‹¤ í›¨ì”¬ ì¬í˜„ì„±ì´ ë†’ìŒ
    """
    min_add_chars = max(400, int(min_add_chars))
    
    # ============================================================
    # âœ… ë§ˆí¬ì—… ê¸ˆì§€ ê·œì¹™ (ê³µí†µ)
    # ============================================================
    markup_rules = """
**CRITICAL - ë§ˆí¬ì—… ê¸ˆì§€:**
âŒ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€: (MAIN-PAGE X), (PAGE X), (VISUAL CONTEXT: ...), (IMG X) ë“±
âœ… ëŒ€ì‹  ì‚¬ìš©: "í™”ë©´ì— ë³´ì´ëŠ”", "ìŠ¬ë¼ì´ë“œ", "êµì¬ Xí˜ì´ì§€" ë“± ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
"""
    
    if is_dialogue:
        return f"""
ë„ˆëŠ” ëŒ€í™”í˜• ìˆ˜ì—… íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ê°€ë‹¤.
ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ ë’¤ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ, ë¶„ëŸ‰ì„ ì±„ìš°ëŠ” **ì¶”ê°€ ëŒ€í™”**ë¥¼ ì‘ì„±í•˜ë¼.

í•„ìˆ˜ êµ¬ì„±(ìˆœì„œëŒ€ë¡œ):
1) ã€Œì„ ìƒë‹˜ã€ 3ì¤„ ìš”ì•½
2) ã€Œ{speaker_b_label}ã€ ìš”ì•½ ê¸°ë°˜ ì§ˆë¬¸ 2ê°œ(ì„œë¡œ ë‹¤ë¥¸ í¬ì¸íŠ¸)
3) ã€Œì„ ìƒë‹˜ã€ ë‹µë³€ + ì˜ˆì‹œ 2ê°œ(í˜„ì‹¤/í•™êµ ì‚¬ë¡€)
4) í€´ì¦ˆ 3ê°œ(OX/ê°ê´€ì‹) â†’ ã€Œ{speaker_b_label}ã€ ë‹µ â†’ ã€Œì„ ìƒë‹˜ã€ í•´ì„¤
5) ì ìš© í™œë™ 1ê°œ ì œì•ˆ
6) ë§ˆë¬´ë¦¬(ë‹¤ìŒ ì‹œê°„ ì˜ˆê³  + ì¸ì‚¬) â€” ì¸ì‚¬ëŠ” 1íšŒë§Œ

{markup_rules}

ê·œì¹™:
- í™”ì íƒœê·¸ëŠ” ë°˜ë“œì‹œ ã€Œì„ ìƒë‹˜ã€: / ã€Œ{speaker_b_label}ã€: ë§Œ ì‚¬ìš©
- ì¤‘ë³µ ê°ì‚¬/ì¸ì‚¬ ê¸ˆì§€(ì¸ì‚¬ 1íšŒ)
- ìµœì†Œ {min_add_chars}ì ì´ìƒ ì¶”ê°€

ì¶”ê°€ ìŠ¤í¬ë¦½íŠ¸ë§Œ ì¶œë ¥í•´ë¼.
""".strip()
    else:
        return f"""
ë„ˆëŠ” ê°•ì˜í˜•(ì„ ìƒë‹˜ ë‹¨ë…) ìˆ˜ì—… íŒŸìºìŠ¤íŠ¸ ì›ê³  ì‘ê°€ë‹¤.
ì•„ë˜ ì›ê³  ë’¤ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ, ë¶„ëŸ‰ì„ ì±„ìš°ëŠ” **ì¶”ê°€ ê°•ì˜**ë¥¼ ì‘ì„±í•˜ë¼.

í•„ìˆ˜ êµ¬ì„±(ìˆœì„œëŒ€ë¡œ):
1) 3ì¤„ ìš”ì•½
2) í•µì‹¬ ê°œë… 5ê°œ ì •ì˜
3) ì ìš© ì˜ˆì‹œ 2ê°œ
4) í€´ì¦ˆ 3ê°œ(OX/ê°ê´€ì‹) + í•´ì„¤
5) ì ìš© í™œë™ 1ê°œ
6) ë§ˆë¬´ë¦¬(ë‹¤ìŒ ì‹œê°„ ì˜ˆê³  + ì¸ì‚¬) â€” ì¸ì‚¬ëŠ” 1íšŒë§Œ

{markup_rules}

ê·œì¹™:
- ìµœì†Œ {min_add_chars}ì ì´ìƒ ì¶”ê°€
- ë ë¬¸ì¥ì€ ì™„ê²°í˜•ìœ¼ë¡œ ë§ˆë¬´ë¦¬

ì¶”ê°€ ì›ê³ ë§Œ ì¶œë ¥í•´ë¼.
""".strip()

def _enforce_length_with_retries(
    *,
    model,
    base_prompt: str,
    extract_text_fn,
    measure_fn,
    min_chars: int,
    max_chars: int,
    max_tries: int = 3,
    max_output_tokens: int = 4096,
) -> str:
    """
    LLM ì¶œë ¥ì´ [min_chars, max_chars] ë²”ìœ„ë¥¼ ë§Œì¡±í•  ë•Œê¹Œì§€ ì¬ì‹œë„.
    - ì‹¤íŒ¨í•˜ë”ë¼ë„ ë§ˆì§€ë§‰ ê²°ê³¼ë¥¼ ë°˜í™˜(ìƒìœ„ ë¡œì§ì—ì„œ ì¶”ê°€ ì²˜ë¦¬)
    """
    last_text = ""
    for i in range(max_tries):
        prompt = base_prompt
        if i > 0:
            prompt += (
                f"\n\n[í”¼ë“œë°±] ì§ì „ ì¶œë ¥ì´ ê¸¸ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. "
                f"ë°˜ë“œì‹œ {min_chars}~{max_chars}ì ë²”ìœ„ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”."
            )
        resp = model.generate_content(
            prompt,
            generation_config={"max_output_tokens": max_output_tokens, "temperature": 0.2 if i > 0 else 0.3},
        )
        text = (extract_text_fn(resp) or "").strip()
        last_text = text
        n = measure_fn(text) if text else 0
        if min_chars <= n <= max_chars:
            return text
    return last_text


def _generate_with_retry(
    *,
    model,
    combined_text: str,
    host_name: str,
    guest_name: str,
    duration_min: float,
    difficulty: str,
    user_prompt: str,
    budget: int,
    style: str,
    user_prompt_template: str,
    speaker_a_label: str,
    speaker_b_label: str,
    extract_text_fn,
    max_attempts: int = 4,
    target_min_ratio: float = 0.85,
    target_max_ratio: float = 1.2,
    max_output_tokens: int = 8192,
) -> tuple:
    """ì¬ìƒì„± ê¸°ë°˜ ê¸¸ì´ ì¡°ì •
    
    Returns:
        tuple: (title, script_text, candidates_history, usage_metadata)
    """
    import time
    
    
    # âœ… í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
    total_input_tokens = 0
    total_output_tokens = 0
    total_tokens = 0
    attempts_detail = []  # âœ… ì‹œë„ë³„ ìƒì„¸ ë‚´ì—­
    
    candidates = []
    
    for attempt in range(1, max_attempts + 1):
        # ì¬ìƒì„± ì •ë³´ êµ¬ì„±
        if attempt == 1:
            retry_info = None
            logger.info(f"[1ì°¨ ìƒì„± ì‹œì‘] ëª©í‘œ: {budget}ì")
        else:
            # âœ… candidatesê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¬ì‹œë„ ì •ë³´ ì—†ì´ ì§„í–‰
            if not candidates:
                retry_info = None
                logger.warning(f"[{attempt}ì°¨ ì‹œì‘] ì´ì „ ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨ - ì¬ì‹œë„ ì •ë³´ ì—†ì´ ì§„í–‰")
            else:
                prev_script, prev_ratio, _ = candidates[-1]
                prev_len = measure(prev_script)
                
                if prev_ratio > target_max_ratio:
                    status = 'TOO_LONG'
                elif prev_ratio < target_min_ratio:
                    status = 'TOO_SHORT'
                else:
                    status = 'IN_RANGE'
                
                retry_info = {
                    'attempt': attempt,
                    'prev_len': prev_len,
                    'prev_ratio': prev_ratio,
                    'status': status,
                }
                
                logger.info(
                    f"[{attempt}ì°¨ ì¬ìƒì„± ì‹œì‘] ì´ì „: {prev_len}ì ({prev_ratio:.1%}), "
                    f"ìƒíƒœ: {status}"
                )
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = create_prompt(
            combined_text=combined_text,
            host_name=host_name,
            guest_name=guest_name,
            duration=duration_min,
            difficulty=difficulty,
            user_prompt=user_prompt,
            budget=budget,
            style=style,
            user_prompt_template=user_prompt_template,
            speaker_a_label=speaker_a_label,
            speaker_b_label=speaker_b_label,
            retry_info=retry_info,
        )
        
        # ============================================================
        # âœ… ë§ˆí¬ì—… ê¸ˆì§€ ê·œì¹™ ì¶”ê°€ (TTS ë¶€ìì—°ìŠ¤ëŸ¬ì›€ ë°©ì§€)
        # ============================================================
        markup_prevention = """

**CRITICAL - í˜•ì‹ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**
"""
        
        if style == "lecture":
            markup_prevention += """
1. âœ… ê° ë°œí™”ë§ˆë‹¤ ë°˜ë“œì‹œ ã€Œì„ ìƒë‹˜ã€: íƒœê·¸ë¡œ ì‹œì‘
2. âœ… ëª¨ë“  ì¤„ì€ ã€Œì„ ìƒë‹˜ã€: ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤
3. âœ… í•œ ë°œí™”ëŠ” 100-300ìë¡œ ì œí•œ
4. âŒ ì¤„ë°”ê¿ˆë§Œìœ¼ë¡œ ë°œí™”ë¥¼ êµ¬ë¶„í•˜ì§€ ë§ˆì„¸ìš”
"""
        else:
            markup_prevention += f"""
1. âœ… ê° ë°œí™”ë§ˆë‹¤ ë°˜ë“œì‹œ í™”ì íƒœê·¸ë¡œ ì‹œì‘
2. âœ… ã€Œì„ ìƒë‹˜ã€: ë˜ëŠ” ã€Œ{speaker_b_label}ã€:
3. âœ… í•œ ë°œí™”ëŠ” 100-300ìë¡œ ì œí•œ
4. âŒ ì¤„ë°”ê¿ˆë§Œìœ¼ë¡œ ë°œí™”ë¥¼ êµ¬ë¶„í•˜ì§€ ë§ˆì„¸ìš”
"""
        
        markup_prevention += """

**CRITICAL - ë§ˆí¬ì—… ê¸ˆì§€ (ë§¤ìš° ì¤‘ìš”!):**
âŒ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€: (MAIN-PAGE X), (PAGE X), (VISUAL CONTEXT: ...), (IMG X), (Figure X), (í‘œ X), (ê·¸ë¦¼ X) ë“± ê´„í˜¸ ì•ˆì˜ ë©”íƒ€ë°ì´í„°
âœ… ëŒ€ì‹  ì‚¬ìš©: "í™”ë©´ì— ë³´ì´ëŠ”", "ìŠ¬ë¼ì´ë“œ", "êµì¬ Xí˜ì´ì§€", "í‘œë¥¼ ë³´ë©´" ë“± ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„

**ì´ìœ :** ê´„í˜¸ ì•ˆì˜ ë§ˆí¬ì—…ì€ TTSê°€ "ë©”ì¸ í˜ì´ì§€ íˆ¬", "ë¹„ì£¼ì–¼ ì»¨í…ìŠ¤íŠ¸" ë“±ìœ¼ë¡œ ì½ì–´ì„œ ì˜¤ë””ì˜¤ê°€ ë¶€ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.

**ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:**
âœ… ì¢‹ìŒ: "ìŒìš´ì€ ì¤‘ìš”í•©ë‹ˆë‹¤"
âœ… ì¢‹ìŒ: "êµì¬ 2í˜ì´ì§€ì— ë‚˜ì˜¨ ê²ƒì²˜ëŸ¼, ìŒìš´ì€ ì¤‘ìš”í•©ë‹ˆë‹¤"
âœ… ì¢‹ìŒ: "í™”ë©´ì— ë³´ì´ëŠ” ë°œìŒ ê¸°ê´€ ê·¸ë¦¼ì²˜ëŸ¼, ììŒì€..."
âœ… ì¢‹ìŒ: "ìŠ¬ë¼ì´ë“œì˜ í‘œë¥¼ ë³´ì‹œë©´ ììŒ ì²´ê³„ë¥¼ í•œëˆˆì— ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

**ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ ê¸ˆì§€):**
âŒ ë‚˜ì¨: "ìŒìš´ì€ (MAIN-PAGE 2) ì¤‘ìš”í•©ë‹ˆë‹¤"
âŒ ë‚˜ì¨: "(VISUAL CONTEXT: ë°œìŒ ê¸°ê´€) ììŒì€..."
âŒ ë‚˜ì¨: "ì, ì´ì œ (PAGE 5) ë„˜ì–´ê°€ë´…ì‹œë‹¤"
"""

        if style == "lecture":
            markup_prevention += """
âŒ ë‚˜ì¨: ã€Œì„ ìƒë‹˜ã€: ì•ˆë…•í•˜ì„¸ìš”!
        ì˜¤ëŠ˜ì€ ìŒìš´ì—...  â† íƒœê·¸ ì—†ìŒ (ê¸ˆì§€!)
"""
        
        markup_prevention += """

**ì°¸ê³ :** ì‹œì²­ê° ìë£Œ ì–¸ê¸‰ì€ ììœ ë¡­ê²Œ í•˜ë˜, ê´„í˜¸ ë§ˆí¬ì—…ë§Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        prompt += markup_prevention
        
        # LLM í˜¸ì¶œ
        generation_config = {
            "max_output_tokens": max_output_tokens,
            "temperature": 0.7 if attempt == 1 else 0.5,
        }
        
        # âœ… 429 ì—ëŸ¬ ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3ë²ˆ)
        max_retries_for_429 = 3
        for retry_429 in range(max_retries_for_429):
            try:
                response = model.generate_content(prompt, generation_config=generation_config)
                
                # âœ… ì‹œë„ë³„ ìƒì„¸ í† í° ë¡œê¹…
                if hasattr(response, 'usage_metadata'):
                    usage = response.usage_metadata
                    
                    # í† í° ëˆ„ì 
                    total_input_tokens += usage.prompt_token_count
                    total_output_tokens += usage.candidates_token_count
                    total_tokens += usage.total_token_count
                    
                    # âœ… ì‹œë„ë³„ ìƒì„¸ ë‚´ì—­ ì €ì¥
                    attempts_detail.append({
                        "attempt": attempt,
                        "input_tokens": usage.prompt_token_count,
                        "output_tokens": usage.candidates_token_count,
                        "total_tokens": usage.total_token_count
                    })
                    
                    # loggerì™€ print ë‘˜ ë‹¤ ì‚¬ìš©
                    logger.info(f"ğŸ“ ì‹œë„ {attempt}/{max_attempts}:")
                    logger.info(f"   Input:  {usage.prompt_token_count:,} tokens")
                    logger.info(f"   Output: {usage.candidates_token_count:,} tokens")
                    logger.info(f"   Total:  {usage.total_token_count:,} tokens")
                    
                    print(f"ğŸ“ ì‹œë„ {attempt}/{max_attempts}:")
                    print(f"   Input:  {usage.prompt_token_count:,} tokens")
                    print(f"   Output: {usage.candidates_token_count:,} tokens")
                    print(f"   Total:  {usage.total_token_count:,} tokens")
                
                raw_text = extract_text_fn(response).strip()
                
                if not raw_text:
                    logger.warning(f"[{attempt}ì°¨ ì‹¤íŒ¨] ë¹ˆ ì‘ë‹µ")
                    break  # 429 ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ, ë‹¤ìŒ attemptë¡œ
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    from .script.parsing import extract_json_from_llm
                    data = extract_json_from_llm(raw_text)
                    title = data.get("title", "ì œëª© ì—†ìŒ").strip()
                    script_text = data.get("script", "").strip()
                except Exception:
                    from .script.parsing import extract_title_fallback
                    title = extract_title_fallback(raw_text) or "ìë™ ìƒì„±ëœ íŒŸìºìŠ¤íŠ¸"
                    script_text = clean_script(raw_text)
                
                script_text = clean_script(script_text)
                
                # ê¸¸ì´ ì¸¡ì •
                current_len = measure(script_text)
                ratio = current_len / budget
                
                candidates.append((script_text, ratio, title))
                
                # âœ… ìƒì„¸ ê²°ê³¼ ë¡œê¹…
                logger.info(f"   ê²°ê³¼: {current_len:,}ì / ëª©í‘œ {budget:,}ì ({ratio:.1%})")
                logger.info(f"   ëª©í‘œ ë²”ìœ„: {target_min_ratio:.1%}~{target_max_ratio:.1%}")
                
                print(f"   ê²°ê³¼: {current_len:,}ì / ëª©í‘œ {budget:,}ì ({ratio:.1%})")
                print(f"   ëª©í‘œ ë²”ìœ„: {target_min_ratio:.1%}~{target_max_ratio:.1%}")
                
                # ì¡´ì¹˜ ë²”ìœ„ ì§„ì… ì‹œ ì¦‰ì‹œ ì±„íƒ
                if target_min_ratio <= ratio <= target_max_ratio:
                    logger.info(f"   âœ… ì„±ê³µ! ëª©í‘œ ë²”ìœ„ ì§„ì… - ì¦‰ì‹œ ì±„íƒ")
                    print(f"   âœ… ì„±ê³µ! ëª©í‘œ ë²”ìœ„ ì§„ì… - ì¦‰ì‹œ ì±„íƒ")
                    # âœ… early returnë„ usage_metadata í¬í•¨
                    usage_metadata = {
                        "input_tokens": total_input_tokens,
                        "output_tokens": total_output_tokens,
                        "total_tokens": total_tokens,
                        "attempts": attempt,
                        "attempts_detail": attempts_detail  # âœ… ì‹œë„ë³„ ìƒì„¸ ë‚´ì—­
                    }
                    
                    # ìµœì¢… ìš”ì•½
                    logger.info(f"\nğŸ’° LLM í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½:")
                    logger.info(f"   ì´ ì‹œë„: {attempt}íšŒ")
                    logger.info(f"   Input:  {total_input_tokens:,} tokens")
                    logger.info(f"   Output: {total_output_tokens:,} tokens")
                    logger.info(f"   Total:  {total_tokens:,} tokens")
                    
                    print(f"\nğŸ’° LLM í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½:")
                    print(f"   ì´ ì‹œë„: {attempt}íšŒ")
                    print(f"   Input:  {total_input_tokens:,} tokens")
                    print(f"   Output: {total_output_tokens:,} tokens")
                    print(f"   Total:  {total_tokens:,} tokens")
                    
                    return title, script_text, candidates, usage_metadata
                else:
                    if ratio < target_min_ratio:
                        logger.info(f"   âŒ ì‹¤íŒ¨: ê¸¸ì´ ë¶€ì¡± ({ratio:.1%} < {target_min_ratio:.1%})")
                        print(f"   âŒ ì‹¤íŒ¨: ê¸¸ì´ ë¶€ì¡± ({ratio:.1%} < {target_min_ratio:.1%})")
                    else:
                        logger.info(f"   âŒ ì‹¤íŒ¨: ê¸¸ì´ ì´ˆê³¼ ({ratio:.1%} > {target_max_ratio:.1%})")
                        print(f"   âŒ ì‹¤íŒ¨: ê¸¸ì´ ì´ˆê³¼ ({ratio:.1%} > {target_max_ratio:.1%})")
                
                # ì„±ê³µí–ˆìœ¼ë©´ 429 ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                break
                
            except Exception as e:
                error_str = str(e)
                
                # âœ… 429 ì—ëŸ¬ ê°ì§€ ë° ì¬ì‹œë„
                if ('429' in error_str or 'Resource exhausted' in error_str or 'quota' in error_str.lower()):
                    if retry_429 < max_retries_for_429 - 1:
                        wait_time = 2 ** (retry_429 + 1)  # 2, 4, 8ì´ˆ
                        logger.warning(
                            f"[{attempt}ì°¨-{retry_429+1}ë²ˆì§¸ 429 ì—ëŸ¬] "
                            f"{wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„... ({error_str[:100]})"
                        )
                        time.sleep(wait_time)
                        continue  # 429 ì¬ì‹œë„ ë£¨í”„ ê³„ì†
                    else:
                        logger.error(
                            f"[{attempt}ì°¨ 429 ì—ëŸ¬] ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({max_retries_for_429}íšŒ) - "
                            f"ë‹¤ìŒ attemptë¡œ ì´ë™"
                        )
                        break  # 429 ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ, ë‹¤ìŒ attemptë¡œ
                else:
                    # 429ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬
                    logger.error(f"[{attempt}ì°¨ ì˜¤ë¥˜] {e}")
                    break  # 429 ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ, ë‹¤ìŒ attemptë¡œ
    
    # ëª¨ë“  ì‹œë„ ì™„ë£Œ - ìµœì„  ì„ íƒ
    if not candidates:
        raise RuntimeError(
            "ëª¨ë“  ì¬ìƒì„± ì‹œë„ ì‹¤íŒ¨ - ìœ íš¨í•œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ë¶ˆê°€\n"
            "ê°€ëŠ¥í•œ ì›ì¸:\n"
            "- API í• ë‹¹ëŸ‰ ì´ˆê³¼ (429 ì—ëŸ¬)\n"
            "- ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ\n"
            "- ì˜ëª»ëœ í”„ë¡¬í”„íŠ¸ í˜•ì‹"
        )
    
    # 1.0ì— ê°€ì¥ ê°€ê¹Œìš´ í›„ë³´ ì„ íƒ
    best = min(candidates, key=lambda x: abs(x[1] - 1.0))
    best_script, best_ratio, best_title = best
    
    logger.warning(
        f"ğŸ”„ [ìµœì„  ì„ íƒ] {max_attempts}íšŒ ì‹œë„ í›„ 1.0 ìµœê·¼ì ‘ ì„ íƒ: "
        f"{measure(best_script):,}ì ({best_ratio:.1%})"
    )
    
    # âœ… í† í° ì •ë³´ ë°˜í™˜
    usage_metadata = {
        "input_tokens": total_input_tokens,
        "output_tokens": total_output_tokens,
        "total_tokens": total_tokens,
        "attempts": max_attempts,
        "attempts_detail": attempts_detail  # âœ… ì‹œë„ë³„ ìƒì„¸ ë‚´ì—­
    }
    
    # ìµœì¢… ìš”ì•½
    logger.info(f"\nğŸ’° LLM í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½:")
    logger.info(f"   ì´ ì‹œë„: {max_attempts}íšŒ (ì „ì²´ ì‹œë„ ì™„ë£Œ)")
    logger.info(f"   Input:  {total_input_tokens:,} tokens")
    logger.info(f"   Output: {total_output_tokens:,} tokens")
    logger.info(f"   Total:  {total_tokens:,} tokens")
    
    print(f"\nğŸ’° LLM í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½:")
    print(f"   ì´ ì‹œë„: {max_attempts}íšŒ (ì „ì²´ ì‹œë„ ì™„ë£Œ)")
    print(f"   Input:  {total_input_tokens:,} tokens")
    print(f"   Output: {total_output_tokens:,} tokens")
    print(f"   Total:  {total_tokens:,} tokens")
    
    return best_title, best_script, candidates, usage_metadata


class ScriptGenerator:
    """LLMì„ ì‚¬ìš©í•œ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (PostgreSQL + Vertex AI)"""
   
        # âœ… db Sessionì„ ìƒì„±ìì—ì„œ ë°›ë„ë¡ ë³€ê²½
    def __init__(self, db: Session, project_id: str, region: str, sa_file: str, style: str = "explain"):
        self.project_id = project_id
        self.region = region
        self.sa_file = sa_file
        self.style = style
        self.db = db  # âœ… ì „ë‹¬ë°›ì€ db ê°ì²´ ì €ì¥
       
        self._init_vertex_ai()
        self._load_prompt_template()
   
    def _init_vertex_ai(self):
        """Vertex AI ì´ˆê¸°í™”"""
        if self.sa_file and os.path.exists(self.sa_file):
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = self.sa_file
            logger.info(f"ì¸ì¦ íŒŒì¼ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ: {self.sa_file}")
 
        credentials = self._load_credentials()
       
        try:
            vertexai.init(
                project=self.project_id,
                location=self.region,
                credentials=credentials
            )
            logger.info(f"Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {self.project_id} / {self.region}")
        except Exception as e:
            logger.error(f"Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
   
    def _load_credentials(self):
        """ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ë¡œë“œ"""
        if os.path.exists(self.sa_file):
            try:
                return service_account.Credentials.from_service_account_file(self.sa_file)
            except Exception as e:
                raise RuntimeError(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        else:
            logger.warning(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.sa_file}")
            return None
   
    def _load_prompt_template(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ (PostgreSQL ì—°ë™)"""
        try:
            template = PromptTemplateService.get_template(self.db, self.style)

            if template:
                self.system_prompt = template["system_prompt"]
                self.user_prompt_template = template["user_prompt_template"]
                logger.info(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì„±ê³µ: {template['style_name']}")
            else:
                logger.warning(f"í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©: {self.style}")
                default_template = PromptTemplateService.get_default_template(self.db)
                self.system_prompt = default_template["system_prompt"]
                self.user_prompt_template = default_template["user_prompt_template"]

        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.system_prompt = "You are a teacher. Respond in Korean."
            self.user_prompt_template = "Create a dialogue in Korean:\n{combined_text}"
 
    def _extract_text_from_gemini_response(self, resp) -> str:
        """Gemini ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        if not resp or not getattr(resp, "candidates", None):
            return ""

        text = ""
        try:
            c = resp.candidates[0]
            if hasattr(c, "content") and hasattr(c.content, "parts"):
                for part in c.content.parts:
                    if getattr(part, "text", None):
                        text += part.text
        except Exception:
            return ""

        return text.strip()

    def generate_script(
        self,
        combined_text: str,
        host_name: str,
        guest_name: str,
        duration: int = 5,
        difficulty: str = "intermediate",
        user_prompt: str = ""
    ) -> dict:
        """íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
         # ---------------------------------------------------------------------------------
         # âœ… ì•ˆì „ì¥ì¹˜: ì…ë ¥ ì»¨í…ìŠ¤íŠ¸(ê°•ì˜ í…ìŠ¤íŠ¸)ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ê¸ˆì§€
         # - OCR ë¹„í™œì„±í™” / ì´ë¯¸ì§€ ê¸°ë°˜ PDF ë“±ìœ¼ë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ëª» ë½‘ì•˜ì„ ë•Œ
         # - LangSmithì—ì„œ [MAIN-PAGE ...] ë§ˆì»¤ë§Œ ìˆê³  ë³¸ë¬¸ì´ ë¹„ëŠ” ì¼€ì´ìŠ¤ë¥¼ ì°¨ë‹¨
         # ---------------------------------------------------------------------------------
        if not combined_text or not combined_text.strip():
             logger.error("[ì…ë ¥ í…ìŠ¤íŠ¸ ë¹„ì •ìƒ] combined_textê°€ ë¹„ì–´ìˆê±°ë‚˜ ë§ˆì»¤-only ì…ë‹ˆë‹¤. OCR/ì¶”ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥.")
             raise ValueError(
                 "ê°•ì˜ í…ìŠ¤íŠ¸(combined_text)ê°€ ë¹„ì–´ ìˆì–´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                 "ì´ë¯¸ì§€ ê¸°ë°˜ PDF(OCR í•„ìš”) ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤."
             )
        
        # í˜ì´ì§€ ë§ˆì»¤ë§Œ ìˆê³  ì‹¤ì œ ë³¸ë¬¸ì´ ì—†ëŠ” ê²½ìš°ë„ ì°¨ë‹¨
         # ì˜ˆ: [MAIN-PAGE 1: Page 1]\n\n ... ë°˜ë³µ
        marker_stripped = re.sub(r"\[(MAIN|SUPP\d+)-PAGE\s*\d+:[^\]]*\]", "", combined_text)
        marker_stripped = re.sub(r"===\s*\[[^\]]+\]\s*===.*?\n", "", marker_stripped)
        marker_stripped = re.sub(r"\s+", "", marker_stripped)
        if len(marker_stripped) < 30:
            logger.error("[ì…ë ¥ í…ìŠ¤íŠ¸ ë¹„ì •ìƒ] combined_textê°€ ë¹„ì–´ìˆê±°ë‚˜ ë§ˆì»¤-only ì…ë‹ˆë‹¤. OCR/ì¶”ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥.")
            raise ValueError(
                "ê°•ì˜ í…ìŠ¤íŠ¸ê°€ í˜ì´ì§€ ë§ˆì»¤ë§Œ ì¡´ì¬í•˜ê³  ì‹¤ì œ ë³¸ë¬¸ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. "
                "OCRì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆê±°ë‚˜, PDFê°€ ì´ë¯¸ì§€ ê¸°ë°˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )

        model_name = os.getenv("VERTEX_AI_MODEL_TEXT", "gemini-2.5-flash-exp")

       # âœ… user_promptì—ì„œ override ì¶”ì¶œ â†’ ì˜µì…˜ë³´ë‹¤ ìš°ì„  ì ìš©
        duration_min = float(duration)
    
       # âœ… user_promptì—ì„œ override ì¶”ì¶œ â†’ ì˜µì…˜ë³´ë‹¤ ìš°ì„  ì ìš©
        overrides = parse_user_prompt_overrides(user_prompt)
        duration_min, style_from_prompt, difficulty = apply_overrides(duration_min, self.style, difficulty, overrides)

        # style overrideê°€ ë“¤ì–´ì˜¤ë©´, self.styleë„ ì´ í˜¸ì¶œì— í•œí•´ ë®ì–´ì“°ê¸°(ë¡œì»¬ ë³€ìˆ˜ë¡œ)
        style = style_from_prompt or self.style

        # âœ… ëŒ€í™”í˜• ì—¬ë¶€ëŠ” style ê²°ì • ì§í›„ í™•ì •í•˜ê¸° (UnboundLocalError ë°©ì§€)
        is_dialogue = (style != "lecture")


        # âœ… teacher_teacher í”„ë¦¬ì…‹(MVP): speaker_b_labelë§Œ êµì²´
        dialogue_mode = overrides.get("dialogue_mode") or None
        speaker_a_label = "ì„ ìƒë‹˜"
        speaker_b_label = "í•™ìƒ"
        if is_dialogue and dialogue_mode == "teacher_teacher":
            speaker_b_label = "ì„ ìƒë‹˜2"
        
        logger.info(
            f"[speaker preset] overrides={overrides}, "
            f"style={style}, is_dialogue={is_dialogue}, "
            f"speaker_b_label={speaker_b_label}, "
            f"user_prompt_preview={repr((user_prompt or '')[:120])}"
        )

        # âœ… float ë¶„ì„ ë°˜ì˜í•´ budget ê³„ì‚° (ë°˜ì˜¬ë¦¼/ìƒí•œ/í•˜í•œ)
        budget = target_char_budget(duration_min, style)

        logger.info(
            f"[override ì ìš©] duration_min={duration_min:.2f}, "
            f"budget={budget}, style={style}, difficulty={difficulty}"
        )
        
        logger.info(f"ëª¨ë¸: {model_name} / ëª©í‘œ: {duration_min:.2f}ë¶„ ({budget}ì) / ë‚œì´ë„: {difficulty} / ìŠ¤íƒ€ì¼: {style}")
        model = GenerativeModel(
        model_name,
        system_instruction=self.system_prompt
        )
        
        # ===== effective_user_prompt_template ì„¤ì • =====
        effective_user_prompt_template = self.user_prompt_template
        
        # ===== max_tokens ê³„ì‚° =====
        # í•œê¸€ íŠ¹ì„± ë°˜ì˜: 1ì â‰ˆ 2.5-3 í† í° + JSON êµ¬ì¡° ì˜¤ë²„í—¤ë“œ + ì•ˆì „ ì—¬ìœ 
        estimated_tokens = int(budget * 3.5)

        if duration_min <= 6:          # ~5ë¶„
            max_cap = 6144
        elif duration_min <= 11:       # ~10ë¶„
            max_cap = 8192
        elif duration_min <= 16:       # ~15ë¶„
            max_cap = 12288
        else:                          # 20ë¶„ ì´ìƒ ë“±
            max_cap = 16384

        max_tokens = max(2000, min(max_cap, estimated_tokens))

        logger.info(f"[CONFIG] budget={budget}ì, max_tokens={max_tokens}")
       
        try:
            # ===== ì¬ìƒì„± ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± =====
            # âœ… durationë³„ ë™ì  tolerance ê³„ì‚°
            min_ratio, max_ratio = get_tolerance_ratios(budget, duration_min)
            min_chars = int(budget * min_ratio)
            max_chars = int(budget * max_ratio)
            
            logger.info("=" * 80)
            logger.info("ì¬ìƒì„± ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œì‘")
            logger.info(f"ëª©í‘œ: {budget}ì (í—ˆìš© ë²”ìœ„: {min_chars}~{max_chars}ì, Â±1ë¶„ ê¸°ì¤€)")
            logger.info(f"Tolerance: {min_ratio:.1%}~{max_ratio:.1%}")
            logger.info("=" * 80)
            
            title, script_text, candidates, llm_usage = _generate_with_retry(
                model=model,
                combined_text=combined_text,
                host_name=host_name,
                guest_name=guest_name,
                duration_min=duration_min,
                difficulty=difficulty,
                user_prompt=user_prompt,
                budget=budget,
                style=style,
                user_prompt_template=effective_user_prompt_template,
                speaker_a_label=speaker_a_label,
                speaker_b_label=speaker_b_label,
                extract_text_fn=self._extract_text_from_gemini_response,
                max_attempts=4,
                target_min_ratio=min_ratio,
                target_max_ratio=max_ratio,
                max_output_tokens=max_tokens,
            )
            
            # ===== usage ë©”íƒ€ë°ì´í„° ì§‘ê³„ =====
            # âœ… LLM ë¹„ìš© ê³„ì‚° (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
            input_tokens = llm_usage.get('input_tokens', 0)
            output_tokens = llm_usage.get('output_tokens', 0)
            total_cost = calculate_llm_cost(input_tokens, output_tokens)
            
            # llm_usageì— cost ì¶”ê°€
            usage_with_cost = {**llm_usage, "cost_usd": total_cost}
            
            logger.info(f"[ì¬ìƒì„± ì™„ë£Œ] ìµœì¢… ì„ íƒ: {measure(script_text)}ì")
            logger.info(f"[ì‹œë„ ì´ë ¥] ì´ {len(candidates)}íšŒ ì‹œë„")
            logger.info(f"[í† í° ì‚¬ìš©] Input: {input_tokens:,}, Output: {output_tokens:,}, Total: {llm_usage.get('total_tokens', 0):,}")
            logger.info(f"[ë¹„ìš©] {format_cost(total_cost)}")
            
            print(f"ğŸ’µ LLM ë¹„ìš©: {format_cost(total_cost)}")
            
            # ===== ìµœì¢… ê²€ì¦ ë° ë³´ì • (ê°„ì†Œí™”) =====
            current_len = measure(script_text)
            ratio = current_len / budget
            
            logger.info("=" * 80)
            logger.info("ìµœì¢… ê²€ì¦ ì‹œì‘")
            logger.info("=" * 80)
            
            # 1. ëŠê¹€ ê°ì§€ â†’ ì´ì–´ì“°ê¸°
            is_incomplete, incomplete_reason = is_script_truncated(script_text)
            if is_incomplete:
                logger.warning(f"[ëŠê¹€ ê°ì§€] {incomplete_reason} â†’ ì´ì–´ì“°ê¸°")
                script_text = continue_script_fallback(
                    script_text=script_text,
                    budget=budget,
                    model=model,
                    style=style,
                    extract_text_fn=self._extract_text_from_gemini_response,
                    speaker_b_label=speaker_b_label,
                )
                script_text = clean_script(script_text)
                current_len = measure(script_text)
                ratio = current_len / budget
                logger.info(f"[ì´ì–´ì“°ê¸° í›„] {current_len}ì ({ratio:.1%})")
            
            # 2. tolerance ì´ˆê³¼ â†’ í•˜ë“œìº¡
            if ratio > max_ratio:  # tolerance ìµœëŒ€ì¹˜ ì´ˆê³¼ ì‹œ í•˜ë“œìº¡
                logger.error(f"[tolerance ì´ˆê³¼] {current_len}ì ({ratio:.1%}) > {max_chars}ì ({max_ratio:.1%}) â†’ í•˜ë“œìº¡")
                script_text = hard_cap_fallback(
                    script_text=script_text,
                    budget=max_chars,  # tolerance ìµœëŒ€ì¹˜ë¥¼ ëª©í‘œë¡œ
                    model=model,
                    style=style,
                    extract_text_fn=self._extract_text_from_gemini_response,
                    speaker_b_label=speaker_b_label,
                )
                script_text = clean_script(script_text)
                current_len = measure(script_text)
                ratio = current_len / budget
                logger.info(f"[í•˜ë“œìº¡ í›„] {current_len}ì ({ratio:.1%})")
            
            # ===== ìµœì¢… ê²°ê³¼ =====
            final_len = measure(script_text)
            final_ratio = final_len / budget
            
            logger.info("=" * 80)
            logger.info(f"[ìµœì¢… ê²°ê³¼] {final_len}ì ({final_ratio:.1%})")
            logger.info(f"[ì œëª©] {title}")
            logger.info("=" * 80)
            
            # ìµœì¢… ìƒíƒœ ë¡œê¹… (ë™ì  tolerance ë°˜ì˜)
            if final_ratio < 0.6:  # 60% ë¯¸ë§Œ (ê·¹ë‹¨ ë¹„ì •ìƒ)
                logger.error(f"âš ï¸ [ë¹„ì •ìƒ] ëª©í‘œì˜ 60% ë¯¸ë§Œ: {final_len}ì / {budget}ì")
            elif final_ratio < min_ratio:  # í—ˆìš© ìµœì†Œì¹˜ ë¯¸ë‹¬
                logger.warning(f"âš ï¸ [ë¶€ì¡±] í—ˆìš© ë²”ìœ„ ë¯¸ë‹¬: {final_len}ì < {min_chars}ì (ëª©í‘œ: {budget}ì)")
            elif final_ratio > 1.5:  # 150% ì´ˆê³¼ (ê·¹ë‹¨ ë¹„ì •ìƒ)
                logger.warning(f"âš ï¸ [ì´ˆê³¼] ëª©í‘œì˜ 150% ì´ˆê³¼: {final_len}ì / {budget}ì")
            elif final_ratio > max_ratio:  # í—ˆìš© ìµœëŒ€ì¹˜ ì´ˆê³¼
                logger.warning(f"âš ï¸ [ì´ˆê³¼] í—ˆìš© ë²”ìœ„ ì´ˆê³¼: {final_len}ì > {max_chars}ì (ëª©í‘œ: {budget}ì)")
            else:
                logger.info(f"âœ… [ì •ìƒ] ëª©í‘œ ë²”ìœ„ ë‚´: {final_len}ì ({min_chars}~{max_chars}ì)")
 
            # ============================================================
            # âœ… í”„ë¡ íŠ¸ì—”ë“œ UI ë…¸ì´ì¦ˆ ì œê±° (ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì)
            # ============================================================
            # JSON ìƒì„± ì‹œ LLMì´ ì¶”ê°€í•œ \ ì œê±°
            script_text = script_text.replace('\\', '')
            title = title.replace('\\', '')
            
            return {
                "title": title,
                "script": script_text,
                "usage": {
                    "script_generation": usage_with_cost
                }
            }
           
        except Exception as e:
            logger.error(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}", exc_info=True)
            raise RuntimeError(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}") from e