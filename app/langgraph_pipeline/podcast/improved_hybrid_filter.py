"""
Improved Hybrid Filter V4
==========================

V4 ë³€ê²½ì‚¬í•­:
- V2ì˜ ìœ ì—°í•œ ì¸ì¦ ë¡œì§ ì¶”ê°€ (í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜)
- V3ì˜ pdfplumber (MIT) ìœ ì§€
- ìƒ‰ìƒ ë³µì¡ë„ í•„í„° ìœ ì§€
- ì¸ì¦ ì‹¤íŒ¨ ì‹œ graceful degradation

í•µì‹¬ ê¸°ëŠ¥:
- PyMuPDF (AGPL) â†’ pdfplumber (MIT) ì „í™˜
- ë¼ì´ì„ ìŠ¤ ë¬¸ì œ í•´ê²°
- ìƒ‰ìƒ ë³µì¡ë„ í•„í„° (í…ìŠ¤íŠ¸ ìƒì ë°°ê²½ ì œê±°)
- í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì¸ì¦ (í”„ë¡œë•ì…˜ ëŒ€ì‘)
"""

import os
import textwrap
import json
from dataclasses import dataclass
from typing import List, Dict
from pptx import Presentation
from vertexai.generative_models import Part
import logging
import sys
logger = logging.getLogger(__name__)

def _log(*args, level: str | None = None, exc_info: bool = False, end: str = '\n', flush: bool = False) -> None:
    """
     logger ê¸°ë°˜ ë¡œê·¸ (í™˜ê²½ë³„ LOG_LEVEL ì ìš©).
     - ê¸°ë³¸ level: DEBUG
     - end/flushë¥¼ ì“°ëŠ” ì§„í–‰í˜• ì¶œë ¥(end != '\\n' ë˜ëŠ” flush=True)ì€ print ìœ ì§€
    """
    msg = " ".join(str(a) for a in args).rstrip() if args else ""
    # ì§„í–‰í˜• ì¶œë ¥ì€ ê·¸ëŒ€ë¡œ stdoutë¡œ (ê¸°ì¡´ UX ìœ ì§€)
    if end != "\n" or flush:
        print(msg, end=end, flush=flush)
        return

    lvl = (level or "DEBUG").upper()
    if lvl == "DEBUG":
        logger.debug(msg, exc_info=exc_info)
    elif lvl == "INFO":
        logger.info(msg, exc_info=exc_info)
    elif lvl in ("WARN", "WARNING"):
        logger.warning(msg, exc_info=exc_info)
    elif lvl == "ERROR":
        logger.error(msg, exc_info=exc_info)
    elif lvl in ("CRITICAL", "FATAL"):
        logger.critical(msg, exc_info=exc_info)
    else:
        logger.debug(msg, exc_info=exc_info)

def _resolve_vertex_sa_file() -> str | None:
    # í”„ë¡œì íŠ¸ì—ì„œ ì“°ëŠ” í‚¤ ìš°ì„ ìˆœìœ„
    # NOTE: VERTEX_AI_SERVICE_ACCOUNT_JSON(=JSON ë¬¸ìì—´)ì€ main.pyì˜ patch_vertex_ai_env()ì—ì„œ
    # íŒŒì¼ë¡œ ë³€í™˜ í›„ GOOGLE_APPLICATION_CREDENTIALSë¡œ ì—°ê²°ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” "ê²½ë¡œ"ë§Œ í™•ì¸í•œë‹¤.
    for key in ("VERTEX_AI_SERVICE_ACCOUNT_FILE", "GOOGLE_APPLICATION_CREDENTIALS"):
        p = os.getenv(key)
        if p and os.path.exists(p):
            return p
    return None

def get_vertex_text_model():
    """
    í‚¤ì›Œë“œ ì¶”ì¶œ/ì´ë¯¸ì§€ íŒë‹¨(vision)ì—ì„œ ì“°ëŠ” Gemini ëª¨ë¸ lazy init.
    - ì¸ì¦ íŒŒì¼ ì—†ìœ¼ë©´ None ë°˜í™˜ (ë¡œì»¬ ë°ëª¨ì—ì„œ visionë§Œ ìŠ¤í‚µ ê°€ëŠ¥)
    """
    try:
        sa_file = _resolve_vertex_sa_file()
        if not sa_file:
            logger.warning("â„¹ï¸ Vertex ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ì´ ì—†ì–´ Gemini í˜¸ì¶œì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return None

        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = sa_file

        import vertexai
        from vertexai.generative_models import GenerativeModel

        project_id = os.getenv("VERTEX_AI_PROJECT_ID")
        location = os.getenv("VERTEX_AI_REGION", "us-central1")

        if project_id:
            vertexai.init(project=project_id, location=location)
        else:
            vertexai.init(location=location)

        model_name = os.getenv("VERTEX_AI_MODEL_TEXT", "gemini-2.5-flash")
        return GenerativeModel(model_name)

    except Exception as e:
        logger.exception(f"Vertex/Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
    
model = None

def get_global_model():
    global model
    if model is None:
        model = get_vertex_text_model()
    return model

@dataclass
class ImageMetadata:
    image_id: str
    slide_number: int
    area_percentage: float
    left: float
    top: float
    adjacent_text: str
    slide_title: str
    image_bytes: bytes = None
    is_core_content: bool = False
    filter_reason: str = ""

# 1. í†µí•© ì´ë¯¸ì§€ ì¶”ì¶œê¸° (PPTX + PDF ì§€ì›)
class UniversalImageExtractor:
    """
    ëª¨ë“  í˜•ì‹ì—ì„œ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    V3: pdfplumber (MIT) ì‚¬ìš©
    """
    
    def extract(self, file_path: str) -> List[ImageMetadata]:
        from pathlib import Path
        
        ext = Path(file_path).suffix.lower()
        
        if ext == '.pptx':
            return self._extract_from_pptx(file_path)
        elif ext == '.pdf':
            return self._extract_from_pdf_v3(file_path)  # âœ… v3ë¡œ ë³€ê²½
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
    
    def _extract_from_pptx(self, pptx_path: str) -> List[ImageMetadata]:
        """PPTXì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹)"""
        if not os.path.exists(pptx_path):
            return []
        
        prs = Presentation(pptx_path)
        metadata_list = []
        slide_width, slide_height = prs.slide_width.inches, prs.slide_height.inches
        slide_area = slide_width * slide_height

        for s_idx, slide in enumerate(prs.slides, 1):
            slide_title = slide.shapes.title.text if slide.shapes.title else "No Title"
            all_text = " ".join([s.text for s in slide.shapes if hasattr(s, "text")])
            
            img_idx = 1
            for shape in slide.shapes:
                if shape.shape_type == 13 or hasattr(shape, 'image'):
                    w, h = shape.width.inches, shape.height.inches
                    area_pct = ((w * h) / slide_area) * 100
                    metadata_list.append(ImageMetadata(
                        image_id=f"S{s_idx:02d}_IMG{img_idx:03d}",
                        slide_number=s_idx,
                        area_percentage=area_pct,
                        left=shape.left.inches,
                        top=shape.top.inches,
                        adjacent_text=all_text.replace('\n', ' ').strip(),
                        slide_title=slide_title,
                        image_bytes=shape.image.blob
                    ))
                    img_idx += 1
        
        return metadata_list
    
    def _safe_parse_paddleocr_result(self, ocr_result):
        """
        PaddleOCR v3~v5 ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ íŒŒì‹±
        ë°˜í™˜: List[Dict] -> {text, bbox, confidence}
        """
        parsed = []

        if not ocr_result:
            return parsed

        # PaddleOCRëŠ” ë³´í†µ [result] í˜•íƒœë¡œ í•œ ë²ˆ ë” ê°ì‹¸ì§
        if isinstance(ocr_result, list) and len(ocr_result) == 1 and isinstance(ocr_result[0], list):
            ocr_result = ocr_result[0]

        for item in ocr_result:
            try:
                # âœ… Case 1: dict í˜•íƒœ (PaddleOCR v5 / PaddleX)
                if isinstance(item, dict):
                    text = item.get("text", "").strip()
                    bbox = item.get("points") or item.get("bbox")
                    conf = item.get("confidence") or item.get("score")

                # âœ… Case 2: classic list í˜•íƒœ [[bbox], (text, score)]
                elif isinstance(item, (list, tuple)):
                    # ("text", score) í˜•íƒœ
                    if len(item) == 2 and isinstance(item[0], str):
                        text = item[0].strip()
                        bbox = None
                        conf = item[1]

                    # [[x,y]... , ("text", score)]
                    elif len(item) >= 2 and isinstance(item[1], (list, tuple)):
                        bbox = item[0]
                        text = item[1][0].strip() if len(item[1]) > 0 else ""
                        conf = item[1][1] if len(item[1]) > 1 else None
                    else:
                        continue
                else:
                    continue

                if not text:
                    continue

                parsed.append({
                    "text": text,
                    "bbox": bbox,
                    "confidence": conf
                })

            except Exception:
                # íŒŒì‹± ì‹¤íŒ¨í•´ë„ ì „ì²´ OCRì€ ì‚´ë¦¬ê¸°
                continue

        return parsed

    def _normalize_ocr_image(self, pil_img):
        """
        PaddleOCR ì•ˆì •í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì •ê·œí™”
        - RGBA â†’ RGB
        - Grayscale â†’ RGB
        - numpy contiguous ë³´ì¥
        """
        from PIL import Image
        import numpy as np

        if pil_img.mode != "RGB":
            pil_img = pil_img.convert("RGB")

        img_array = np.array(pil_img)

        # numpy contiguous ë³´ì¥ (ì¤‘ìš”)
        if not img_array.flags['C_CONTIGUOUS']:
            img_array = np.ascontiguousarray(img_array)

        return img_array


    def _extract_text_with_ocr(self, pdf_path: str, page_num: int, min_length: int = 100) -> str:
        """
        í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•„ìš”ì‹œ OCR)
        V3: pdfplumber + pypdfium2 + PaddleOCR
        """
        # ===== 1. pdfplumberë¡œ ë¨¼ì € ì‹œë„ =====
        try:
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                page = pdf.pages[page_num]
                text = page.extract_text() or ""
                text_length = len(text.strip())
                
                if text_length >= min_length:
                    return text
        except:
            text_length = 0
        
        # ===== 2. í…ìŠ¤íŠ¸ ë¶€ì¡± â†’ OCR ì‹¤í–‰ =====
        try:
            from paddleocr import PaddleOCR
            import numpy as np
            from pypdfium2 import PdfDocument

            if not hasattr(self, '_ocr_engine'):
                os.environ['FLAGS_log_level'] = '3'
                os.environ['PPOCR_SHOW_LOG'] = 'False'

                _log(f"      â†’ PaddleOCR ì´ˆê¸°í™” ì¤‘...")
                self._ocr_engine = PaddleOCR(lang='korean', use_angle_cls=True)

            # âœ… pypdfium2ë¡œ í•´ë‹¹ í˜ì´ì§€ë§Œ ë Œë”ë§ (0-indexed page_num)
            pdf = PdfDocument(pdf_path)
            if page_num < 0 or page_num >= len(pdf):
                return text

            page = pdf[page_num]
            target_dpi = 150
            scale = target_dpi / 72.0
            bitmap = page.render(scale=scale)
            pil_img = bitmap.to_pil()

            img_array = self._normalize_ocr_image(pil_img)

            # ===== OCR ì‹¤í–‰ (ì•ˆì •í™” ë²„ì „) =====
            result = None

            # í˜ì´ì§€ OCRì—ì„œëŠ” cls=True ê¸ˆì§€
            try:
                result = self._ocr_engine.ocr(img_array)
            except Exception as e1:
                _log(f"      âš ï¸ ocr() ì‹¤íŒ¨, predict() ì‹œë„: {e1}")
                try:
                    if hasattr(self._ocr_engine, "predict"):
                        result = self._ocr_engine.predict(img_array)
                except Exception as e2:
                    _log(f"      âŒ OCR ì™„ì „ ì‹¤íŒ¨: {e2}")
                    return text

            parsed = self._safe_parse_paddleocr_result(result)

            if parsed:
                lines = [p["text"] for p in parsed]
                ocr_result = "\n".join(lines)
                _log(f"      â†’ OCR ì™„ë£Œ: {text_length}ì â†’ {len(ocr_result)}ì")
                return ocr_result if ocr_result else text


        except ImportError as e:
            _log(f"      â†’ PaddleOCR/pypdfium2 ë¯¸ì„¤ì¹˜, í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©: {e}")
            return text
        except Exception as e:
            _log(f"      âš ï¸  OCR ì‹¤íŒ¨: {e}")
            return text

        return text

    
    def _extract_text_bboxes_with_ocr(self, pdf_path: str, page_num: int) -> List[Dict]:
        """
        í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ (OCR í™œìš©)
        
        Returns:
            [{'x0', 'top', 'x1', 'bottom'}, ...]
        """
        text_bboxes = []
        
        # ===== 1. pdfplumberë¡œ ë¨¼ì € ì‹œë„ =====
        try:
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                page = pdf.pages[page_num]
                chars = page.chars
                
                if chars and len(chars) > 0:
                    # í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ìˆìŒ
                    for char in chars:
                        text_bboxes.append({
                            'x0': char['x0'],
                            'top': char['top'],
                            'x1': char['x1'],
                            'bottom': char['bottom']
                        })
                    
                    _log(f"      â†’ pdfplumberë¡œ {len(text_bboxes)}ê°œ ë¬¸ì bbox ì¶”ì¶œ")
                    return text_bboxes
        except:
            pass
        
        # ===== 2. í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì—†ìŒ â†’ OCRë¡œ bbox ì¶”ì¶œ =====
        try:
            from paddleocr import PaddleOCR
            import numpy as np
            from pypdfium2 import PdfDocument

            if not hasattr(self, '_ocr_engine'):
                os.environ['FLAGS_log_level'] = '3'
                os.environ['PPOCR_SHOW_LOG'] = 'False'
                self._ocr_engine = PaddleOCR(lang='korean', use_angle_cls=True)

            # âœ… pypdfium2ë¡œ í•´ë‹¹ í˜ì´ì§€ ë Œë”ë§
            pdf = PdfDocument(pdf_path)
            if page_num < 0 or page_num >= len(pdf):
                return []

            page = pdf[page_num]
            target_dpi = 150
            scale = target_dpi / 72.0
            bitmap = page.render(scale=scale)
            pil_img = bitmap.to_pil()

            img_array = self._normalize_ocr_image(pil_img)

            # ===== OCR ì‹¤í–‰ (ë²„ì „ë³„ ëŒ€ì‘) =====
            result = None

            try:
                result = self._ocr_engine.ocr(img_array)
            except Exception as e1:
                _log(f"      âš ï¸ bbox OCR ocr() ì‹¤íŒ¨, predict() ì‹œë„: {e1}")
                try:
                    if hasattr(self._ocr_engine, "predict"):
                        result = self._ocr_engine.predict(img_array)
                except Exception as e2:
                    _log(f"      âŒ bbox OCR ì™„ì „ ì‹¤íŒ¨: {e2}")
                    return []

            parsed = self._safe_parse_paddleocr_result(result)

            for item in parsed:
                bbox_points = item["bbox"]
                if not bbox_points:
                    continue

                try:
                    x_coords = [p[0] for p in bbox_points if len(p) == 2]
                    y_coords = [p[1] for p in bbox_points if len(p) == 2]

                    if not x_coords or not y_coords:
                        continue

                    text_bboxes.append({
                        'x0': min(x_coords),
                        'top': min(y_coords),
                        'x1': max(x_coords),
                        'bottom': max(y_coords)
                    })
                except Exception:
                    continue

            if text_bboxes:
                _log(f"      â†’ OCRë¡œ {len(text_bboxes)}ê°œ í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ")

            return text_bboxes

        except ImportError as e:
            _log(f"      âš ï¸  OCR bbox ì¶”ì¶œ ë¶ˆê°€(PaddleOCR/pypdfium2 ë¯¸ì„¤ì¹˜): {e}")
            return []
        except Exception as e:
            _log(f"      âš ï¸  í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    
    def _calculate_text_overlap(self, img_bbox: tuple, text_bboxes: List[Dict]) -> float:
        """
        ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì¤‘ì²© ë¹„ìœ¨ ê³„ì‚°
        
        Args:
            img_bbox: (x0, top, x1, bottom)
            text_bboxes: [{'x0', 'top', 'x1', 'bottom'}, ...]
        
        Returns:
            ì¤‘ì²© ë¹„ìœ¨ (0.0 ~ 1.0)
        """
        if not text_bboxes:
            return 0.0
        
        img_x0, img_top, img_x1, img_bottom = img_bbox
        img_area = (img_x1 - img_x0) * (img_bottom - img_top)
        
        if img_area <= 0:
            return 0.0
        
        overlap_area = 0.0
        
        for text_bbox in text_bboxes:
            # êµì§‘í•© ê³„ì‚°
            x0 = max(img_x0, text_bbox['x0'])
            top = max(img_top, text_bbox['top'])
            x1 = min(img_x1, text_bbox['x1'])
            bottom = min(img_bottom, text_bbox['bottom'])
            
            if x0 < x1 and top < bottom:
                overlap_area += (x1 - x0) * (bottom - top)
        
        overlap_ratio = overlap_area / img_area
        
        return overlap_ratio
    
    def _calculate_color_complexity(self, image_bytes) -> int:
        """
        ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ ë³µì¡ë„ ê³„ì‚° (ê³ ìœ  ìƒ‰ìƒ ìˆ˜)
        
        í…ìŠ¤íŠ¸ ìƒì ë°°ê²½: 10-300ê°œ (ë‹¨ì¡°ë¡œìš´ ìƒ‰ìƒ)
        ì§„ì§œ ì½˜í…ì¸ : 500+ ê°œ (ë³µì¡í•œ ìƒ‰ìƒ)
        
        Args:
            image_bytes: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
        
        Returns:
            ê³ ìœ  ìƒ‰ìƒ ìˆ˜ (0 ~ 10000+)
        """
        try:
            from PIL import Image
            import io
            
            # ë°”ì´ë„ˆë¦¬ â†’ PIL Image
            img = Image.open(io.BytesIO(image_bytes))
            
            # RGB ë³€í™˜
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ)
            max_size = 500
            if img.width > max_size or img.height > max_size:
                ratio = min(max_size / img.width, max_size / img.height)
                new_size = (int(img.width * ratio), int(img.height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # ê³ ìœ  ìƒ‰ìƒ ìˆ˜ ê³„ì‚°
            colors = img.getcolors(maxcolors=10000)
            
            if colors:
                unique_colors = len(colors)
            else:
                # 10000ê°œ ì´ìƒ ìƒ‰ìƒ
                unique_colors = 10000
            
            return unique_colors
        
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 10000  # ì‹¤íŒ¨ ì‹œ ë³µì¡í•œ ì´ë¯¸ì§€ë¡œ ê°„ì£¼
    
    def _extract_page_title(self, page_text: str) -> str:
        """í˜ì´ì§€ ì œëª© ì¶”ì¶œ"""
        lines = page_text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if len(line) > 3 and not line.startswith('â˜'):
                return line[:50]
        return "í˜ì´ì§€ ì œëª© ì—†ìŒ"
    
    def _extract_from_pdf_v3(self, pdf_path: str) -> List[ImageMetadata]:
        """
        PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (V3: pdfplumber ì‚¬ìš©)
        
        í•µì‹¬ ë³€ê²½:
        - PyMuPDF â†’ pdfplumber (MIT ë¼ì´ì„ ìŠ¤)
        - ê¸°ëŠ¥ ë™ì¼í•˜ê²Œ ìœ ì§€
        """
        try:
            import pdfplumber  # âœ… pdfplumber ì‚¬ìš©
        except ImportError:
            _log("   âŒ pdfplumberê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            _log("   pip install pdfplumber")
            return []
        
        if not os.path.exists(pdf_path):
            return []
        
        metadata_list = []
        
        # í•„í„°ë§ ê¸°ì¤€
        MIN_WIDTH = 40
        MIN_HEIGHT = 40
        MIN_AREA_PCT = 3.0      # 3% ë¯¸ë§Œ: ë ˆì´ë¸”/ì•„ì´ì½˜
        MAX_AREA_PCT = 90.0     # 90% ì´ìƒ: ë°°ê²½
        MIN_PIXEL_AREA = 1000
        MAX_ASPECT_RATIO = 6.0  # 6:1 ì´ìƒ: ì œëª©/í…ìŠ¤íŠ¸
        
        total_images = 0
        filtered_background = 0
        filtered_aspect = 0
        filtered_area = 0
        filtered_size = 0
        filtered_text_overlap = 0  # âœ… ì¶”ê°€
        
        try:
            # ===== pdfplumberë¡œ PDF ì—´ê¸° =====
            with pdfplumber.open(pdf_path) as pdf:
                
                for page_num, page in enumerate(pdf.pages):
                    # í˜ì´ì§€ ì •ë³´
                    page_width = page.width
                    page_height = page.height
                    page_area = page_width * page_height
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR í¬í•¨)
                    page_text = self._extract_text_with_ocr(pdf_path, page_num, min_length=100)
                    page_title = self._extract_page_title(page_text)
                    
                    # ===== í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ (ì¤‘ì²© ì²´í¬ìš©) =====
                    text_bboxes = self._extract_text_bboxes_with_ocr(pdf_path, page_num)
                    
                    # ===== pdfplumberë¡œ ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° =====
                    images = page.images
                    total_images += len(images)
                    
                    _log(f"      [P{page_num+1}] ì´ {len(images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
                    
                    for img in images:
                        try:
                            # ===== bbox ì •ë³´ (pdfplumber í˜•ì‹) =====
                            x0 = img['x0']
                            top = img['top']
                            x1 = img['x1']
                            bottom = img['bottom']
                            
                            width = x1 - x0
                            height = bottom - top
                            area_pct = (width * height) / page_area * 100
                            
                            debug_msg = f"      [P{page_num+1}] {area_pct:.1f}%"
                            
                            # ===== í•„í„° 1: ë°°ê²½ ì œì™¸ (90% ì´ìƒ) =====
                            if area_pct > MAX_AREA_PCT:
                                filtered_background += 1
                                _log(debug_msg + f" â†’ ë°°ê²½ ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 2: ê°€ë¡œì„¸ë¡œë¹„ =====
                            if width > 0 and height > 0:
                                aspect_ratio = max(width, height) / min(width, height)
                                if aspect_ratio > MAX_ASPECT_RATIO:
                                    filtered_aspect += 1
                                    _log(debug_msg + f" â†’ ê°€ë¡œì„¸ë¡œë¹„ ì œì™¸ ({aspect_ratio:.1f}:1) âŒ")
                                    continue
                            
                            # ===== í•„í„° 3: ì‘ì€ ë©´ì  =====
                            pixel_area = width * height
                            if pixel_area < MIN_PIXEL_AREA:
                                filtered_area += 1
                                _log(debug_msg + f" â†’ ì‘ì€ ë©´ì  ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 4: ì ˆëŒ€ í¬ê¸° =====
                            if width < MIN_WIDTH or height < MIN_HEIGHT:
                                filtered_size += 1
                                _log(debug_msg + f" â†’ ì‘ì€ í¬ê¸° ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 5: ìƒëŒ€ í¬ê¸° =====
                            if area_pct < MIN_AREA_PCT:
                                filtered_size += 1
                                _log(debug_msg + f" â†’ ìƒëŒ€ í¬ê¸° ì œì™¸ ({area_pct:.1f}%) âŒ")
                                continue
                            
                            # ===== í†µê³¼! =====
                            _log(debug_msg + " â†’ ìµœì¢… ì¶”ì¶œ âœ…âœ…âœ…")
                            
                            # ===== í•„í„° 6: í…ìŠ¤íŠ¸ ì¤‘ì²© + ìƒ‰ìƒ ë³µì¡ë„ ì²´í¬ â­â­â­ =====
                            # ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ì¶”ì¶œ
                            stream = img.get('stream')
                            
                            if stream:
                                if hasattr(stream, 'get_data'):
                                    image_bytes = stream.get_data()
                                elif hasattr(stream, 'rawdata'):
                                    image_bytes = stream.rawdata
                                else:
                                    _log(debug_msg + " â†’ ë°”ì´ë„ˆë¦¬ ì¶”ì¶œ ì‹¤íŒ¨ âš ï¸")
                                    continue
                            else:
                                _log(debug_msg + " â†’ stream ì—†ìŒ âš ï¸")
                                continue
                            
                            # í…ìŠ¤íŠ¸ ì¤‘ì²© ê³„ì‚°
                            img_bbox = (x0, top, x1, bottom)
                            overlap_ratio = self._calculate_text_overlap(img_bbox, text_bboxes)
                            
                            # ìƒ‰ìƒ ë³µì¡ë„ ê³„ì‚°
                            color_count = self._calculate_color_complexity(image_bytes)
                            
                            # íŒë‹¨ ë¡œì§ (ìƒ‰ìƒ + ì¤‘ì²©)
                            is_textbox = False
                            filter_reason = ""
                            
                            # ê·œì¹™ 1: ë‹¨ì¡°ë¡œìš´ ìƒ‰ìƒ (< 300ê°œ) â†’ í…ìŠ¤íŠ¸ ìƒì ê°€ëŠ¥ì„±
                            if color_count < 300:
                                if overlap_ratio >= 0.05:  # 5% ì´ìƒ ì¤‘ì²©
                                    is_textbox = True
                                    filter_reason = f"ë‹¨ì¡°ìƒ‰ìƒ({color_count}ê°œ)+ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                                elif area_pct >= 15.0:
                                    is_textbox = True
                                    filter_reason = f"ë‹¨ì¡°ìƒ‰ìƒ({color_count}ê°œ)+ëŒ€í˜•"
                            
                            # ê·œì¹™ 2: ë³µì¡í•œ ìƒ‰ìƒ (>= 500ê°œ) â†’ ì§„ì§œ ì½˜í…ì¸  ê°€ëŠ¥ì„±
                            elif color_count >= 500:
                                if overlap_ratio >= 0.30:  # 30% ì´ìƒë§Œ ì œì™¸
                                    is_textbox = True
                                    filter_reason = f"ê³ ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                                # else: í†µê³¼
                            
                            # ê·œì¹™ 3: ì¤‘ê°„ ë³µì¡ë„ (300-500ê°œ) â†’ ì¤‘ì²© ë¹„ìœ¨ë¡œ íŒë‹¨
                            else:
                                if overlap_ratio >= 0.15:  # 15% ì´ìƒ
                                    is_textbox = True
                                    filter_reason = f"ì¤‘ê°„ìƒ‰ìƒ({color_count}ê°œ)+ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                            
                            # ê²°ê³¼ ì²˜ë¦¬
                            if is_textbox:
                                filtered_text_overlap += 1
                                _log(debug_msg + f" â†’ í…ìŠ¤íŠ¸ìƒì ì œì™¸ ({filter_reason}) âŒ")
                                continue
                            
                            # ìµœì¢… í†µê³¼ - ë©”íƒ€ë°ì´í„° ì €ì¥
                            
                            metadata_list.append(ImageMetadata(
                                image_id=f"P{page_num+1:02d}_IMG{len(metadata_list)+1:03d}",
                                slide_number=page_num + 1,
                                area_percentage=area_pct,
                                left=x0,
                                top=top,
                                adjacent_text=page_text.replace('\n', ' ').strip(),
                                slide_title=page_title,
                                image_bytes=image_bytes
                            ))
                        
                        except Exception as e:
                            _log(f"      âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            continue
        
        except Exception as e:
            _log(f"   âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
        
        # í†µê³„
        _log(f"\n   ğŸ“Š PDF ì´ë¯¸ì§€ ë¶„ì„:")
        _log(f"      - ì „ì²´ ì´ë¯¸ì§€: {total_images}ê°œ")
        _log(f"   ğŸ” í•„í„°ë§ í†µê³„:")
        _log(f"      - ë°°ê²½ ì œì™¸: {filtered_background}ê°œ")
        _log(f"      - ê°€ë¡œì„¸ë¡œë¹„: {filtered_aspect}ê°œ")
        _log(f"      - ì‘ì€ ë©´ì : {filtered_area}ê°œ")
        _log(f"      - ì‘ì€ í¬ê¸°: {filtered_size}ê°œ")
        _log(f"      - í…ìŠ¤íŠ¸ ìƒì (ìƒ‰ìƒ+ì¤‘ì²©): {filtered_text_overlap}ê°œ")  # âœ… ì¶”ê°€
        _log(f"   âœ… ìµœì¢… ì¶”ì¶œ: {len(metadata_list)}ê°œ ì´ë¯¸ì§€\n")
        
        return metadata_list


# 2. ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ í•„í„° íŒŒì´í”„ë¼ì¸
class ImprovedHybridFilterPipeline:
    def __init__(self, auto_extract_keywords: bool = True):
        self.auto_extract = auto_extract_keywords
        
        self.UNIVERSAL_PATTERNS = [
            'í•™ìŠµ', 'í™œë™', 'ë¬¸ì œ', 'ì˜ˆì œ', 'ì—°ìŠµ',
            'ìƒê°', 'ì•Œì•„ë³´', 'ì‚´í´ë³´', 'ì •ë¦¬',
            'ëª©í‘œ', 'ê°œë…', 'ì›ë¦¬', 'ë²•ì¹™', 'ì •ì˜',
            'ë‹¨ì›', 'ì°¨ì‹œ',
            'ê·¸ë¦¼', 'ë„í‘œ', 'í‘œ', 'ì°¨íŠ¸', 'ê·¸ë˜í”„',
            'ì˜ˆì‹œ', 'ì‚¬ë¡€', 'ëª¨í˜•', 'êµ¬ì¡°'
        ]
        
        self.DECORATION_PATTERNS = [
            'ë¡œê³ ', 'logo', 'ì¶œì²˜', 'ì°¸ê³ ', 'ì•„ì´ì½˜', 'icon'
        ]
        
        self.document_keywords = []
        
        self.model = get_global_model()

    def extract_keywords_from_document(self, file_path: str):
        """ë¬¸ì„œì—ì„œ ìë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not self.auto_extract:
            return
        
        from pathlib import Path
        
        _log("ğŸ“š ë¬¸ì„œ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ ì¤‘...")
        
        ext = Path(file_path).suffix.lower()
        all_text = []
        
        if ext == '.pptx':
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        all_text.append(shape.text)
        
        elif ext == '.pdf':
            import pdfplumber  # âœ… pdfplumber ì‚¬ìš©
            try:
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        text = page.extract_text()
                        if text:
                            all_text.append(text)
            except Exception as e:
                _log(f"   âš ï¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨, ë²”ìš© íŒ¨í„´ë§Œ ì‚¬ìš©")
                return
        
        else:
            _log(f"   âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
            return
        
        full_text = "\n".join(all_text)[:5000]
        
        prompt = f"""
ë‹¤ìŒ ê°•ì˜ ìë£Œì—ì„œ **í•µì‹¬ í‚¤ì›Œë“œ 20ê°œ**ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

# ë¬¸ì„œ ë‚´ìš©
{full_text}

# ì¡°ê±´
- ê°œë…ì–´, ì „ë¬¸ ìš©ì–´, ì£¼ì œì–´ë§Œ í¬í•¨
- JSON í˜•ì‹: {{"keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]}}
"""
        
        if self.model is None:
            _log("   âš ï¸ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨(ì¸ì¦ ì—†ìŒ). í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ ìŠ¤í‚µ.")
            self.document_keywords = []
            return

        try:
            response = self.model.generate_content(prompt)
            text = response.text.strip()
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            self.document_keywords = data.get("keywords", [])
            
            _log(f"   âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(self.document_keywords[:10])}")
        
        except Exception as e:
            _log(f"   âš ï¸ ìë™ ì¶”ì¶œ ì‹¤íŒ¨, ë²”ìš© íŒ¨í„´ë§Œ ì‚¬ìš©")
            self.document_keywords = []

    def step1_rule_check(self, meta: ImageMetadata):
        """ê·œì¹™ ê¸°ë°˜ 1ì°¨ í•„í„°"""
        context = f"{meta.slide_title} {meta.adjacent_text}".lower()
        
        has_deco = any(kw in context for kw in self.DECORATION_PATTERNS)
        is_corner = (meta.left < 1.0 and meta.top < 1.0) or (meta.left > 8.0 and meta.top < 1.0)
        
        if is_corner and meta.area_percentage < 5.0 and not any(kw in context for kw in self.UNIVERSAL_PATTERNS):
            return "EXCLUDE", "Static Decoration (Corner)"
        
        if has_deco and meta.area_percentage < 8.0:
            return "EXCLUDE", "Decorative element"
        
        has_universal = any(p in context for p in self.UNIVERSAL_PATTERNS)
        has_document_kw = any(kw in context for kw in self.document_keywords)
        
        if meta.area_percentage > 15.0 and (has_universal or has_document_kw):
            return "INCLUDE", f"Core content ({meta.area_percentage:.1f}% + pattern)"
        
        if has_document_kw and meta.area_percentage > 10.0:
            matched = [kw for kw in self.document_keywords if kw in context]
            return "INCLUDE", f"Document keyword: {', '.join(matched[:2])}"
        
        return "PENDING", "Requires AI Vision Check"

    def step2_gemini_check(self, meta: ImageMetadata, max_retries=3):
        """AI Visionìœ¼ë¡œ 2ì°¨ íŒë‹¨"""
        import time
        
        
        if self.model is None:
            return "DISCARD: Gemini unavailable (no credentials)", 0, 0.0

        for attempt in range(max_retries):
            try:
                image_part = Part.from_data(data=meta.image_bytes, mime_type="image/png")
                
                keyword_list = ', '.join(list(self.document_keywords)[:15]) if self.document_keywords else "ì¼ë°˜ í•™ìŠµ ë‚´ìš©"
                
                prompt = f"""
ì´ ê°•ì˜ì˜ í•µì‹¬ ì£¼ì œ: {keyword_list}

ì£¼ë³€ í…ìŠ¤íŠ¸: "{meta.adjacent_text}"

ì´ ì´ë¯¸ì§€ê°€ ìœ„ ì£¼ì œì™€ ê´€ë ¨ìˆëŠ” **í•µì‹¬ í•™ìŠµ ìë£Œ**ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

âœ… KEEP ê¸°ì¤€:
- ì£¼ì œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ì‹œê° ìë£Œ (ì°¨íŠ¸, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨, ë„í‘œ, ë§Œí™”, ì‚¬ì§„)
- ì£¼ë³€ í…ìŠ¤íŠ¸ì™€ ê¸´ë°€í•˜ê²Œ ì—°ê²°ëœ í•µì‹¬ ì½˜í…ì¸ 

âŒ DISCARD ê¸°ì¤€:
- ì¥ì‹ìš© ì´ë¯¸ì§€ (ì•„ì´ì½˜, ë°°ê²½, í…Œë‘ë¦¬, ë‹¨ìˆœ ë„í˜•)
- í•™ìŠµ ìƒí™© ë¬˜ì‚¬ ì‚½í™” (ì„ ìƒë‹˜/í•™ìƒ ê·¸ë¦¼, ê³µë¶€í•˜ëŠ” ëª¨ìŠµ ë“±) âš ï¸ ì¤‘ìš”!
- ì£¼ì œì™€ ë¬´ê´€í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€

âš ï¸ ì£¼ì˜: "í•™ìŠµ ë§¥ë½ ì œê³µ"ì€ DISCARDì…ë‹ˆë‹¤. ì§„ì§œ êµìœ¡ ì½˜í…ì¸ ë§Œ KEEPí•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹: KEEP ë˜ëŠ” DISCARDë¡œ ì‹œì‘ + ì´ìœ  (1-2ë¬¸ì¥)
"""
                response = self.model.generate_content([image_part, prompt])
                return response.text.strip()
                
            except Exception as e:
                error_msg = str(e)
                
                if "429" in error_msg or "Resource exhausted" in error_msg:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 3
                        _log(f"      âš ï¸  Rate Limit, {wait_time}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(wait_time)
                        continue
                    else:
                        return "DISCARD: API rate limit exceeded"
                else:
                    return f"ERROR: {error_msg}"
        
        return "DISCARD: Failed after all retries"

    def run(self, source_path: str):
        """ì´ë¯¸ì§€ í•„í„°ë§ ì‹¤í–‰"""
        from pathlib import Path
        
        file_ext = Path(source_path).suffix.lower()
        _log(f"\nğŸ” ë¶„ì„ ì‹œì‘: {os.path.basename(source_path)} ({file_ext})")
        
        if self.auto_extract:
            self.extract_keywords_from_document(source_path)
        
        extractor = UniversalImageExtractor()
        all_meta = extractor.extract(source_path)
        
        _log("\n" + "="*120)
        _log(f"{'Slide':<6} | {'Size':<6} | {'Filter':<12} | {'Result':<12} | {'Reason'}")
        _log("-" * 120)

        final_core = []
        stats = {
            'total': len(all_meta),
            'rule_pass': 0,
            'rule_drop': 0,
            'ai_keep': 0,
            'ai_drop': 0,
        }
        
        for meta in all_meta:
            decision_type, s1_reason = self.step1_rule_check(meta)
            
            final_status = ""
            filter_stage = ""
            detail_reason = ""

            if decision_type == "INCLUDE":
                meta.is_core_content = True
                filter_stage = "1ì°¨ (Rule)"
                final_status = "âœ… PASS"
                detail_reason = s1_reason
                final_core.append(meta)
                stats['rule_pass'] += 1
                
            elif decision_type == "PENDING":
                filter_stage = "2ì°¨ (AI)"
                ai_res = self.step2_gemini_check(meta)
                
                if ai_res.upper().startswith("KEEP"):
                    meta.is_core_content = True
                    final_status = "âœ… KEEP"
                    stats['ai_keep'] += 1
                    final_core.append(meta)
                else:
                    final_status = "âŒ DROP"
                    stats['ai_drop'] += 1
                    
                detail_reason = ai_res.replace('\n', ' ')
                
            else:
                filter_stage = "1ì°¨ (Rule)"
                final_status = "âŒ DROP"
                detail_reason = s1_reason
                stats['rule_drop'] += 1

            wrapped_reason = textwrap.wrap(detail_reason, width=70)
            _log(f"{meta.slide_number:<6} | {meta.area_percentage:>5.1f}% | {filter_stage:<12} | {final_status:<12} | {wrapped_reason[0]}")
            for line in wrapped_reason[1:]:
                _log(f"{'':<6} | {'':<6} | {'':<12} | {'':<12} | {line}")
            _log("-" * 120)

        _log("\n" + "="*120)
        _log("ğŸ“Š ìµœì¢… ê²°ê³¼")
        _log("="*120)
        
        _log(f"\nì´ ì´ë¯¸ì§€: {stats['total']}ê°œ")
        _log(f"\n[1ì°¨ í•„í„° - ê·œì¹™ ê¸°ë°˜]")
        _log(f"  âœ… í†µê³¼: {stats['rule_pass']}ê°œ")
        _log(f"  âŒ ì œì™¸: {stats['rule_drop']}ê°œ")
        _log(f"  âš ï¸  2ì°¨ ì´ë™: {stats['ai_keep'] + stats['ai_drop']}ê°œ")
        
        _log(f"\n[2ì°¨ í•„í„° - AI íŒë‹¨]")
        _log(f"  âœ… í†µê³¼: {stats['ai_keep']}ê°œ")
        _log(f"  âŒ ì œì™¸: {stats['ai_drop']}ê°œ")
        
        total_keep = stats['rule_pass'] + stats['ai_keep']
        total_drop = stats['rule_drop'] + stats['ai_drop']
        
        _log(f"\n{'='*120}")
        _log(f"ğŸ’ ìµœì¢… í•µì‹¬ ì´ë¯¸ì§€: {total_keep}ê°œ (1ì°¨: {stats['rule_pass']}ê°œ + 2ì°¨: {stats['ai_keep']}ê°œ)")
        _log(f"ğŸ—‘ï¸  ì œì™¸ëœ ì´ë¯¸ì§€: {total_drop}ê°œ")
        if stats['total'] > 0:
            _log(f"ğŸ’° Vision API ì‚¬ìš©: {stats['ai_keep'] + stats['ai_drop']}íšŒ ({(stats['ai_keep'] + stats['ai_drop'])/stats['total']*100:.1f}%)")
        _log(f"{'='*120}\n")
        
        return final_core


if __name__ == "__main__":
    import sys
    
    _log("\n" + "="*120)
    _log("ğŸ¯ Improved Hybrid Filter V3 - ì´ë¯¸ì§€ í•„í„°ë§ (pdfplumber)")
    _log("="*120)
    
    if len(sys.argv) > 1:
        source_file = sys.argv[1]
        
        if not os.path.exists(source_file):
            _log(f"\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_file}")
            sys.exit(1)
        
        auto_extract = True
        if len(sys.argv) > 2 and sys.argv[2] in ['--no-auto', '-n']:
            auto_extract = False
            _log("\nâš ï¸  ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ ë¹„í™œì„±í™”")
        else:
            _log("\nâœ… ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™”")
        
        try:
            pipeline = ImprovedHybridFilterPipeline(auto_extract_keywords=auto_extract)
            core_images = pipeline.run(source_file)
            
            _log(f"\n{'='*120}")
            _log(f"âœ… ì™„ë£Œ! í•µì‹¬ ì´ë¯¸ì§€: {len(core_images)}ê°œ")
            _log(f"{'='*120}\n")
            
        except Exception as e:
            _log(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    else:
        _log("\nì‚¬ìš©ë²•:")
        _log("  python improved_hybrid_filter_v3.py <íŒŒì¼ê²½ë¡œ>")
        _log("\nì˜ˆì‹œ:")
        _log("  python improved_hybrid_filter_v3.py ì¤‘ë“±êµ­ì–´1.pdf")
        _log("\nâœ… V3 ê°œì„ ì‚¬í•­:")
        _log("  - PyMuPDF (AGPL) â†’ pdfplumber (MIT) ì „í™˜")
        _log("  - ë¼ì´ì„ ìŠ¤ ë¬¸ì œ í•´ê²°")
        _log("  - OCR ê¸°ëŠ¥ ì™„ì „ ìœ ì§€ (pypdfium2 + PaddleOCR)")
        _log("  - í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì¤‘ì²© ê°ì§€ ìœ ì§€")
        _log("  - ìƒ‰ìƒ ë³µì¡ë„ í•„í„° ì¶”ê°€ (í…ìŠ¤íŠ¸ ìƒì ì œê±°) â­")
        _log("  - ê¸°ì¡´ v2 ê¸°ëŠ¥ ëª¨ë‘ ìœ ì§€")
        _log("="*120 + "\n")