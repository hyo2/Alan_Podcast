"""
Improved Hybrid Filter V4
==========================

V4 ë³€ê²½ì‚¬í•­:
- V2ì˜ ìœ ì—°í•œ ì¸ì¦ ë¡œì§ ì¶”ê°€ (í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜)
- V3ì˜ pdfplumber (MIT) ìœ ì§€
- ìƒ‰ìƒ ë³µì¡ë„ í•„í„° ìœ ì§€
- ì¸ì¦ ì‹¤íŒ¨ ì‹œ graceful degradation

í•µì‹¬ ê¸°ëŠ¥:
- PyMuPDF (AGPL) â†’ pdfplumber (MIT) ì „í™˜
- ë¼ì´ì„ ìŠ¤ ë¬¸ì œ í•´ê²°
- ìƒ‰ìƒ ë³µì¡ë„ í•„í„° (í…ìŠ¤íŠ¸ ìƒì ë°°ê²½ ì œê±°)
- í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì¸ì¦ (í”„ë¡œë•ì…˜ ëŒ€ì‘)
"""

import os
import textwrap
import json
from dataclasses import dataclass
from typing import List, Dict
from pptx import Presentation
from vertexai.generative_models import Part
import logging

# âœ… ë¹„ìš© ê³„ì‚° ìœ í‹¸ë¦¬í‹° import
try:
    from .pricing import calculate_vision_cost, format_cost
except ImportError:
    # ë…ë¦½ ì‹¤í–‰ ì‹œ
    import sys
    sys.path.insert(0, os.path.dirname(__file__))
    from pricing import calculate_vision_cost, format_cost

logger = logging.getLogger(__name__)

def _resolve_vertex_sa_file() -> str | None:
    # í”„ë¡œì íŠ¸ì—ì„œ ì“°ëŠ” í‚¤ ìš°ì„ ìˆœìœ„
    # NOTE: VERTEX_AI_SERVICE_ACCOUNT_JSON(=JSON ë¬¸ìì—´)ì€ main.pyì˜ patch_vertex_ai_env()ì—ì„œ
    # íŒŒì¼ë¡œ ë³€í™˜ í›„ GOOGLE_APPLICATION_CREDENTIALSë¡œ ì—°ê²°ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” "ê²½ë¡œ"ë§Œ í™•ì¸í•œë‹¤.
    for key in ("VERTEX_AI_SERVICE_ACCOUNT_FILE", "GOOGLE_APPLICATION_CREDENTIALS"):
        p = os.getenv(key)
        if p and os.path.exists(p):
            return p
    return None

def get_vertex_text_model():
    """
    í‚¤ì›Œë“œ ì¶”ì¶œ/ì´ë¯¸ì§€ íŒë‹¨(vision)ì—ì„œ ì“°ëŠ” Gemini ëª¨ë¸ lazy init.
    - ì¸ì¦ íŒŒì¼ ì—†ìœ¼ë©´ None ë°˜í™˜ (ë¡œì»¬ ë°ëª¨ì—ì„œ visionë§Œ ìŠ¤í‚µ ê°€ëŠ¥)
    """
    try:
        sa_file = _resolve_vertex_sa_file()
        if not sa_file:
            logger.warning("â„¹ï¸ Vertex ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ì´ ì—†ì–´ Gemini í˜¸ì¶œì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return None

        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = sa_file

        import vertexai
        from vertexai.generative_models import GenerativeModel

        project_id = os.getenv("VERTEX_AI_PROJECT_ID") or os.getenv("GOOGLE_CLOUD_PROJECT")
        location = os.getenv("VERTEX_AI_REGION", "us-central1")

        if project_id:
            vertexai.init(project=project_id, location=location)
        else:
            vertexai.init(location=location)

        model_name = os.getenv("VERTEX_AI_MODEL_TEXT", "gemini-2.5-flash")
        return GenerativeModel(model_name)

    except Exception as e:
        logger.exception(f"Vertex/Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
    
model = None

def get_global_model():
    global model
    if model is None:
        model = get_vertex_text_model()
    return model

@dataclass
class ImageMetadata:
    image_id: str
    slide_number: int
    area_percentage: float
    left: float
    top: float
    adjacent_text: str
    slide_title: str
    image_bytes: bytes = None
    is_core_content: bool = False
    filter_reason: str = ""

# 1. í†µí•© ì´ë¯¸ì§€ ì¶”ì¶œê¸° (PPTX + PDF ì§€ì›)
class UniversalImageExtractor:
    """
    ëª¨ë“  í˜•ì‹ì—ì„œ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    V3: pdfplumber (MIT) ì‚¬ìš©
    """
    
    def extract(self, file_path: str) -> List[ImageMetadata]:
        from pathlib import Path
        
        ext = Path(file_path).suffix.lower()
        
        if ext == '.pptx':
            return self._extract_from_pptx(file_path)
        elif ext == '.pdf':
            return self._extract_from_pdf_v3(file_path)  # âœ… v3ë¡œ ë³€ê²½
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
    
    def _extract_from_pptx(self, pptx_path: str) -> List[ImageMetadata]:
        """PPTXì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹)"""
        if not os.path.exists(pptx_path):
            return []
        
        prs = Presentation(pptx_path)
        metadata_list = []
        slide_width, slide_height = prs.slide_width.inches, prs.slide_height.inches
        slide_area = slide_width * slide_height

        for s_idx, slide in enumerate(prs.slides, 1):
            slide_title = slide.shapes.title.text if slide.shapes.title else "No Title"
            all_text = " ".join([s.text for s in slide.shapes if hasattr(s, "text")])
            
            img_idx = 1
            for shape in slide.shapes:
                if shape.shape_type == 13 or hasattr(shape, 'image'):
                    w, h = shape.width.inches, shape.height.inches
                    area_pct = ((w * h) / slide_area) * 100
                    metadata_list.append(ImageMetadata(
                        image_id=f"S{s_idx:02d}_IMG{img_idx:03d}",
                        slide_number=s_idx,
                        area_percentage=area_pct,
                        left=shape.left.inches,
                        top=shape.top.inches,
                        adjacent_text=all_text.replace('\n', ' ').strip(),
                        slide_title=slide_title,
                        image_bytes=shape.image.blob
                    ))
                    img_idx += 1
        
        return metadata_list
    
    def _extract_text_with_ocr(self, pdf_path: str, page_num: int, min_length: int = 100) -> str:
        """
        í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•„ìš”ì‹œ OCR)
        V3: pdfplumber + pdf2image + PaddleOCR
        """
        # ===== 1. pdfplumberë¡œ ë¨¼ì € ì‹œë„ =====
        try:
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                page = pdf.pages[page_num]
                text = page.extract_text() or ""
                text_length = len(text.strip())
                
                if text_length >= min_length:
                    return text
        except:
            text_length = 0
        
        # ===== 2. í…ìŠ¤íŠ¸ ë¶€ì¡± â†’ OCR ì‹¤í–‰ =====
        try:
            from paddleocr import PaddleOCR
            from pdf2image import convert_from_path
            import numpy as np
            
            if not hasattr(self, '_ocr_engine'):
                os.environ['FLAGS_log_level'] = '3'
                os.environ['PPOCR_SHOW_LOG'] = 'False'
                
                print(f"      â†’ PaddleOCR ì´ˆê¸°í™” ì¤‘...")
                self._ocr_engine = PaddleOCR(lang='korean', use_textline_orientation=True)
            
            # ===== pdf2imageë¡œ í•´ë‹¹ í˜ì´ì§€ë§Œ ì´ë¯¸ì§€ë¡œ ë³€í™˜ =====
            # first_pageì™€ last_pageë¥¼ 1-indexedë¡œ ì§€ì •
            images = convert_from_path(
                pdf_path, 
                first_page=page_num + 1,  # 1-indexed
                last_page=page_num + 1,
                dpi=150
            )
            
            if not images:
                print(f"      â†’ PDF ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨")
                return text
            
            img = images[0]
            img_array = np.array(img)
            
            # ===== OCR ì‹¤í–‰ =====
            result = self._ocr_engine.ocr(img_array)
            
            if result and result[0]:
                lines = []
                for line in result[0]:
                    if line and len(line) >= 2:
                        ocr_text = line[1][0]
                        lines.append(ocr_text)
                
                ocr_result = "\n".join(lines)
                print(f"      â†’ OCR ì™„ë£Œ: {text_length}ì â†’ {len(ocr_result)}ì")
                return ocr_result if ocr_result else text
        
        except ImportError:
            print(f"      â†’ PaddleOCR/pdf2image ë¯¸ì„¤ì¹˜, í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©")
            return text
        except Exception as e:
            print(f"      âš ï¸  OCR ì‹¤íŒ¨: {e}")
            return text
        
        return text
    
    def _extract_text_bboxes_with_ocr(self, pdf_path: str, page_num: int) -> List[Dict]:
        """
        í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ (OCR í™œìš©)
        
        Returns:
            [{'x0', 'top', 'x1', 'bottom'}, ...]
        """
        text_bboxes = []
        
        # ===== 1. pdfplumberë¡œ ë¨¼ì € ì‹œë„ =====
        try:
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                page = pdf.pages[page_num]
                chars = page.chars
                
                if chars and len(chars) > 0:
                    # í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ìˆìŒ
                    for char in chars:
                        text_bboxes.append({
                            'x0': char['x0'],
                            'top': char['top'],
                            'x1': char['x1'],
                            'bottom': char['bottom']
                        })
                    
                    print(f"      â†’ pdfplumberë¡œ {len(text_bboxes)}ê°œ ë¬¸ì bbox ì¶”ì¶œ")
                    return text_bboxes
        except:
            pass
        
        # ===== 2. í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì—†ìŒ â†’ OCRë¡œ bbox ì¶”ì¶œ =====
        try:
            from paddleocr import PaddleOCR
            from pdf2image import convert_from_path
            import numpy as np
            
            if not hasattr(self, '_ocr_engine'):
                os.environ['FLAGS_log_level'] = '3'
                os.environ['PPOCR_SHOW_LOG'] = 'False'
                self._ocr_engine = PaddleOCR(lang='korean', use_textline_orientation=True)
            
            # pdf â†’ image
            images = convert_from_path(
                pdf_path, 
                first_page=page_num + 1,
                last_page=page_num + 1,
                dpi=150
            )
            
            if not images:
                return []
            
            img = images[0]
            img_array = np.array(img)
            
            # OCR ì‹¤í–‰
            result = self._ocr_engine.ocr(img_array)
            
            if result and result[0]:
                # OCR ê²°ê³¼ì—ì„œ bbox ì¶”ì¶œ
                for line in result[0]:
                    if line and len(line) >= 2:
                        # line[0]: bbox [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]
                        bbox_points = line[0]
                        
                        # bboxë¥¼ x0, top, x1, bottomìœ¼ë¡œ ë³€í™˜
                        x_coords = [p[0] for p in bbox_points]
                        y_coords = [p[1] for p in bbox_points]
                        
                        text_bboxes.append({
                            'x0': min(x_coords),
                            'top': min(y_coords),
                            'x1': max(x_coords),
                            'bottom': max(y_coords)
                        })
                
                print(f"      â†’ OCRë¡œ {len(text_bboxes)}ê°œ í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ")
                return text_bboxes
        
        except Exception as e:
            print(f"      âš ï¸  í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
        
        return []
    
    def _calculate_text_overlap(self, img_bbox: tuple, text_bboxes: List[Dict]) -> float:
        """
        ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì¤‘ì²© ë¹„ìœ¨ ê³„ì‚°
        
        Args:
            img_bbox: (x0, top, x1, bottom)
            text_bboxes: [{'x0', 'top', 'x1', 'bottom'}, ...]
        
        Returns:
            ì¤‘ì²© ë¹„ìœ¨ (0.0 ~ 1.0)
        """
        if not text_bboxes:
            return 0.0
        
        img_x0, img_top, img_x1, img_bottom = img_bbox
        img_area = (img_x1 - img_x0) * (img_bottom - img_top)
        
        if img_area <= 0:
            return 0.0
        
        overlap_area = 0.0
        
        for text_bbox in text_bboxes:
            # êµì§‘í•© ê³„ì‚°
            x0 = max(img_x0, text_bbox['x0'])
            top = max(img_top, text_bbox['top'])
            x1 = min(img_x1, text_bbox['x1'])
            bottom = min(img_bottom, text_bbox['bottom'])
            
            if x0 < x1 and top < bottom:
                overlap_area += (x1 - x0) * (bottom - top)
        
        overlap_ratio = overlap_area / img_area
        
        return overlap_ratio
    
    def _calculate_color_complexity(self, image_bytes) -> int:
        """
        ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ ë³µì¡ë„ ê³„ì‚° (ê³ ìœ  ìƒ‰ìƒ ìˆ˜)
        
        í…ìŠ¤íŠ¸ ìƒì ë°°ê²½: 10-300ê°œ (ë‹¨ì¡°ë¡œìš´ ìƒ‰ìƒ)
        ì§„ì§œ ì½˜í…ì¸ : 500+ ê°œ (ë³µì¡í•œ ìƒ‰ìƒ)
        
        Args:
            image_bytes: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
        
        Returns:
            ê³ ìœ  ìƒ‰ìƒ ìˆ˜ (0 ~ 10000+)
        """
        try:
            from PIL import Image
            import io
            
            # ë°”ì´ë„ˆë¦¬ â†’ PIL Image
            img = Image.open(io.BytesIO(image_bytes))
            
            # RGB ë³€í™˜
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ)
            max_size = 500
            if img.width > max_size or img.height > max_size:
                ratio = min(max_size / img.width, max_size / img.height)
                new_size = (int(img.width * ratio), int(img.height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # ê³ ìœ  ìƒ‰ìƒ ìˆ˜ ê³„ì‚°
            colors = img.getcolors(maxcolors=10000)
            
            if colors:
                unique_colors = len(colors)
            else:
                # 10000ê°œ ì´ìƒ ìƒ‰ìƒ
                unique_colors = 10000
            
            return unique_colors
        
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 10000  # ì‹¤íŒ¨ ì‹œ ë³µì¡í•œ ì´ë¯¸ì§€ë¡œ ê°„ì£¼
    
    def _extract_page_title(self, page_text: str) -> str:
        """í˜ì´ì§€ ì œëª© ì¶”ì¶œ"""
        lines = page_text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if len(line) > 3 and not line.startswith('â˜'):
                return line[:50]
        return "í˜ì´ì§€ ì œëª© ì—†ìŒ"
    
    def _extract_from_pdf_v3(self, pdf_path: str) -> List[ImageMetadata]:
        """
        PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (V3: pdfplumber ì‚¬ìš©)
        
        í•µì‹¬ ë³€ê²½:
        - PyMuPDF â†’ pdfplumber (MIT ë¼ì´ì„ ìŠ¤)
        - ê¸°ëŠ¥ ë™ì¼í•˜ê²Œ ìœ ì§€
        """
        try:
            import pdfplumber  # âœ… pdfplumber ì‚¬ìš©
        except ImportError:
            print("   âŒ pdfplumberê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   pip install pdfplumber")
            return []
        
        if not os.path.exists(pdf_path):
            return []
        
        metadata_list = []
        
        # í•„í„°ë§ ê¸°ì¤€
        MIN_WIDTH = 50          # 40 â†’ 50
        MIN_HEIGHT = 50         # 40 â†’ 50
        MIN_AREA_PCT = 5.0      # 3% â†’ 5% (ì‘ì€ ì•„ì´ì½˜ ì œê±°)
        MAX_AREA_PCT = 90.0     # 90% ì´ìƒ: ë°°ê²½
        MIN_PIXEL_AREA = 2000   # 1000 â†’ 2000
        MAX_ASPECT_RATIO = 6.0  # 6:1 ì´ìƒ: ì œëª©/í…ìŠ¤íŠ¸
        
        total_images = 0
        filtered_background = 0
        filtered_aspect = 0
        filtered_area = 0
        filtered_size = 0
        filtered_text_overlap = 0  # âœ… ì¶”ê°€
        
        try:
            # ===== pdfplumberë¡œ PDF ì—´ê¸° =====
            with pdfplumber.open(pdf_path) as pdf:
                
                for page_num, page in enumerate(pdf.pages):
                    # í˜ì´ì§€ ì •ë³´
                    page_width = page.width
                    page_height = page.height
                    page_area = page_width * page_height
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR í¬í•¨)
                    page_text = self._extract_text_with_ocr(pdf_path, page_num, min_length=100)
                    page_title = self._extract_page_title(page_text)
                    
                    # ===== í…ìŠ¤íŠ¸ bbox ì¶”ì¶œ (ì¤‘ì²© ì²´í¬ìš©) =====
                    text_bboxes = self._extract_text_bboxes_with_ocr(pdf_path, page_num)
                    
                    # ===== pdfplumberë¡œ ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° =====
                    images = page.images
                    total_images += len(images)
                    
                    print(f"      [P{page_num+1}] ì´ {len(images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
                    
                    # ===== 1ë‹¨ê³„: ìœ íš¨í•œ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ìˆ˜ì§‘ (ë ˆì´ì–´ íŒë‹¨ìš©) =====
                    valid_image_indices = []
                    for idx, img in enumerate(images):
                        stream = img.get('stream')
                        if stream:
                            try:
                                if hasattr(stream, 'get_data'):
                                    data = stream.get_data()
                                elif hasattr(stream, 'rawdata'):
                                    data = stream.rawdata
                                else:
                                    continue
                                
                                # ìœ íš¨í•œ ì´ë¯¸ì§€ í˜•ì‹ì¸ì§€ ì²´í¬
                                if (data.startswith(b'\xff\xd8\xff') or 
                                    data.startswith(b'\x89PNG\r\n\x1a\n') or
                                    data.startswith(b'GIF89a') or 
                                    data.startswith(b'GIF87a')):
                                    valid_image_indices.append(idx)
                            except:
                                pass
                    
                    total_valid = len(valid_image_indices)
                    print(f"      [P{page_num+1}] â†’ ìœ íš¨í•œ ì´ë¯¸ì§€: {total_valid}ê°œ (ë ˆì´ì–´ ìˆœì„œ í™œìš©)")
                    
                    # ===== 2ë‹¨ê³„: ì´ë¯¸ì§€ í•„í„°ë§ (ë ˆì´ì–´ ìˆœì„œ ê³ ë ¤) =====
                    for img_idx, img in enumerate(images):
                        try:
                            # ===== bbox ì •ë³´ (pdfplumber í˜•ì‹) =====
                            x0 = img['x0']
                            top = img['top']
                            x1 = img['x1']
                            bottom = img['bottom']
                            
                            width = x1 - x0
                            height = bottom - top
                            area_pct = (width * height) / page_area * 100
                            
                            debug_msg = f"      [P{page_num+1}] {area_pct:.1f}%"
                            
                            # ===== í•„í„° 1: ë°°ê²½ ì œì™¸ (90% ì´ìƒ) =====
                            if area_pct > MAX_AREA_PCT:
                                filtered_background += 1
                                print(debug_msg + f" â†’ ë°°ê²½ ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 2: ê°€ë¡œì„¸ë¡œë¹„ =====
                            if width > 0 and height > 0:
                                aspect_ratio = max(width, height) / min(width, height)
                                if aspect_ratio > MAX_ASPECT_RATIO:
                                    filtered_aspect += 1
                                    print(debug_msg + f" â†’ ê°€ë¡œì„¸ë¡œë¹„ ì œì™¸ ({aspect_ratio:.1f}:1) âŒ")
                                    continue
                            
                            # ===== í•„í„° 3: ì‘ì€ ë©´ì  =====
                            pixel_area = width * height
                            if pixel_area < MIN_PIXEL_AREA:
                                filtered_area += 1
                                print(debug_msg + f" â†’ ì‘ì€ ë©´ì  ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 4: ì ˆëŒ€ í¬ê¸° =====
                            if width < MIN_WIDTH or height < MIN_HEIGHT:
                                filtered_size += 1
                                print(debug_msg + f" â†’ ì‘ì€ í¬ê¸° ì œì™¸ âŒ")
                                continue
                            
                            # ===== í•„í„° 5: ìƒëŒ€ í¬ê¸° =====
                            if area_pct < MIN_AREA_PCT:
                                filtered_size += 1
                                print(debug_msg + f" â†’ ìƒëŒ€ í¬ê¸° ì œì™¸ ({area_pct:.1f}%) âŒ")
                                continue
                            
                            # ===== í†µê³¼! =====
                            print(debug_msg + " â†’ ìµœì¢… ì¶”ì¶œ âœ…âœ…âœ…")
                            
                            # ===== í•„í„° 6: ì´ë¯¸ì§€ ìœ íš¨ì„± + í…ìŠ¤íŠ¸ ì¤‘ì²© + ìƒ‰ìƒ ë³µì¡ë„ ì²´í¬ â­â­â­ =====
                            # ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ì¶”ì¶œ
                            stream = img.get('stream')
                            
                            if stream:
                                if hasattr(stream, 'get_data'):
                                    image_bytes = stream.get_data()
                                elif hasattr(stream, 'rawdata'):
                                    image_bytes = stream.rawdata
                                else:
                                    print(debug_msg + " â†’ ë°”ì´ë„ˆë¦¬ ì¶”ì¶œ ì‹¤íŒ¨ âš ï¸")
                                    continue
                            else:
                                print(debug_msg + " â†’ stream ì—†ìŒ âš ï¸")
                                continue
                            
                            # ===== í•„í„° 6-1: ìœ íš¨í•œ ì´ë¯¸ì§€ í˜•ì‹ë§Œ ì²˜ë¦¬ =====
                            is_valid_image = False
                            if image_bytes.startswith(b'\xff\xd8\xff'):  # JPEG
                                is_valid_image = True
                            elif image_bytes.startswith(b'\x89PNG\r\n\x1a\n'):  # PNG
                                is_valid_image = True
                            elif image_bytes.startswith(b'GIF89a') or image_bytes.startswith(b'GIF87a'):  # GIF
                                is_valid_image = True
                            
                            if not is_valid_image:
                                filtered_text_overlap += 1
                                print(debug_msg + " â†’ ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ âŒ")
                                continue
                            
                            # ===== ë ˆì´ì–´ ìˆœì„œ íŒë‹¨ =====
                            # í˜„ì¬ ì´ë¯¸ì§€ê°€ ìœ íš¨í•œ ì´ë¯¸ì§€ ì¤‘ ëª‡ ë²ˆì§¸ì¸ì§€ í™•ì¸
                            try:
                                valid_rank = valid_image_indices.index(img_idx)
                                is_top_layer = (total_valid - valid_rank) <= 2  # ë§ˆì§€ë§‰ 1-2ê°œ
                            except ValueError:
                                is_top_layer = False
                            
                            if is_top_layer:
                                print(debug_msg + f" â†’ ìƒìœ„ ë ˆì´ì–´ ({valid_rank+1}/{total_valid}) ğŸ”")
                            
                            # í…ìŠ¤íŠ¸ ì¤‘ì²© ê³„ì‚°
                            img_bbox = (x0, top, x1, bottom)
                            overlap_ratio = self._calculate_text_overlap(img_bbox, text_bboxes)
                            
                            # ìƒ‰ìƒ ë³µì¡ë„ ê³„ì‚°
                            color_count = self._calculate_color_complexity(image_bytes)
                            
                            # ===== ë ˆì´ì–´ ê¸°ë°˜ ì¤‘ì²© í—ˆìš© =====
                            # ìƒìœ„ ë ˆì´ì–´(ì• ë‹ˆë©”ì´ì…˜ ë“±)ëŠ” ì¤‘ì²©ì´ ì •ìƒì´ë¯€ë¡œ í—ˆìš©ëŸ‰ ì¦ê°€
                            if is_top_layer:
                                overlap_threshold_high = 0.60  # 60%ê¹Œì§€ í—ˆìš©
                                overlap_threshold_mid = 0.50   # 50%ê¹Œì§€ í—ˆìš©
                            else:
                                overlap_threshold_high = 0.40  # ê¸°ì¡´ 40%
                                overlap_threshold_mid = 0.35   # ê¸°ì¡´ 35%
                            
                            # íŒë‹¨ ë¡œì§ (ìƒ‰ìƒ + ì¤‘ì²© + ë©´ì  + ë ˆì´ì–´)
                            is_textbox = False
                            filter_reason = ""
                            
                            # ê·œì¹™ 0: ëŒ€í˜• ë©´ì  + ë†’ì€ ì¤‘ì²© â†’ ì œì™¸
                            # (ìƒìœ„ ë ˆì´ì–´ëŠ” í—ˆìš©ëŸ‰ ì¦ê°€: 35% â†’ 50%)
                            if area_pct >= 65.0 and overlap_ratio >= overlap_threshold_mid:
                                is_textbox = True
                                filter_reason = f"ëŒ€í˜•({area_pct:.1f}%)+ê³ ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                            
                            # ê·œì¹™ 1: ë‹¨ì¡°ë¡œìš´ ìƒ‰ìƒ (< 500ê°œ) â†’ í…ìŠ¤íŠ¸ ìƒì ê°€ëŠ¥ì„± ë†’ìŒ
                            elif color_count < 500:
                                # ìƒìœ„ ë ˆì´ì–´ê°€ ì•„ë‹ ë•Œë§Œ ì ìš© (ë°°ê²½ í…ìŠ¤íŠ¸ë°•ìŠ¤ ì œê±°ìš©)
                                if not is_top_layer:
                                    # ë‹¨ì¡°ìƒ‰ìƒ + ì•½ê°„ì˜ ì¤‘ì²©ì´ë¼ë„ ì œì™¸
                                    if overlap_ratio >= 0.03:  # 3% ì´ìƒ ì¤‘ì²©
                                        is_textbox = True
                                        filter_reason = f"ë‹¨ì¡°ìƒ‰ìƒ({color_count}ê°œ)+ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                                    # ë‹¨ì¡°ìƒ‰ìƒ + í° ë©´ì  (10% ì´ìƒ)
                                    elif area_pct >= 10.0:
                                        is_textbox = True
                                        filter_reason = f"ë‹¨ì¡°ìƒ‰ìƒ({color_count}ê°œ)+ëŒ€í˜•({area_pct:.1f}%)"
                                    # ì¤‘ì²© ì—†ì–´ë„ ë§¤ìš° ë‹¨ì¡°ë¡œìš°ë©´ (< 100ê°œ) ì œì™¸
                                    elif color_count < 100:
                                        is_textbox = True
                                        filter_reason = f"ë§¤ìš°ë‹¨ì¡°({color_count}ê°œ)"
                            
                            # ê·œì¹™ 2: ë³µì¡í•œ ìƒ‰ìƒ (>= 1000ê°œ) â†’ ì§„ì§œ ì½˜í…ì¸  ê°€ëŠ¥ì„±
                            elif color_count >= 1000:
                                # ìƒìœ„ ë ˆì´ì–´ëŠ” í—ˆìš©ëŸ‰ ì¦ê°€: 40% â†’ 60%
                                if overlap_ratio >= overlap_threshold_high:
                                    is_textbox = True
                                    filter_reason = f"ê³ ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                                # else: í†µê³¼
                            
                            # ê·œì¹™ 3: ì¤‘ê°„ ë³µì¡ë„ (500-1000ê°œ) â†’ ì¤‘ì²© ë¹„ìœ¨ë¡œ íŒë‹¨
                            else:
                                # ìƒìœ„ ë ˆì´ì–´ê°€ ì•„ë‹ ë•Œë§Œ ì—„ê²©í•˜ê²Œ ì ìš©
                                if not is_top_layer:
                                    # ì¤‘ê°„ ìƒ‰ìƒ + ëŒ€í˜• ë©´ì 
                                    if area_pct >= 40.0 and overlap_ratio >= 0.15:
                                        is_textbox = True
                                        filter_reason = f"ì¤‘ê°„ìƒ‰ìƒ({color_count}ê°œ)+ëŒ€í˜•({area_pct:.1f}%)+ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                                    elif overlap_ratio >= 0.20:  # 20% ì´ìƒ
                                        is_textbox = True
                                        filter_reason = f"ì¤‘ê°„ìƒ‰ìƒ({color_count}ê°œ)+ì¤‘ì²©({overlap_ratio*100:.0f}%)"
                            
                            # ê²°ê³¼ ì²˜ë¦¬
                            if is_textbox:
                                filtered_text_overlap += 1
                                print(debug_msg + f" â†’ í…ìŠ¤íŠ¸ìƒì ì œì™¸ ({filter_reason}) âŒ")
                                continue
                            
                            # ìµœì¢… í†µê³¼ - ë©”íƒ€ë°ì´í„° ì €ì¥
                            
                            metadata_list.append(ImageMetadata(
                                image_id=f"P{page_num+1:02d}_IMG{len(metadata_list)+1:03d}",
                                slide_number=page_num + 1,
                                area_percentage=area_pct,
                                left=x0,
                                top=top,
                                adjacent_text=page_text.replace('\n', ' ').strip(),
                                slide_title=page_title,
                                image_bytes=image_bytes
                            ))
                        
                        except Exception as e:
                            print(f"      âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            continue
        
        except Exception as e:
            print(f"   âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
        
        # í†µê³„
        print(f"\n   ğŸ“Š PDF ì´ë¯¸ì§€ ë¶„ì„:")
        print(f"      - ì „ì²´ ì´ë¯¸ì§€: {total_images}ê°œ")
        print(f"   ğŸ” í•„í„°ë§ í†µê³„:")
        print(f"      - ë°°ê²½ ì œì™¸: {filtered_background}ê°œ")
        print(f"      - ê°€ë¡œì„¸ë¡œë¹„: {filtered_aspect}ê°œ")
        print(f"      - ì‘ì€ ë©´ì : {filtered_area}ê°œ")
        print(f"      - ì‘ì€ í¬ê¸°: {filtered_size}ê°œ")
        print(f"      - í…ìŠ¤íŠ¸ ìƒì (ìƒ‰ìƒ+ì¤‘ì²©): {filtered_text_overlap}ê°œ")  # âœ… ì¶”ê°€
        print(f"   âœ… ìµœì¢… ì¶”ì¶œ: {len(metadata_list)}ê°œ ì´ë¯¸ì§€\n")
        
        return metadata_list


# 2. ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ í•„í„° íŒŒì´í”„ë¼ì¸
class ImprovedHybridFilterPipeline:
    def __init__(self, auto_extract_keywords: bool = True):
        self.auto_extract = auto_extract_keywords
        
        self.UNIVERSAL_PATTERNS = [
            'í•™ìŠµ', 'í™œë™', 'ë¬¸ì œ', 'ì˜ˆì œ', 'ì—°ìŠµ',
            'ìƒê°', 'ì•Œì•„ë³´', 'ì‚´í´ë³´', 'ì •ë¦¬',
            'ëª©í‘œ', 'ê°œë…', 'ì›ë¦¬', 'ë²•ì¹™', 'ì •ì˜',
            'ë‹¨ì›', 'ì°¨ì‹œ',
            'ê·¸ë¦¼', 'ë„í‘œ', 'í‘œ', 'ì°¨íŠ¸', 'ê·¸ë˜í”„',
            'ì˜ˆì‹œ', 'ì‚¬ë¡€', 'ëª¨í˜•', 'êµ¬ì¡°'
        ]
        
        self.DECORATION_PATTERNS = [
            'ë¡œê³ ', 'logo', 'ì¶œì²˜', 'ì°¸ê³ ', 'ì•„ì´ì½˜', 'icon'
        ]
        
        self.document_keywords = []
        
        
        # âœ… Vision í† í° ì¶”ì 
        self.vision_tokens = {"keyword_extraction": 0, "image_filtering": 0, "total": 0}
        
        self.model = get_global_model()

    def extract_keywords_from_document(self, file_path: str):
        """ë¬¸ì„œì—ì„œ ìë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not self.auto_extract:
            return
        
        from pathlib import Path
        
        print("ğŸ“š ë¬¸ì„œ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ ì¤‘...")
        
        ext = Path(file_path).suffix.lower()
        all_text = []
        
        if ext == '.pptx':
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        all_text.append(shape.text)
        
        elif ext == '.pdf':
            import pdfplumber  # âœ… pdfplumber ì‚¬ìš©
            try:
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        text = page.extract_text()
                        if text:
                            all_text.append(text)
            except Exception as e:
                print(f"   âš ï¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨, ë²”ìš© íŒ¨í„´ë§Œ ì‚¬ìš©")
                return
        
        else:
            print(f"   âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
            return
        
        full_text = "\n".join(all_text)[:5000]
        
        prompt = f"""
ë‹¤ìŒ ê°•ì˜ ìë£Œì—ì„œ **í•µì‹¬ í‚¤ì›Œë“œ 20ê°œ**ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

# ë¬¸ì„œ ë‚´ìš©
{full_text}

# ì¡°ê±´
- ê°œë…ì–´, ì „ë¬¸ ìš©ì–´, ì£¼ì œì–´ë§Œ í¬í•¨
- JSON í˜•ì‹: {{"keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]}}
"""
        
        if self.model is None:
            print("   âš ï¸ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨(ì¸ì¦ ì—†ìŒ). í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ ìŠ¤í‚µ.")
            self.document_keywords = []
            return

        try:
            response = self.model.generate_content(prompt)
            
            # âœ… í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ë° ì €ì¥
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                token_count = usage.total_token_count
                print(f"   ğŸ’° [Vision-í‚¤ì›Œë“œ] Total tokens: {token_count:,}")
                
                # âœ… vision_tokensì— ì €ì¥
                self.vision_tokens["keyword_extraction"] = token_count
                self.vision_tokens["total"] += token_count
            
            text = response.text.strip()
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            self.document_keywords = data.get("keywords", [])
            
            print(f"   âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(self.document_keywords[:10])}")
        
        except Exception as e:
            print(f"   âš ï¸ ìë™ ì¶”ì¶œ ì‹¤íŒ¨, ë²”ìš© íŒ¨í„´ë§Œ ì‚¬ìš©")
            self.document_keywords = []

    def step1_rule_check(self, meta: ImageMetadata):
        """ê·œì¹™ ê¸°ë°˜ 1ì°¨ í•„í„°"""
        context = f"{meta.slide_title} {meta.adjacent_text}".lower()
        
        has_deco = any(kw in context for kw in self.DECORATION_PATTERNS)
        is_corner = (meta.left < 1.0 and meta.top < 1.0) or (meta.left > 8.0 and meta.top < 1.0)
        
        if is_corner and meta.area_percentage < 5.0 and not any(kw in context for kw in self.UNIVERSAL_PATTERNS):
            return "EXCLUDE", "Static Decoration (Corner)"
        
        if has_deco and meta.area_percentage < 8.0:
            return "EXCLUDE", "Decorative element"
        
        has_universal = any(p in context for p in self.UNIVERSAL_PATTERNS)
        has_document_kw = any(kw in context for kw in self.document_keywords)
        
        if meta.area_percentage > 15.0 and (has_universal or has_document_kw):
            return "INCLUDE", f"Core content ({meta.area_percentage:.1f}% + pattern)"
        
        if has_document_kw and meta.area_percentage > 10.0:
            matched = [kw for kw in self.document_keywords if kw in context]
            return "INCLUDE", f"Document keyword: {', '.join(matched[:2])}"
        
        return "PENDING", "Requires AI Vision Check"

    def step2_gemini_check(self, meta: ImageMetadata, max_retries=3):
        """AI Visionìœ¼ë¡œ 2ì°¨ íŒë‹¨"""
        import time
        
        
        if self.model is None:
            return "DISCARD: Gemini unavailable (no credentials)", 0, 0.0

        for attempt in range(max_retries):
            try:
                image_part = Part.from_data(data=meta.image_bytes, mime_type="image/png")
                
                keyword_list = ', '.join(list(self.document_keywords)[:15]) if self.document_keywords else "ì¼ë°˜ í•™ìŠµ ë‚´ìš©"
                
                prompt = f"""
ì´ ê°•ì˜ì˜ í•µì‹¬ ì£¼ì œ: {keyword_list}

ì£¼ë³€ í…ìŠ¤íŠ¸: "{meta.adjacent_text}"

ì´ ì´ë¯¸ì§€ê°€ ìœ„ ì£¼ì œì™€ ê´€ë ¨ìˆëŠ” **í•µì‹¬ í•™ìŠµ ìë£Œ**ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

âœ… KEEP ê¸°ì¤€:
- ì£¼ì œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ì‹œê° ìë£Œ (ì°¨íŠ¸, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨, ë„í‘œ, ë§Œí™”, ì‚¬ì§„)
- ì£¼ë³€ í…ìŠ¤íŠ¸ì™€ ê¸´ë°€í•˜ê²Œ ì—°ê²°ëœ í•µì‹¬ ì½˜í…ì¸ 

âŒ DISCARD ê¸°ì¤€:
- ì¥ì‹ìš© ì´ë¯¸ì§€ (ì•„ì´ì½˜, ë°°ê²½, í…Œë‘ë¦¬, ë‹¨ìˆœ ë„í˜•)
- í•™ìŠµ ìƒí™© ë¬˜ì‚¬ ì‚½í™” (ì„ ìƒë‹˜/í•™ìƒ ê·¸ë¦¼, ê³µë¶€í•˜ëŠ” ëª¨ìŠµ ë“±) âš ï¸ ì¤‘ìš”!
- ì£¼ì œì™€ ë¬´ê´€í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€

âš ï¸ ì£¼ì˜: "í•™ìŠµ ë§¥ë½ ì œê³µ"ì€ DISCARDì…ë‹ˆë‹¤. ì§„ì§œ êµìœ¡ ì½˜í…ì¸ ë§Œ KEEPí•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹: KEEP ë˜ëŠ” DISCARDë¡œ ì‹œì‘ + ì´ìœ  (1-2ë¬¸ì¥)
"""
                response = self.model.generate_content([image_part, prompt])
                
                # âœ… ì´ë¯¸ì§€ë³„ ìƒì„¸ í† í° ë¡œê¹…
                if hasattr(response, 'usage_metadata'):
                    usage = response.usage_metadata
                    self.vision_tokens["image_filtering"] += usage.total_token_count
                    self.vision_tokens["total"] += usage.total_token_count
                    print(f"      ğŸ“¸ Image #{meta.slide_number}: {usage.total_token_count:,} tokens")
                
                return response.text.strip()
                
            except Exception as e:
                error_msg = str(e)
                
                if "429" in error_msg or "Resource exhausted" in error_msg:
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 3
                        print(f"      âš ï¸  Rate Limit, {wait_time}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(wait_time)
                        continue
                    else:
                        return "DISCARD: API rate limit exceeded"
                else:
                    return f"ERROR: {error_msg}"
        
        return "DISCARD: Failed after all retries"

    def run(self, source_path: str):
        """ì´ë¯¸ì§€ í•„í„°ë§ ì‹¤í–‰"""
        from pathlib import Path
        
        file_ext = Path(source_path).suffix.lower()
        print(f"\nğŸ” ë¶„ì„ ì‹œì‘: {os.path.basename(source_path)} ({file_ext})")
        
        if self.auto_extract:
            self.extract_keywords_from_document(source_path)
        
        extractor = UniversalImageExtractor()
        all_meta = extractor.extract(source_path)
        
        print("\n" + "="*120)
        print(f"{'Slide':<6} | {'Size':<6} | {'Filter':<12} | {'Result':<12} | {'Reason'}")
        print("-" * 120)

        final_core = []
        stats = {
            'total': len(all_meta),
            'rule_pass': 0,
            'rule_drop': 0,
            'ai_keep': 0,
            'ai_drop': 0,
        }
        
        for meta in all_meta:
            decision_type, s1_reason = self.step1_rule_check(meta)
            
            final_status = ""
            filter_stage = ""
            detail_reason = ""

            if decision_type == "INCLUDE":
                meta.is_core_content = True
                filter_stage = "1ì°¨ (Rule)"
                final_status = "âœ… PASS"
                detail_reason = s1_reason
                final_core.append(meta)
                stats['rule_pass'] += 1
                
            elif decision_type == "PENDING":
                filter_stage = "2ì°¨ (AI)"
                ai_res = self.step2_gemini_check(meta)
                
                if ai_res.upper().startswith("KEEP"):
                    meta.is_core_content = True
                    final_status = "âœ… KEEP"
                    stats['ai_keep'] += 1
                    final_core.append(meta)
                else:
                    final_status = "âŒ DROP"
                    stats['ai_drop'] += 1
                    
                detail_reason = ai_res.replace('\n', ' ')
                
            else:
                filter_stage = "1ì°¨ (Rule)"
                final_status = "âŒ DROP"
                detail_reason = s1_reason
                stats['rule_drop'] += 1

            wrapped_reason = textwrap.wrap(detail_reason, width=70)
            print(f"{meta.slide_number:<6} | {meta.area_percentage:>5.1f}% | {filter_stage:<12} | {final_status:<12} | {wrapped_reason[0]}")
            for line in wrapped_reason[1:]:
                print(f"{'':<6} | {'':<6} | {'':<12} | {'':<12} | {line}")
            print("-" * 120)

        print("\n" + "="*120)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼")
        print("="*120)
        
        print(f"\nì´ ì´ë¯¸ì§€: {stats['total']}ê°œ")
        print(f"\n[1ì°¨ í•„í„° - ê·œì¹™ ê¸°ë°˜]")
        print(f"  âœ… í†µê³¼: {stats['rule_pass']}ê°œ")
        print(f"  âŒ ì œì™¸: {stats['rule_drop']}ê°œ")
        print(f"  âš ï¸  2ì°¨ ì´ë™: {stats['ai_keep'] + stats['ai_drop']}ê°œ")
        
        print(f"\n[2ì°¨ í•„í„° - AI íŒë‹¨]")
        print(f"  âœ… í†µê³¼: {stats['ai_keep']}ê°œ")
        print(f"  âŒ ì œì™¸: {stats['ai_drop']}ê°œ")
        
        total_keep = stats['rule_pass'] + stats['ai_keep']
        total_drop = stats['rule_drop'] + stats['ai_drop']
        
        print(f"\n{'='*120}")
        print(f"ğŸ’ ìµœì¢… í•µì‹¬ ì´ë¯¸ì§€: {total_keep}ê°œ (1ì°¨: {stats['rule_pass']}ê°œ + 2ì°¨: {stats['ai_keep']}ê°œ)")
        print(f"ğŸ—‘ï¸  ì œì™¸ëœ ì´ë¯¸ì§€: {total_drop}ê°œ")
        if stats['total'] > 0:
            print(f"ğŸ’° Vision API ì‚¬ìš©: {stats['ai_keep'] + stats['ai_drop']}íšŒ ({(stats['ai_keep'] + stats['ai_drop'])/stats['total']*100:.1f}%)")
        print(f"{'='*120}\n")
        
        # âœ… Vision í† í° ìƒì„¸ í†µê³„
        total_tokens = self.vision_tokens['total']
        total_cost = calculate_vision_cost(total_tokens)
        
        print(f"ğŸ’° Vision í† í° ì‚¬ìš© ìƒì„¸:")
        print(f"   ğŸ“ í‚¤ì›Œë“œ ì¶”ì¶œ: {self.vision_tokens['keyword_extraction']:,} tokens (1íšŒ)")
        print(f"   ğŸ“¸ ì´ë¯¸ì§€ í•„í„°ë§: {self.vision_tokens['image_filtering']:,} tokens ({stats['ai_keep'] + stats['ai_drop']}ê°œ ì´ë¯¸ì§€)")
        if stats['ai_keep'] + stats['ai_drop'] > 0:
            avg_tokens = self.vision_tokens['image_filtering'] / (stats['ai_keep'] + stats['ai_drop'])
            print(f"      - í‰ê· : {avg_tokens:.0f} tokens/image")
        print(f"   ğŸ“Š Total: {total_tokens:,} tokens")
        print(f"   ğŸ’µ ë¹„ìš©: {format_cost(total_cost)}")
        print()
        
        # vision_tokensì— ë¹„ìš© ì¶”ê°€
        self.vision_tokens['cost_usd'] = total_cost
        
        return {
            "images": final_core,
            "vision_tokens": self.vision_tokens
        }


if __name__ == "__main__":
    import sys
    
    print("\n" + "="*120)
    print("ğŸ¯ Improved Hybrid Filter V3 - ì´ë¯¸ì§€ í•„í„°ë§ (pdfplumber)")
    print("="*120)
    
    if len(sys.argv) > 1:
        source_file = sys.argv[1]
        
        if not os.path.exists(source_file):
            print(f"\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_file}")
            sys.exit(1)
        
        auto_extract = True
        if len(sys.argv) > 2 and sys.argv[2] in ['--no-auto', '-n']:
            auto_extract = False
            print("\nâš ï¸  ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ ë¹„í™œì„±í™”")
        else:
            print("\nâœ… ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™”")
        
        try:
            pipeline = ImprovedHybridFilterPipeline(auto_extract_keywords=auto_extract)
            core_images = pipeline.run(source_file)
            
            print(f"\n{'='*120}")
            print(f"âœ… ì™„ë£Œ! í•µì‹¬ ì´ë¯¸ì§€: {len(core_images)}ê°œ")
            print(f"{'='*120}\n")
            
        except Exception as e:
            print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    else:
        print("\nì‚¬ìš©ë²•:")
        print("  python improved_hybrid_filter_v3.py <íŒŒì¼ê²½ë¡œ>")
        print("\nì˜ˆì‹œ:")
        print("  python improved_hybrid_filter_v3.py ì¤‘ë“±êµ­ì–´1.pdf")
        print("\nâœ… V3 ê°œì„ ì‚¬í•­:")
        print("  - PyMuPDF (AGPL) â†’ pdfplumber (MIT) ì „í™˜")
        print("  - ë¼ì´ì„ ìŠ¤ ë¬¸ì œ í•´ê²°")
        print("  - OCR ê¸°ëŠ¥ ì™„ì „ ìœ ì§€ (pdf2image + PaddleOCR)")
        print("  - í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì¤‘ì²© ê°ì§€ ìœ ì§€")
        print("  - ìƒ‰ìƒ ë³µì¡ë„ í•„í„° ì¶”ê°€ (í…ìŠ¤íŠ¸ ìƒì ì œê±°) â­")
        print("  - ê¸°ì¡´ v2 ê¸°ëŠ¥ ëª¨ë‘ ìœ ì§€")
        print("="*120 + "\n")