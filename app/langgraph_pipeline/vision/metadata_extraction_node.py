"""
ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë…¸ë“œ (LangGraph)
ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ Global Visual Guidelines + Content Metadata ìƒì„±
"""

import json
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict

# Vertex AI import
try:
    import vertexai
    from vertexai.generative_models import GenerativeModel
    VERTEXAI_AVAILABLE = True
except ImportError:
    VERTEXAI_AVAILABLE = False
    print("âš ï¸  vertexai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")


# PodcastScene import
try:
    from script_parser_node import PodcastScene
except ImportError:
    import sys
    import os
    sys.path.insert(0, os.path.dirname(__file__))
    try:
        from script_parser_node import PodcastScene
    except ImportError:
        print("âš ï¸  script_parser_nodeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        PodcastScene = None


@dataclass
class ColorPalette:
    """ìƒ‰ìƒ íŒ”ë ˆíŠ¸"""
    primary: str        # ì£¼ ìƒ‰ìƒ (HEX)
    secondary: str      # ë³´ì¡° ìƒ‰ìƒ
    accent: str         # ê°•ì¡° ìƒ‰ìƒ
    background: str     # ë°°ê²½ ìƒ‰ìƒ
    text_safe: str      # í…ìŠ¤íŠ¸ ì˜ì—­ ìƒ‰ìƒ


@dataclass
class GlobalVisualGuidelines:
    """ì „ì—­ ë¹„ì£¼ì–¼ ê°€ì´ë“œë¼ì¸"""
    art_style: str                      # "Flat isometric illustration"
    art_style_description: str          # ìŠ¤íƒ€ì¼ ìƒì„¸ ì„¤ëª…
    art_style_details: Dict[str, str]   # primary, secondary, avoid
    color_palette: ColorPalette
    color_mood: str
    overall_mood: str
    emotional_tone: str
    lighting_style: str                 # ì¡°ëª… ìŠ¤íƒ€ì¼
    composition_guidelines: str         # êµ¬ë„ ê°€ì´ë“œë¼ì¸
    recurring_elements: Dict[str, Any]
    reference_style: str


@dataclass
class Chapter:
    """ì±•í„° ì •ë³´"""
    id: str
    title: str
    start_time: str
    end_time: str
    duration: int
    scene_ids: List[str]
    key_topics: List[str]
    summary: str
    importance: float
    expected_images: int


@dataclass
class KeyConcept:
    """í•µì‹¬ ê°œë…"""
    term: str
    full_name: Optional[str]
    first_appearance: str
    importance: float
    should_visualize: bool
    visual_priority: str  # "high", "medium", "low"


@dataclass
class CriticalMoment:
    """ì„ê³„ ìˆœê°„"""
    timestamp: str
    scene_id: str
    type: str           # "í•µì‹¬ ê¸°ìˆ  ë„ì…", "ì „í™˜ì "
    description: str


@dataclass
class ContentAnalysis:
    """ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼"""
    total_duration: str
    total_scenes: int
    content_type: str           # educational, news, story, business
    main_topic: str             # ì£¼ì œ (1-2ì¤„, ê°„ê²°)
    summary: str                # í•œ ì¤„ ìš”ì•½
    detailed_summary: str       # ìƒì„¸ ìš”ì•½ (ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì¡°ì ˆ)
    target_audience: str
    chapters: List[Chapter]
    key_concepts: List[KeyConcept]
    critical_moments: List[CriticalMoment]


@dataclass
class PodcastMetadata:
    """ì „ì²´ íŒŸìºìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„°"""
    podcast_id: str
    created_at: str
    content: ContentAnalysis
    visual: GlobalVisualGuidelines


class MetadataExtractionNode:
    """
    ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë…¸ë“œ
    
    ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬:
    1. Global Visual Guidelines ìƒì„±
    2. Content Analysis (ì±•í„°, í•µì‹¬ ê°œë…)
    3. Critical Moments ì¶”ì¶œ
    """
    
    # Global Visual Metadata ìƒì„± í”„ë¡¬í”„íŠ¸
    VISUAL_GUIDELINES_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¹„ë””ì˜¤ ì•„íŠ¸ ë””ë ‰í„°ì…ë‹ˆë‹¤.
YouTube êµìœ¡ ì½˜í…ì¸ , NotebookLM ìŠ¤íƒ€ì¼ ë¹„ë””ì˜¤ ì œì‘ ê²½í—˜ì´ í’ë¶€í•©ë‹ˆë‹¤.

ë‹¤ìŒ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ê³ , ì „ì²´ ë¹„ë””ì˜¤ì— ì¼ê´€ë˜ê²Œ ì ìš©í•  **ë¹„ì£¼ì–¼ ê°€ì´ë“œë¼ì¸**ì„ ìƒì„±í•˜ì„¸ìš”.

**ìŠ¤í¬ë¦½íŠ¸:**
{script}

**ëª©í‘œ:**
- ëª¨ë“  ì´ë¯¸ì§€ê°€ ê°™ì€ ì‹œë¦¬ì¦ˆì²˜ëŸ¼ ë³´ì´ë„ë¡ í†µì¼ê° ìœ ì§€
- NotebookLM ìŠ¤íƒ€ì¼: ê¹”ë”í•˜ê³ , êµìœ¡ì ì´ë©°, engaging
- ë‚˜ë…¸ë°”ë‚˜ë‚˜(Gemini 2.5 Flash Image) ìµœì í™”

**ë‚˜ë…¸ë°”ë‚˜ë‚˜ ì•„íŠ¸ ìŠ¤íƒ€ì¼ ì„ íƒ ê°€ì´ë“œ:**

**1. ë§¤ì²´/ê¸°ë²• ê¸°ë°˜ ìŠ¤íƒ€ì¼:**
- "3D animation" - ì…ì²´ì ì¸ ë§Œí™” ìŠ¤íƒ€ì¼ (êµìœ¡/ê¸°ìˆ  ì½˜í…ì¸  ì í•©)
- "Flat vector illustration" - ê¹”ë”í•œ í‰ë©´ ë²¡í„°, WPA í¬ìŠ¤í„° ìŠ¤íƒ€ì¼ (ì •ë³´ ì „ë‹¬ ìµœì )
- "Isometric illustration" - ì•„ì´ì†Œë©”íŠ¸ë¦­ ì…ì²´ ì¼ëŸ¬ìŠ¤íŠ¸ (ê¸°ìˆ /í”„ë¡œì„¸ìŠ¤ ì„¤ëª…)
- "Watercolor painting" - ìˆ˜ì±„í™” ë²ˆì§ íš¨ê³¼ (ê°ì„±ì /ì˜ˆìˆ  ì½˜í…ì¸ )
- "Oil painting" - ìœ í™” ì§ˆê° (ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ëŠë‚Œ)
- "Line art" - ì„  ìœ„ì£¼ì˜ ë‹¨ìˆœí•œ ê·¸ë¦¼ (ë¯¸ë‹ˆë©€ ë””ìì¸)
- "Comic sequence" - ë§Œí™”ì±… ìŠ¤íƒ€ì¼ (ìŠ¤í† ë¦¬í…”ë§)

**2. ì‚¬ì§„ ê¸°ë°˜ ìŠ¤íƒ€ì¼:**
- "Photorealistic" - ê·¹ì‚¬ì‹¤ì  ì‚¬ì§„ (ì œí’ˆ/í˜„ì‹¤ ë¬˜ì‚¬)
- "Cinematic wide-angle" - ì˜í™” ê°™ì€ êµ¬ë„ (ë“œë¼ë§ˆí‹±í•œ íš¨ê³¼)
- "Product photography" - ê¹”ë”í•œ ì œí’ˆ ì‚¬ì§„ (ë¹„ì¦ˆë‹ˆìŠ¤)

**3. ë””ìì¸/ì½˜ì…‰íŠ¸ ìŠ¤íƒ€ì¼:**
- "Technical diagram" - ê¸°ìˆ  ë„ì‹/ì²­ì‚¬ì§„ (ì—”ì§€ë‹ˆì–´ë§/ê³¼í•™)
- "Infographic style" - ì¸í¬ê·¸ë˜í”½ ìŠ¤íƒ€ì¼ (ë°ì´í„° ì‹œê°í™”)
- "Children's picture book style" - ë™í™”ì±… ì‚½í™” (êµìœ¡/ì•„ë™)
- "Modern minimalist design" - í˜„ëŒ€ì  ë¯¸ë‹ˆë©€ ë””ìì¸ (ì„¸ë ¨ëœ ë¸Œëœë“œ)

**ìŠ¤íƒ€ì¼ ì„ íƒ ê¸°ì¤€:**
- ê¸°ìˆ /AI/êµìœ¡ â†’ "Flat vector illustration" ë˜ëŠ” "3D animation" ë˜ëŠ” "Isometric illustration"
- ìŠ¤í† ë¦¬/ê°ì„± â†’ "Watercolor painting" ë˜ëŠ” "Children's picture book style"
- ë¹„ì¦ˆë‹ˆìŠ¤/ì „ë¬¸ â†’ "Modern minimalist design" ë˜ëŠ” "Photorealistic"
- ê³¼í•™/ì—”ì§€ë‹ˆì–´ë§ â†’ "Technical diagram" ë˜ëŠ” "Isometric illustration"

**ë‹¤ìŒ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”:**

```json
{{
    "art_style": "Flat vector illustration",
    "art_style_description": "ê¹”ë”í•˜ê³  í˜„ëŒ€ì ì¸ í‰ë©´ ë²¡í„° ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜. ë‹¨ìˆœí•œ í˜•íƒœì™€ ëª…í™•í•œ ìƒ‰ìƒ êµ¬ë¶„ìœ¼ë¡œ ì •ë³´ ì „ë‹¬ì— ìµœì í™”.",
    "art_style_details": {{
        "primary": "ë¶€ë“œëŸ¬ìš´ ê³¡ì„ ê³¼ ê¸°í•˜í•™ì  í˜•íƒœ",
        "secondary": "ê·¸ë¼ë°ì´ì…˜ ìµœì†Œí™”, í”Œë«í•œ ìƒ‰ìƒ ë¸”ë¡",
        "avoid": "ê³¼ë„í•œ ë””í…Œì¼, ì‚¬ì‹¤ì  í…ìŠ¤ì²˜, ë³µì¡í•œ ê·¸ë¦¼ì"
    }},
    "color_palette": {{
        "primary": "#6366f1",
        "secondary": "#8b5cf6",
        "accent": "#ec4899",
        "background": "#f8fafc",
        "text_safe": "#ffffff"
    }},
    "color_mood": "ë°ê³  ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸",
    "overall_mood": "Professional and engaging, ë¯¸ë˜ì§€í–¥ì ì´ë©´ì„œë„ ì ‘ê·¼ ê°€ëŠ¥í•œ",
    "emotional_tone": "ë‚™ê´€ì ì´ê³  ìì‹ ê° ìˆëŠ”, êµìœ¡ì ",
    "lighting_style": "ë°ê³  ê· ì¼í•œ ì¡°ëª…, ë¶€ë“œëŸ¬ìš´ ê·¸ë¦¼ì, ëª…í™•í•œ ìƒ‰ê°",
    "composition_guidelines": "16:9 ë¹„ìœ¨, ì¤‘ì•™ ì§‘ì¤‘ êµ¬ë„, ì¶©ë¶„í•œ ì—¬ë°±, ì‹œê°ì  ìœ„ê³„ ëª…í™•",
    "recurring_elements": {{
        "character": "ë°˜ë³µ ë“±ì¥í•  ìºë¦­í„°/ì•„ì´ì½˜ (ìˆìœ¼ë©´)",
        "motifs": ["ê¸°í•˜í•™ì  íŒ¨í„´", "ë°ì´í„° íë¦„ì„ "],
        "icons_style": "ë‘¥ê·¼ ëª¨ì„œë¦¬, ì±„ì›Œì§„ ìŠ¤íƒ€ì¼"
    }},
    "reference_style": "NotebookLM Video Overview style, Kurzgesagt educational videos"
}}
```

**ì¤‘ìš”:**
- **ë‹¨ì¼ ì•„íŠ¸ ìŠ¤íƒ€ì¼ ì„ íƒ** (ìŠ¤í¬ë¦½íŠ¸ ì½˜í…ì¸ ì— ê°€ì¥ ì í•©í•œ ê²ƒ)
- ìƒ‰ìƒì€ ë°˜ë“œì‹œ HEX ì½”ë“œë¡œ (#RRGGBB)
- art_style_descriptionì€ ë‚˜ë…¸ë°”ë‚˜ë‚˜ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ êµ¬ì²´ì ìœ¼ë¡œ
- **ğŸ”´ CRITICAL: ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸/ë¼ë²¨/ë‹¤ì´ì–´ê·¸ë¨ì€ ì˜ì–´ë¡œë§Œ í‘œê¸°** (í•œê¸€ í…ìŠ¤íŠ¸ëŠ” ë Œë”ë§ í’ˆì§ˆ ì €í•˜)
- ëª¨ë“  í•„ë“œë¥¼ ë¹ ì§ì—†ì´ ì‘ì„±
- JSONë§Œ ì¶œë ¥ (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´)
"""

    # Content Analysis í”„ë¡¬í”„íŠ¸
    CONTENT_ANALYSIS_PROMPT = """ë‹¹ì‹ ì€ ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì½˜í…ì¸  êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

**ìŠ¤í¬ë¦½íŠ¸:**
{script}

**ë¶„ì„ ëª©í‘œ:**
1. íŒŸìºìŠ¤íŠ¸ì˜ í•µì‹¬ ì£¼ì œ íŒŒì•…
2. ì „ì²´ ë‚´ìš© ìš”ì•½ (ê¸¸ì´ì— ë”°ë¼ ì ì ˆíˆ ì¡°ì ˆ)
3. ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì±•í„° ë¶„í•  (ë³´í†µ 5-8ê°œ)
4. ê° ì±•í„°ì˜ í•µì‹¬ ì£¼ì œ íŒŒì•…
5. ì‹œê°í™”ê°€ í•„ìš”í•œ í•µì‹¬ ê°œë… ì¶”ì¶œ
6. ì„ê³„ ìˆœê°„ (Critical Moments) ì°¾ê¸°

**ë‹¤ìŒ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”:**

```json
{{
    "total_duration": "Xë¶„ Yì´ˆ",
    "total_scenes": ìˆ«ì,
    "content_type": "educational/news/story/business/interview ì¤‘ ì„ íƒ",
    
    "main_topic": "íŒŸìºìŠ¤íŠ¸ì˜ í•µì‹¬ ì£¼ì œ (1-2ì¤„, ê°„ê²°í•˜ê²Œ)",
    "summary": "í•œ ì¤„ ìš”ì•½ (50-80ì)",
    "detailed_summary": "ìƒì„¸ ìš”ì•½ (ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì¡°ì ˆ: 5ë¶„ ë¯¸ë§Œ=2-3ë¬¸ì¥, 5-10ë¶„=3-5ë¬¸ì¥, 10-20ë¶„=5-7ë¬¸ì¥, 20ë¶„ ì´ìƒ=7-10ë¬¸ì¥)",
    
    "target_audience": "íƒ€ê²Ÿ ì²­ì¤‘ ì„¤ëª…",
    
    "chapters": [
        {{
            "id": "ch_01",
            "title": "ì±•í„° ì œëª© (ì˜ˆ: ì˜¤í”„ë‹)",
            "start_time": "00:00:00",
            "end_time": "00:00:48",
            "duration": 48,
            "scene_ids": ["scene_001", "scene_002"],
            "key_topics": ["í† í”½1", "í† í”½2"],
            "summary": "ì´ ì±•í„° ìš”ì•½",
            "importance": 0.0-1.0 (ì¤‘ìš”ë„),
            "expected_images": ì˜ˆìƒ ì´ë¯¸ì§€ ê°œìˆ˜
        }}
    ],
    
    "key_concepts": [
        {{
            "term": "ê°œë… ì´ë¦„ (ì˜ˆ: TTS)",
            "full_name": "ì „ì²´ ì´ë¦„ (ìˆìœ¼ë©´)",
            "first_appearance": "00:01:48",
            "importance": 0.0-1.0,
            "should_visualize": true/false,
            "visual_priority": "high/medium/low"
        }}
    ],
    
    "critical_moments": [
        {{
            "timestamp": "00:01:48",
            "scene_id": "scene_008",
            "type": "í•µì‹¬ ê¸°ìˆ  ë„ì…/ì „í™˜ì /ê²°ë¡  ë“±",
            "description": "ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ê°€"
        }}
    ]
}}
```

**ì£¼ì˜:**
- main_topic: ì´ íŒŸìºìŠ¤íŠ¸ê°€ ë¬´ì—‡ì— ê´€í•œ ê²ƒì¸ì§€ ëª…í™•í•˜ê²Œ
- summary: í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ í•œ ì¤„ë¡œ
- detailed_summary: ì „ì²´ íë¦„ì„ ìƒì„¸íˆ, ê¸¸ì´ëŠ” íŒŸìºìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€
- ì±•í„°ëŠ” ì˜ë¯¸ ë‹¨ìœ„ë¡œ (3-5ê°œ ì¥ë©´ì”©)
- expected_imagesëŠ” ì±•í„° ì¤‘ìš”ë„ì— ë¹„ë¡€
- key_conceptsëŠ” ì‹œê°í™” ê°€ëŠ¥í•œ ê²ƒë§Œ
- JSONë§Œ ì¶œë ¥
"""

    def __init__(
        self,
        project_id: str = None,  # Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°
        location: str = "us-central1",
        model_name: str = "gemini-2.0-flash-exp"
    ):
        """
        ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë…¸ë“œ ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
            location: Vertex AI ë¦¬ì „
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸
        """
        # í”„ë¡œì íŠ¸ ID ê²°ì •
        if project_id is None:
            import os
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT") or os.getenv("GCP_PROJECT")
            if not project_id:
                print("âš ï¸  í”„ë¡œì íŠ¸ IDê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ GOOGLE_CLOUD_PROJECTë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ì„¸ìš”.")
                project_id = "dummy-project"  # fallback
        """
        ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë…¸ë“œ ì´ˆê¸°í™”
        """
        self.project_id = project_id
        self.location = location
        self.model_name = model_name
        
        # Vertex AI ì´ˆê¸°í™”
        if VERTEXAI_AVAILABLE:
            try:
                vertexai.init(project=project_id, location=location)
                self.model = GenerativeModel(model_name)
                print(f"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {model_name}")
            except Exception as e:
                print(f"âš ï¸  Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.model = None
        else:
            self.model = None
    
    def _prepare_script_text(self, scenes: List[PodcastScene]) -> str:
        """
        ì¥ë©´ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        """
        lines = []
        for scene in scenes:
            lines.append(f"[{scene.timestamp_start}] {scene.speaker}: {scene.text}")
        
        return "\n".join(lines)
    
    def _clean_json_response(self, text: str) -> str:
        """JSON ì‘ë‹µ ì •ë¦¬ (ë§ˆí¬ë‹¤ìš´ ì œê±° + ì´ìŠ¤ì¼€ì´í•‘)"""
        # ```json ... ``` ì œê±°
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        # JSON ë¬¸ìì—´ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆ ë¬¸ì œ ìˆ˜ì • ì‹œë„
        # (ì´ê±´ ì™„ë²½í•œ í•´ê²°ì±…ì€ ì•„ë‹ˆì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë„ì›€ë¨)
        try:
            # ì´ë¯¸ ìœ íš¨í•œ JSONì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            json.loads(text)
            return text
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì¬ì‹œë„ ë¡œì§ì´ ì²˜ë¦¬í•¨)
            return text
    
    def extract_visual_guidelines(
        self,
        scenes: List[PodcastScene],
        max_retries: int = 3
    ) -> Optional[GlobalVisualGuidelines]:
        """
        Global Visual Guidelines ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        """
        if not self.model:
            raise RuntimeError("Vertex AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GOOGLE_CLOUD_PROJECT ë° ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        print("\nğŸ¨ Global Visual Guidelines ìƒì„± ì¤‘...")
        
        # ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
        script_text = self._prepare_script_text(scenes)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.VISUAL_GUIDELINES_PROMPT.format(script=script_text)
        
        # ì¬ì‹œë„ ë£¨í”„
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"   ì¬ì‹œë„ {attempt + 1}/{max_retries}...")
                
                # Gemini í˜¸ì¶œ
                response = self.model.generate_content(
                    prompt,
                    generation_config={
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_output_tokens": 4096,
                        "response_mime_type": "application/json"  # JSON ì‘ë‹µ ê°•ì œ
                    }
                )
                
                # ì‘ë‹µ íŒŒì‹±
                response_text = self._clean_json_response(response.text)
                data = json.loads(response_text)
                
                # GlobalVisualGuidelines ê°ì²´ ìƒì„±
                visual = GlobalVisualGuidelines(
                    art_style=data["art_style"],
                    art_style_description=data.get("art_style_description", ""),
                    art_style_details=data["art_style_details"],
                    color_palette=ColorPalette(**data["color_palette"]),
                    color_mood=data["color_mood"],
                    overall_mood=data["overall_mood"],
                    emotional_tone=data["emotional_tone"],
                    lighting_style=data.get("lighting_style", "ë°ê³  ê· ì¼í•œ ì¡°ëª…"),
                    composition_guidelines=data.get("composition_guidelines", "16:9 ë¹„ìœ¨"),
                    recurring_elements=data["recurring_elements"],
                    reference_style=data["reference_style"]
                )
                
                print("âœ… Visual Guidelines ìƒì„± ì™„ë£Œ")
                self._print_visual_summary(visual)
                
                return visual
            
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    print(f"   ì‘ë‹µ ì¼ë¶€: {response_text[:200]}...")
                    continue
                else:
                    print(f"âŒ Visual Guidelines ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Visual Guidelines ìƒì„± ì‹¤íŒ¨: JSON íŒŒì‹± ì—ëŸ¬ ({str(e)})")
            
            except KeyError as e:
                print(f"âš ï¸  í•„ìˆ˜ í•„ë“œ ëˆ„ë½ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    print(f"âŒ Visual Guidelines ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Visual Guidelines ìƒì„± ì‹¤íŒ¨: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ({str(e)})")
            
            except Exception as e:
                print(f"âš ï¸  ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    print(f"âŒ Visual Guidelines ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Visual Guidelines ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # ì—¬ê¸° ë„ë‹¬í•˜ë©´ ì‹¤íŒ¨
        raise RuntimeError("Visual Guidelines ìƒì„± ì‹¤íŒ¨: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    
    def extract_content_analysis(
        self,
        scenes: List[PodcastScene],
        max_retries: int = 3
    ) -> Optional[ContentAnalysis]:
        """
        Content Analysis ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        """
        if not self.model:
            raise RuntimeError("Vertex AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GOOGLE_CLOUD_PROJECT ë° ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        print("\nğŸ“Š Content Analysis ìƒì„± ì¤‘...")
        
        # ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
        script_text = self._prepare_script_text(scenes)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.CONTENT_ANALYSIS_PROMPT.format(script=script_text)
        
        # ì¬ì‹œë„ ë£¨í”„
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"   ì¬ì‹œë„ {attempt + 1}/{max_retries}...")
                
                # Gemini í˜¸ì¶œ
                response = self.model.generate_content(
                    prompt,
                    generation_config={
                        "temperature": 0.3,  # ë¶„ì„ì€ ì¼ê´€ì„± ì¤‘ìš”
                        "top_p": 0.8,
                        "max_output_tokens": 8192,  # 6144 â†’ 8192
                        "response_mime_type": "application/json"  # JSON ì‘ë‹µ ê°•ì œ
                    }
                )
                
                # ì‘ë‹µ íŒŒì‹±
                response_text = self._clean_json_response(response.text)
                data = json.loads(response_text)
                
                # ContentAnalysis ê°ì²´ ìƒì„±
                content = ContentAnalysis(
                    total_duration=data["total_duration"],
                    total_scenes=data["total_scenes"],
                    content_type=data["content_type"],
                    main_topic=data["main_topic"],
                    summary=data["summary"],
                    detailed_summary=data["detailed_summary"],
                    target_audience=data["target_audience"],
                    chapters=[Chapter(**ch) for ch in data["chapters"]],
                    key_concepts=[KeyConcept(**kc) for kc in data["key_concepts"]],
                    critical_moments=[CriticalMoment(**cm) for cm in data["critical_moments"]]
                )
                
                print("âœ… Content Analysis ìƒì„± ì™„ë£Œ")
                self._print_content_summary(content)
                
                return content
            
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    print(f"   ì‘ë‹µ ì¼ë¶€: {response_text[:200]}...")
                    continue
                else:
                    print(f"âŒ Content Analysis ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Content Analysis ìƒì„± ì‹¤íŒ¨: JSON íŒŒì‹± ì—ëŸ¬ ({str(e)})")
            
            except KeyError as e:
                print(f"âš ï¸  í•„ìˆ˜ í•„ë“œ ëˆ„ë½ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    print(f"âŒ Content Analysis ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Content Analysis ìƒì„± ì‹¤íŒ¨: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ({str(e)})")
            
            except Exception as e:
                print(f"âš ï¸  ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    print(f"âŒ Content Analysis ìƒì„± ìµœì¢… ì‹¤íŒ¨")
                    raise RuntimeError(f"Content Analysis ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # ì—¬ê¸° ë„ë‹¬í•˜ë©´ ì‹¤íŒ¨
        raise RuntimeError("Content Analysis ìƒì„± ì‹¤íŒ¨: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    
    def extract_metadata(
        self,
        scenes: List[PodcastScene],
        podcast_id: str = "podcast_001"
    ) -> PodcastMetadata:
        """
        ì „ì²´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (Visual + Content)
        """
        print("\n" + "="*80)
        print("ğŸ” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹œì‘")
        print("="*80)
        print(f"ì´ ì¥ë©´: {len(scenes)}ê°œ")
        
        # Visual Guidelines ìƒì„±
        visual = self.extract_visual_guidelines(scenes)
        
        # Content Analysis ìƒì„±
        content = self.extract_content_analysis(scenes)
        
        # í†µí•©
        import datetime
        metadata = PodcastMetadata(
            podcast_id=podcast_id,
            created_at=datetime.datetime.now().isoformat(),
            content=content,
            visual=visual
        )
        
        print("\n" + "="*80)
        print("âœ… ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
        print("="*80)
        
        return metadata
    
    def _print_visual_summary(self, visual: GlobalVisualGuidelines):
        """Visual Guidelines ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ¨ Visual Guidelines:")
        print(f"  Art Style: {visual.art_style}")
        print(f"  Primary Color: {visual.color_palette.primary}")
        print(f"  Mood: {visual.overall_mood}")
    
    def _print_content_summary(self, content: ContentAnalysis):
        """Content Analysis ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“Š Content Analysis:")
        print(f"  Duration: {content.total_duration}")
        print(f"  Type: {content.content_type}")
        print(f"  Topic: {content.main_topic}")
        print(f"  Summary: {content.summary}")
        print(f"  Chapters: {len(content.chapters)}ê°œ")
        print(f"  Key Concepts: {len(content.key_concepts)}ê°œ")
        print(f"  Critical Moments: {len(content.critical_moments)}ê°œ")
    
    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        LangGraph ë…¸ë“œë¡œ ì‹¤í–‰
        """
        scenes = state.get("scenes", [])
        
        if not scenes:
            print("âš ï¸  ì¥ë©´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {**state, "metadata": None}
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = self.extract_metadata(scenes)
        
        return {
            **state,
            "metadata": metadata
        }


# ============================================================================
# í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

def save_metadata(metadata: PodcastMetadata, output_path: str):
    """ë©”íƒ€ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    
    # dataclassë¥¼ dictë¡œ ë³€í™˜
    def to_dict(obj):
        if hasattr(obj, '__dict__'):
            return {k: to_dict(v) for k, v in obj.__dict__.items()}
        elif isinstance(obj, list):
            return [to_dict(item) for item in obj]
        else:
            return obj
    
    data = to_dict(metadata)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {output_path}")


def print_metadata_summary(metadata: PodcastMetadata):
    """ë©”íƒ€ë°ì´í„° ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“‹ ë©”íƒ€ë°ì´í„° ìš”ì•½")
    print("="*80)
    
    print(f"\nğŸ“Š ì½˜í…ì¸  ì •ë³´:")
    print(f"  íƒ€ì…: {metadata.content.content_type}")
    print(f"  ê¸¸ì´: {metadata.content.total_duration}")
    print(f"  ì£¼ì œ: {metadata.content.main_topic}")
    print(f"  ìš”ì•½: {metadata.content.summary}")
    
    print(f"\nğŸ“ ìƒì„¸ ìš”ì•½:")
    # ìƒì„¸ ìš”ì•½ì„ ì ì ˆíˆ ì¤„ë°”ê¿ˆí•´ì„œ ì¶œë ¥
    summary_lines = metadata.content.detailed_summary.split('. ')
    for line in summary_lines:
        if line.strip():
            print(f"  {line.strip()}{'.' if not line.endswith('.') else ''}")
    
    print(f"\nğŸ“š ì±•í„°: {len(metadata.content.chapters)}ê°œ")
    for ch in metadata.content.chapters:
        print(f"  - {ch.title} ({ch.start_time}-{ch.end_time})")
        print(f"    ì¤‘ìš”ë„: {ch.importance:.2f}, ì˜ˆìƒ ì´ë¯¸ì§€: {ch.expected_images}ê°œ")
    
    print(f"\nğŸ”‘ í•µì‹¬ ê°œë…: {len(metadata.content.key_concepts)}ê°œ")
    for kc in metadata.content.key_concepts:
        if kc.should_visualize:
            print(f"  - {kc.term} (ìš°ì„ ìˆœìœ„: {kc.visual_priority})")
    
    print(f"\nğŸ¨ ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼:")
    print(f"  ì•„íŠ¸: {metadata.visual.art_style}")
    print(f"  ì£¼ ìƒ‰ìƒ: {metadata.visual.color_palette.primary}")
    print(f"  ë¬´ë“œ: {metadata.visual.overall_mood}")


if __name__ == "__main__":
    print("Metadata Extraction Node - ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë…¸ë“œ")
    print("Importí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”: from metadata_extraction_node import MetadataExtractionNode")