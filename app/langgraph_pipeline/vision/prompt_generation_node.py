"""
í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ (LangGraph)
ImagePlan + PodcastMetadata.visual â†’ ë‚˜ë…¸ë°”ë‚˜ë‚˜ìš© í•œê¸€ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
"""

import os
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

# Vertex AI import
try:
    import vertexai
    from vertexai.generative_models import GenerativeModel
    VERTEXAI_AVAILABLE = True
except ImportError:
    VERTEXAI_AVAILABLE = False
    print("âš ï¸  vertexai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ImagePlan import (ìƒëŒ€/ì§ì ‘ ì‹¤í–‰ ë‘˜ ë‹¤ ëŒ€ì‘)
try:
    from .image_planning_node import ImagePlan  # íŒ¨í‚¤ì§€ import
except Exception:
    # ì›ë³¸
    import sys
    sys.path.insert(0, os.path.dirname(__file__))
    try:
        from image_planning_node import ImagePlan
    except ImportError:
        print("âš ï¸  image_planning_node import ì‹¤íŒ¨")
        ImagePlan = None

# ë³€ê²½ 
#     try:
#         from image_planning_node import ImagePlan  # ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ìš©
#     except Exception:
#         print("âš ï¸  image_planning_node import ì‹¤íŒ¨")
#         ImagePlan = None

# from dataclasses import asdict

IMAGE_PROMPT_GENERATION = """
ë‹¹ì‹ ì€ ë‚˜ë…¸ë°”ë‚˜ë‚˜(Gemini 2.5 Flash Image) í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‚˜ë…¸ë°”ë‚˜ë‚˜ëŠ”:
- í•œê¸€ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ë²½í•˜ê²Œ ì´í•´í•©ë‹ˆë‹¤
- ëŒ€í™”í˜•/ì„œìˆ í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤
- "~í•´ì£¼ì„¸ìš”", "~ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì´í•´í•©ë‹ˆë‹¤
- Geminiì˜ ì„¸ê³„ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤

ì£¼ì–´ì§„ ì´ë¯¸ì§€ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ë‚˜ë…¸ë°”ë‚˜ë‚˜ì— ìµœì í™”ëœ **í•œê¸€ í”„ë¡¬í”„íŠ¸**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

## ì…ë ¥ ì •ë³´:

**Global Visual Guidelines:**
{visual_guidelines}

**ì´ë¯¸ì§€ ê³„íš:**
- Title: {title}
- Description: {description}
- Visual Concept: {visual_concept}
- Key Concepts: {key_concepts}

## í”„ë¡¬í”„íŠ¸ ìƒì„± ê°€ì´ë“œë¼ì¸:

1. **í•œê¸€ ì‚¬ìš©**: ì˜ì–´ê°€ ì•„ë‹Œ í•œê¸€ë¡œ ì‘ì„±!
2. **ëŒ€í™”í˜•/ì„œìˆ í˜•**: "ì´ëŸ° ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”" ìŠ¤íƒ€ì¼
3. **êµ¬ì²´ì  ë¬˜ì‚¬**: ìƒ‰ìƒ, êµ¬ë„, ìŠ¤íƒ€ì¼ ëª…í™•íˆ
4. **Art Style ì ìš©**: Global Guidelinesì˜ ìŠ¤íƒ€ì¼ ë°˜ì˜
5. **Color Palette ì ìš©**: ì§€ì •ëœ ìƒ‰ìƒ ì‚¬ìš©
6. **ìˆœìˆ˜ ì´ë¯¸ì§€**: í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê±±ì • ì—†ì´ ì´ë¯¸ì§€ í’ˆì§ˆì—ë§Œ ì§‘ì¤‘

## ì¶œë ¥ í˜•ì‹ (JSON):

{{
  "image_title": "ê°„ê²°í•œ ì œëª©",
  "visual_elements": ["ìš”ì†Œ1", "ìš”ì†Œ2", "ìš”ì†Œ3"],
  "composition": "êµ¬ë„ ì„¤ëª…",
  "lighting": "ì¡°ëª… ì„¤ëª…",
  "image_prompt": "ìµœì¢… í•œê¸€ í”„ë¡¬í”„íŠ¸ (150-200ì)"
}}

**í”„ë¡¬í”„íŠ¸ í˜•ì‹ ì˜ˆì‹œ:**
"{visual_concept}ë¥¼ í‘œí˜„í•œ {art_style} ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
êµ¬ë„ëŠ” {composition}ì´ê³ , {key_elements}ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ìƒ‰ìƒì€ {colors}ë¥¼ ì‚¬ìš©í•˜ê³ , ì¡°ëª…ì€ {lighting}ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
ì „ì²´ì ìœ¼ë¡œ {mood} ëŠë‚Œì˜ ê³ í’ˆì§ˆ, ì „ë¬¸ì ì¸ ë””ìì¸ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”."

**ì¢‹ì€ ì˜ˆì‹œ:**
"í…ìŠ¤íŠ¸ê°€ ìŒì„± íŒŒí˜•ìœ¼ë¡œ ë³€í™˜ë˜ëŠ” TTS íŒŒì´í”„ë¼ì¸ì„ í”Œë« ì•„ì´ì†Œë©”íŠ¸ë¦­ ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ íë¥´ëŠ” êµ¬ë„ë¡œ, ë¬¸ì„œ ì•„ì´ì½˜ â†’ Gemini API ë°°ì§€ â†’ ìŒì„± íŒŒí˜•ì´ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ë°ì€ íŒŒë€ìƒ‰(#3498DB)ê³¼ ì´ˆë¡ìƒ‰(#2ECC71)ì„ ì£¼ë¡œ ì‚¬ìš©í•˜ê³ , ë°ê³  ê¹¨ë—í•œ ì¡°ëª…ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
í˜„ëŒ€ì ì´ê³  ì¹œê·¼í•œ ëŠë‚Œì˜ ê³ í’ˆì§ˆ ë””ìì¸ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”."

**ì¤‘ìš”:**
- JSONë§Œ ì¶œë ¥
- í•œê¸€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì˜ì–´ ê¸ˆì§€!)
- êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ
- 16:9 ë¹„ìœ¨ ê³ ë ¤
- ëŒ€í™”í˜•/ì„œìˆ í˜• ë¬¸ì²´

ì´ì œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”:
"""

class PromptGenerationNode:
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ (ì´ë¯¸ì§€ ê³„íš ê¸°ë°˜)

    ê¸°ëŠ¥:
    1. ì´ë¯¸ì§€ ê³„íš â†’ Imagen 4 í”„ë¡¬í”„íŠ¸
    2. Global Visual Guidelines ì ìš©
    3. í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„ ì œê±°

    - ì…ë ¥:
        state["image_plans"]: List[ImagePlan]
        state["metadata"]: PodcastMetadata (metadata.visual ì‚¬ìš©)
    - ì¶œë ¥:
        state["image_prompts"]: List[Dict]
          [
            {
              "image_id": str,
              "image_title": str,
              "image_prompt": str,
              "primary_timestamp": str,
              "covered_timestamps": List[str],
              "duration": int,
              ...
            },
            ...
          ]
    """

    def __init__(
        self,
        project_id: str = None,
        location: str = "us-central1",
        model_name: str = "gemini-2.5-flash",
    ):
        # í”„ë¡œì íŠ¸ ID ìë™ íƒì§€
        if project_id is None:
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT") or os.getenv("GCP_PROJECT")
            if not project_id:
                cred_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
                if cred_path and os.path.exists(cred_path):
                    try:
                        with open(cred_path, "r", encoding="utf-8") as f:
                            creds = json.load(f)
                            project_id = creds.get("project_id")
                    except Exception:
                        pass

            if not project_id:
                print("âš ï¸  PromptGenerationNode: í”„ë¡œì íŠ¸ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.project_id = project_id
        self.location = location
        self.model_name = model_name

        # Vertex AI ì´ˆê¸°í™”
        if VERTEXAI_AVAILABLE and project_id:
            try:
                vertexai.init(project=project_id, location=location)
                self.model = GenerativeModel(model_name)
                print(f"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ ì´ˆê¸°í™”: {model_name}")
            except Exception as e:
                print(f"âš ï¸  PromptGenerationNode ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.model = None
        else:
            self.model = None
            if not project_id:
                print("âš ï¸  Gemini ëª¨ë¸ ì—†ìŒ (í”„ë¡œì íŠ¸ ID ì—†ìŒ)")

    # ------------------------------------------------------------
    # ë‚´ë¶€ ìœ í‹¸: visual_guidelines ì¶”ì¶œ
    # ------------------------------------------------------------
    def _extract_visual_guidelines(self, metadata: Any) -> Dict[str, Any]:
        """
        PodcastMetadataì—ì„œ visual(GlobalVisualGuidelines)ë§Œ dictë¡œ ë³€í™˜
        """
        if metadata is None:
            return {}

        # metadata.visualì´ ìˆìœ¼ë©´ ê·¸ ë¶€ë¶„ë§Œ ì‚¬ìš©
        visual = getattr(metadata, "visual", None)
        if visual is None:
            # í˜¹ì‹œ ì´ë¯¸ dictë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ëŒ€ë¹„
            if isinstance(metadata, dict) and "visual" in metadata:
                visual = metadata["visual"]
            else:
                return {}

        # dataclass â†’ dict
        if hasattr(visual, "__dataclass_fields__"):
            return asdict(visual)
        if isinstance(visual, dict):
            return visual

        return {}

    # ------------------------------------------------------------
    # í•µì‹¬: ImagePlan + visual_guidelines â†’ í•œê¸€ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    # ------------------------------------------------------------
    def generate_prompt_from_plan(
        self,
        plan: ImagePlan,
        visual_guidelines: Dict[str, Any],
        max_retries: int = 3,
    ) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ê³„íšìœ¼ë¡œë¶€í„° í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        if not self.model:
            raise RuntimeError("Vertex AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ê¸€ë¡œë²Œ ìŠ¤íƒ€ì¼ ì¶”ì¶œ
        art_style = visual_guidelines.get("art_style", "Flat vector illustration")
        art_style_description = visual_guidelines.get('art_style_description', '')
        lighting_style = visual_guidelines.get("lighting_style", "ë°ê³  ê· ì¼í•œ ì¡°ëª…")
        composition_guidelines = visual_guidelines.get('composition_guidelines', '16:9 ë¹„ìœ¨, ì¤‘ì•™ ì§‘ì¤‘ êµ¬ë„')

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
    ë‹¹ì‹ ì€ ë‚˜ë…¸ë°”ë‚˜ë‚˜(Gemini 2.5 Flash Image) í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    **ì´ë¯¸ì§€ ê³„íš:**
    - ì œëª©: {plan.title}
    - ì„¤ëª…: {plan.description}
    - ì‹œê° ê°œë…: {plan.visual_concept}
    - í•µì‹¬ ê°œë…: {', '.join(plan.key_concepts)}

    **ê¸€ë¡œë²Œ ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (ëª¨ë“  ì´ë¯¸ì§€ì— í†µì¼):**
    - ì•„íŠ¸ ìŠ¤íƒ€ì¼: **{art_style}**
    - ìŠ¤íƒ€ì¼ ì„¤ëª…: {art_style_description}
    - ì¡°ëª…: {lighting_style}
    - êµ¬ë„ ê°€ì´ë“œ: {composition_guidelines}

    **ì „ì²´ ìƒ‰ìƒ íŒ”ë ˆíŠ¸:**
    {json.dumps(visual_guidelines.get('color_palette', {}), ensure_ascii=False, indent=2)}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚˜ë…¸ë°”ë‚˜ë‚˜ì— ìµœì í™”ëœ **í•œê¸€ í”„ë¡¬í”„íŠ¸**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

    **ì¤‘ìš” ê·œì¹™:**
    1. **ë°˜ë“œì‹œ "{art_style}" ìŠ¤íƒ€ì¼**ì„ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œí•˜ì„¸ìš”
    2. ê¸€ë¡œë²Œ ì¡°ëª…/êµ¬ë„ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜
    3. í•œê¸€ ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ("~í•´ì£¼ì„¸ìš”")
    4. êµ¬ì²´ì ì¸ ì‹œê° ìš”ì†Œ í¬í•¨
    5. ìƒ‰ìƒì€ HEX ì½”ë“œ ë˜ëŠ” ìƒ‰ìƒ ì´ë¦„ìœ¼ë¡œ
    6. **JSON ë¬¸ìì—´ ë‚´ë¶€ì— ì¤„ë°”ê¿ˆ ê¸ˆì§€**
    7. **ğŸ”´ CRITICAL: ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸/ë¼ë²¨/ë‹¤ì´ì–´ê·¸ë¨ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œë§Œ í‘œê¸°** (í•œê¸€ í…ìŠ¤íŠ¸ëŠ” ë Œë”ë§ í’ˆì§ˆ ì €í•˜)

    ì¶œë ¥ í˜•ì‹ (JSON, í•œ ì¤„ë¡œ):
    {{
    "image_title": "ì œëª©",
    "style": "{art_style}",
    "visual_elements": ["ìš”ì†Œ1", "ìš”ì†Œ2", "ìš”ì†Œ3", "ìš”ì†Œ4"],
    "composition": "êµ¬ë„ ìƒì„¸ ì„¤ëª…",
    "lighting": "ì¡°ëª… ìƒì„¸ ì„¤ëª…",
    "color_usage": "ì£¼ìš” ìƒ‰ìƒ",
    "image_prompt": "ì™„ì „í•œ í•œê¸€ í”„ë¡¬í”„íŠ¸ (200-300ì). ë‹¨, ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ëŠ” ì˜ì–´ë¡œë§Œ í‘œê¸°í•˜ë„ë¡ ëª…ì‹œí•  ê²ƒ."
    }}

    **ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì¤„ë°”ê¿ˆ ì—†ì´.**
    """

        # ì¬ì‹œë„ ë£¨í”„
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"   ì¬ì‹œë„ {attempt + 1}/{max_retries}...")

                # â­ í† í° í•œê³„ ì¦ê°€
                response = self.model.generate_content(
                    prompt,
                    generation_config={ 
                        "temperature": 0.6,  # 0.7 â†’ 0.6
                        "max_output_tokens": 4096,  # 2048 â†’ 4096 (2ë°° ì¦ê°€)
                        "response_mime_type": "application/json"
                    }
                )

                # â­ finish_reason ì²´í¬
                if not response.candidates:
                    raise RuntimeError("ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                candidate = response.candidates[0]
                
                if candidate.finish_reason.name == "MAX_TOKENS":
                    print(f"   âš ï¸  MAX_TOKENS ë„ë‹¬ (ì‹œë„ {attempt + 1}/{max_retries}, {plan.image_id})")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        raise RuntimeError("MAX_TOKENS í•œê³„ë¡œ ì¸í•´ ìƒì„± ì‹¤íŒ¨")

                # JSON íŒŒì‹±
                response_text = response.text.strip()

                # ë§ˆí¬ë‹¤ìš´ ì œê±°
                if response_text.startswith("```"):
                    response_text = response_text.split("```")[1]
                    if response_text.startswith("json"):
                        response_text = response_text[4:]
                    response_text = response_text.strip()
                
                # â­ JSON ì™„ì „ì„± ì²´í¬
                if not response_text.endswith("}"):
                    print(f"   âš ï¸  JSONì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤ ({plan.image_id})")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        raise json.JSONDecodeError("JSONì´ ì™„ì „í•˜ì§€ ì•ŠìŒ", response_text, len(response_text))
                
                result = json.loads(response_text)
                
                return {
                    'image_id': plan.image_id,
                    'image_title': result['image_title'],
                    'style': result.get('style', art_style),
                    'image_prompt': result['image_prompt'],
                    'visual_elements': result['visual_elements'],
                    'composition': result['composition'],
                    'lighting': result['lighting'],
                    'color_usage': result.get('color_usage', ''),
                    'primary_timestamp': plan.primary_timestamp,
                    'covered_timestamps': plan.covered_timestamps,
                    'duration': plan.duration
                }

            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}, {plan.image_id}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ ({plan.image_id}): JSON íŒŒì‹± ì—ëŸ¬ {str(e)}")
            
            except Exception as e:
                print(f"âš ï¸  ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}, {plan.image_id}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ ({plan.image_id}): {str(e)}")

        raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ ({plan.image_id}): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")

    # ------------------------------------------------------------
    # ì—¬ëŸ¬ ImagePlan â†’ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸
    # ------------------------------------------------------------
    def generate_prompts_for_plans(
        self,
        plans: List[ImagePlan],
        metadata: Any, # PodcastMetadata
        show_progress: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ ê³„íšìœ¼ë¡œë¶€í„° í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            plans: ì´ë¯¸ì§€ ê³„íš ë¦¬ìŠ¤íŠ¸
            metadata: ë©”íƒ€ë°ì´í„° (PodcastMetadata ê°ì²´)
            show_progress: ì§„í–‰ ìƒí™© í‘œì‹œ
        
        Returns:
            í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        print("\n" + "=" * 80)
        print("ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        print("=" * 80)

        # visual_guidelines = self._extract_visual_guidelines(metadata)

        # PodcastMetadata ê°ì²´ì—ì„œ visual_guidelines ì¶”ì¶œ
        if hasattr(metadata, 'global_visual_guidelines'):
            visual_guidelines = metadata.global_visual_guidelines
            # dataclassë¥¼ dictë¡œ ë³€í™˜
            if hasattr(visual_guidelines, '__dataclass_fields__'):
                from dataclasses import asdict
                visual_guidelines = asdict(visual_guidelines)
        else:
            visual_guidelines = {}
        
        # ì›ë³¸
        prompts = []

        # ë³€ê²½ -> prompts: List[Dict[str, Any]] = []

        for i, plan in enumerate(plans):
            if show_progress:
                print(f"\n[{i+1}/{len(plans)}] {plan.image_id} - {plan.title}")

            prompt_data = self.generate_prompt_from_plan(plan, visual_guidelines)
            prompts.append(prompt_data)

        print(f"\nâœ… {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
        return prompts

    # ------------------------------------------------------------
    # LangGraph entry
    # ------------------------------------------------------------
    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        LangGraphì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜¸ì¶œ ì¸í„°í˜ì´ìŠ¤

        ì…ë ¥ state:
          - image_plans: List[ImagePlan]
          - metadata: PodcastMetadata
        ì¶œë ¥ state:
          - image_prompts: List[Dict]
        """
        plans = state.get("image_plans", [])
        metadata = state.get("metadata", []) # ë³€ê²½ -> ("metadata")

        if not plans:
            print("âš ï¸  PromptGenerationNode: image_plans ë¹„ì–´ ìˆìŒ")
            return {**state, "image_prompts": []}

        prompts = self.generate_prompts_for_plans(plans, metadata)
        return {**state, "image_prompts": prompts}


# -------------------------------------------------------------------------
# í—¬í¼ í•¨ìˆ˜ë“¤ (ì˜µì…˜)
# -------------------------------------------------------------------------
def print_prompts_summary(prompts: List[Dict[str, Any]]):
    """í”„ë¡¬í”„íŠ¸ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ í”„ë¡¬í”„íŠ¸ ìš”ì•½")
    print("=" * 80)

    print(f"\nì´ í”„ë¡¬í”„íŠ¸: {len(prompts)}ê°œ")

    for i, prompt in enumerate(prompts):
        print(f"\n[{i+1}] {prompt['image_id']} - {prompt['image_title']}")
        print(f"    íƒ€ì„ìŠ¤íƒ¬í”„: {prompt['primary_timestamp']}")
        print(f"    ì»¤ë²„ ë²”ìœ„: {len(prompt['covered_timestamps'])}ê°œ ì¥ë©´")
        print(f"    ì§€ì† ì‹œê°„: {prompt['duration']}ì´ˆ")
        print(f"    í”„ë¡¬í”„íŠ¸: {prompt['image_prompt'][:100]}...")


def export_prompts(prompts: List[Dict[str, Any]], output_path: str):
    """í”„ë¡¬í”„íŠ¸ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(prompts, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥: {output_path}")


if __name__ == "__main__":
    print("Prompt Generation Node - í”„ë¡¬í”„íŠ¸ ìƒì„± ë…¸ë“œ (ì´ë¯¸ì§€ ê³„íš ê¸°ë°˜)")
    print("Importí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”: from prompt_generation_node import PromptGenerationNode")
